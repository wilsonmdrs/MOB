import {
  __commonJS,
  __toESM
} from "./chunk-DFKQJ226.js";

// browser-external:fs
var require_fs = __commonJS({
  "browser-external:fs"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "fs" has been externalized for browser compatibility. Cannot access "fs.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:net
var require_net = __commonJS({
  "browser-external:net"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "net" has been externalized for browser compatibility. Cannot access "net.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:tls
var require_tls = __commonJS({
  "browser-external:tls"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "tls" has been externalized for browser compatibility. Cannot access "tls.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:agent-base
var require_agent_base = __commonJS({
  "browser-external:agent-base"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "agent-base" has been externalized for browser compatibility. Cannot access "agent-base.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:https-proxy-agent
var require_https_proxy_agent = __commonJS({
  "browser-external:https-proxy-agent"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "https-proxy-agent" has been externalized for browser compatibility. Cannot access "https-proxy-agent.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:ws
var require_ws = __commonJS({
  "browser-external:ws"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "ws" has been externalized for browser compatibility. Cannot access "ws.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/bent/src/core.js
var require_core = __commonJS({
  "node_modules/bent/src/core.js"(exports, module) {
    "use strict";
    var encodings = /* @__PURE__ */ new Set(["json", "buffer", "string"]);
    module.exports = (mkrequest) => (...args) => {
      const statusCodes = /* @__PURE__ */ new Set();
      let method;
      let encoding;
      let headers;
      let baseurl = "";
      args.forEach((arg) => {
        if (typeof arg === "string") {
          if (arg.toUpperCase() === arg) {
            if (method) {
              const msg = `Can't set method to ${arg}, already set to ${method}.`;
              throw new Error(msg);
            } else {
              method = arg;
            }
          } else if (arg.startsWith("http:") || arg.startsWith("https:")) {
            baseurl = arg;
          } else {
            if (encodings.has(arg)) {
              encoding = arg;
            } else {
              throw new Error(`Unknown encoding, ${arg}`);
            }
          }
        } else if (typeof arg === "number") {
          statusCodes.add(arg);
        } else if (typeof arg === "object") {
          if (Array.isArray(arg) || arg instanceof Set) {
            arg.forEach((code) => statusCodes.add(code));
          } else {
            if (headers) {
              throw new Error("Cannot set headers twice.");
            }
            headers = arg;
          }
        } else {
          throw new Error(`Unknown type: ${typeof arg}`);
        }
      });
      if (!method)
        method = "GET";
      if (statusCodes.size === 0) {
        statusCodes.add(200);
      }
      return mkrequest(statusCodes, method, encoding, headers, baseurl);
    };
  }
});

// node_modules/bent/src/browser.js
var require_browser = __commonJS({
  "node_modules/bent/src/browser.js"(exports, module) {
    "use strict";
    var core = require_core();
    var StatusError = class extends Error {
      constructor(res, ...params) {
        super(...params);
        if (Error.captureStackTrace) {
          Error.captureStackTrace(this, StatusError);
        }
        this.name = "StatusError";
        this.message = res.statusMessage;
        this.statusCode = res.status;
        this.res = res;
        this.json = res.json.bind(res);
        this.text = res.text.bind(res);
        this.arrayBuffer = res.arrayBuffer.bind(res);
        let buffer;
        const get = () => {
          if (!buffer)
            buffer = this.arrayBuffer();
          return buffer;
        };
        Object.defineProperty(this, "responseBody", { get });
        this.headers = {};
        for (const [key, value] of res.headers.entries()) {
          this.headers[key.toLowerCase()] = value;
        }
      }
    };
    var mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {
      _url = baseurl + (_url || "");
      let parsed = new URL(_url);
      if (!headers)
        headers = {};
      if (parsed.username) {
        headers.Authorization = "Basic " + btoa(parsed.username + ":" + parsed.password);
        parsed = new URL(parsed.protocol + "//" + parsed.host + parsed.pathname + parsed.search);
      }
      if (parsed.protocol !== "https:" && parsed.protocol !== "http:") {
        throw new Error(`Unknown protocol, ${parsed.protocol}`);
      }
      if (body) {
        if (body instanceof ArrayBuffer || ArrayBuffer.isView(body) || typeof body === "string") {
        } else if (typeof body === "object") {
          body = JSON.stringify(body);
          headers["Content-Type"] = "application/json";
        } else {
          throw new Error("Unknown body type.");
        }
      }
      _headers = new Headers({ ...headers || {}, ..._headers });
      const resp = await fetch(parsed, { method, headers: _headers, body });
      resp.statusCode = resp.status;
      if (!statusCodes.has(resp.status)) {
        throw new StatusError(resp);
      }
      if (encoding === "json")
        return resp.json();
      else if (encoding === "buffer")
        return resp.arrayBuffer();
      else if (encoding === "string")
        return resp.text();
      else
        return resp;
    };
    module.exports = core(mkrequest);
  }
});

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js
var fs = __toESM(require_fs());

// node_modules/uuid/dist/esm-browser/rng.js
var getRandomValues;
var rnds8 = new Uint8Array(16);
function rng() {
  if (!getRandomValues) {
    getRandomValues = typeof crypto !== "undefined" && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);
    if (!getRandomValues) {
      throw new Error("crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported");
    }
  }
  return getRandomValues(rnds8);
}

// node_modules/uuid/dist/esm-browser/regex.js
var regex_default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;

// node_modules/uuid/dist/esm-browser/validate.js
function validate(uuid) {
  return typeof uuid === "string" && regex_default.test(uuid);
}
var validate_default = validate;

// node_modules/uuid/dist/esm-browser/stringify.js
var byteToHex = [];
for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 256).toString(16).slice(1));
}
function unsafeStringify(arr, offset = 0) {
  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + "-" + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + "-" + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + "-" + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + "-" + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();
}

// node_modules/uuid/dist/esm-browser/parse.js
function parse(uuid) {
  if (!validate_default(uuid)) {
    throw TypeError("Invalid UUID");
  }
  let v;
  const arr = new Uint8Array(16);
  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;
  arr[1] = v >>> 16 & 255;
  arr[2] = v >>> 8 & 255;
  arr[3] = v & 255;
  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;
  arr[5] = v & 255;
  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;
  arr[7] = v & 255;
  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;
  arr[9] = v & 255;
  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 1099511627776 & 255;
  arr[11] = v / 4294967296 & 255;
  arr[12] = v >>> 24 & 255;
  arr[13] = v >>> 16 & 255;
  arr[14] = v >>> 8 & 255;
  arr[15] = v & 255;
  return arr;
}
var parse_default = parse;

// node_modules/uuid/dist/esm-browser/v35.js
function stringToBytes(str) {
  str = unescape(encodeURIComponent(str));
  const bytes = [];
  for (let i = 0; i < str.length; ++i) {
    bytes.push(str.charCodeAt(i));
  }
  return bytes;
}
var DNS = "6ba7b810-9dad-11d1-80b4-00c04fd430c8";
var URL2 = "6ba7b811-9dad-11d1-80b4-00c04fd430c8";
function v35(name, version, hashfunc) {
  function generateUUID(value, namespace, buf, offset) {
    var _namespace;
    if (typeof value === "string") {
      value = stringToBytes(value);
    }
    if (typeof namespace === "string") {
      namespace = parse_default(namespace);
    }
    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {
      throw TypeError("Namespace must be array-like (16 iterable integer values, 0-255)");
    }
    let bytes = new Uint8Array(16 + value.length);
    bytes.set(namespace);
    bytes.set(value, namespace.length);
    bytes = hashfunc(bytes);
    bytes[6] = bytes[6] & 15 | version;
    bytes[8] = bytes[8] & 63 | 128;
    if (buf) {
      offset = offset || 0;
      for (let i = 0; i < 16; ++i) {
        buf[offset + i] = bytes[i];
      }
      return buf;
    }
    return unsafeStringify(bytes);
  }
  try {
    generateUUID.name = name;
  } catch (err) {
  }
  generateUUID.DNS = DNS;
  generateUUID.URL = URL2;
  return generateUUID;
}

// node_modules/uuid/dist/esm-browser/md5.js
function md5(bytes) {
  if (typeof bytes === "string") {
    const msg = unescape(encodeURIComponent(bytes));
    bytes = new Uint8Array(msg.length);
    for (let i = 0; i < msg.length; ++i) {
      bytes[i] = msg.charCodeAt(i);
    }
  }
  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));
}
function md5ToHexEncodedArray(input) {
  const output = [];
  const length32 = input.length * 32;
  const hexTab = "0123456789abcdef";
  for (let i = 0; i < length32; i += 8) {
    const x = input[i >> 5] >>> i % 32 & 255;
    const hex = parseInt(hexTab.charAt(x >>> 4 & 15) + hexTab.charAt(x & 15), 16);
    output.push(hex);
  }
  return output;
}
function getOutputLength(inputLength8) {
  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;
}
function wordsToMd5(x, len) {
  x[len >> 5] |= 128 << len % 32;
  x[getOutputLength(len) - 1] = len;
  let a = 1732584193;
  let b = -271733879;
  let c = -1732584194;
  let d = 271733878;
  for (let i = 0; i < x.length; i += 16) {
    const olda = a;
    const oldb = b;
    const oldc = c;
    const oldd = d;
    a = md5ff(a, b, c, d, x[i], 7, -680876936);
    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);
    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);
    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);
    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);
    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);
    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);
    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);
    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);
    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);
    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);
    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);
    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);
    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);
    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);
    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);
    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);
    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);
    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);
    b = md5gg(b, c, d, a, x[i], 20, -373897302);
    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);
    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);
    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);
    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);
    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);
    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);
    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);
    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);
    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);
    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);
    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);
    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);
    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);
    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);
    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);
    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);
    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);
    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);
    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);
    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);
    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);
    d = md5hh(d, a, b, c, x[i], 11, -358537222);
    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);
    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);
    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);
    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);
    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);
    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);
    a = md5ii(a, b, c, d, x[i], 6, -198630844);
    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);
    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);
    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);
    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);
    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);
    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);
    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);
    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);
    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);
    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);
    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);
    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);
    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);
    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);
    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);
    a = safeAdd(a, olda);
    b = safeAdd(b, oldb);
    c = safeAdd(c, oldc);
    d = safeAdd(d, oldd);
  }
  return [a, b, c, d];
}
function bytesToWords(input) {
  if (input.length === 0) {
    return [];
  }
  const length8 = input.length * 8;
  const output = new Uint32Array(getOutputLength(length8));
  for (let i = 0; i < length8; i += 8) {
    output[i >> 5] |= (input[i / 8] & 255) << i % 32;
  }
  return output;
}
function safeAdd(x, y) {
  const lsw = (x & 65535) + (y & 65535);
  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);
  return msw << 16 | lsw & 65535;
}
function bitRotateLeft(num, cnt) {
  return num << cnt | num >>> 32 - cnt;
}
function md5cmn(q, a, b, x, s, t) {
  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);
}
function md5ff(a, b, c, d, x, s, t) {
  return md5cmn(b & c | ~b & d, a, b, x, s, t);
}
function md5gg(a, b, c, d, x, s, t) {
  return md5cmn(b & d | c & ~d, a, b, x, s, t);
}
function md5hh(a, b, c, d, x, s, t) {
  return md5cmn(b ^ c ^ d, a, b, x, s, t);
}
function md5ii(a, b, c, d, x, s, t) {
  return md5cmn(c ^ (b | ~d), a, b, x, s, t);
}
var md5_default = md5;

// node_modules/uuid/dist/esm-browser/v3.js
var v3 = v35("v3", 48, md5_default);

// node_modules/uuid/dist/esm-browser/native.js
var randomUUID = typeof crypto !== "undefined" && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native_default = {
  randomUUID
};

// node_modules/uuid/dist/esm-browser/v4.js
function v4(options, buf, offset) {
  if (native_default.randomUUID && !buf && !options) {
    return native_default.randomUUID();
  }
  options = options || {};
  const rnds = options.random || (options.rng || rng)();
  rnds[6] = rnds[6] & 15 | 64;
  rnds[8] = rnds[8] & 63 | 128;
  if (buf) {
    offset = offset || 0;
    for (let i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }
    return buf;
  }
  return unsafeStringify(rnds);
}
var v4_default = v4;

// node_modules/uuid/dist/esm-browser/sha1.js
function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;
    case 1:
      return x ^ y ^ z;
    case 2:
      return x & y ^ x & z ^ y & z;
    case 3:
      return x ^ y ^ z;
  }
}
function ROTL(x, n) {
  return x << n | x >>> 32 - n;
}
function sha1(bytes) {
  const K = [1518500249, 1859775393, 2400959708, 3395469782];
  const H = [1732584193, 4023233417, 2562383102, 271733878, 3285377520];
  if (typeof bytes === "string") {
    const msg = unescape(encodeURIComponent(bytes));
    bytes = [];
    for (let i = 0; i < msg.length; ++i) {
      bytes.push(msg.charCodeAt(i));
    }
  } else if (!Array.isArray(bytes)) {
    bytes = Array.prototype.slice.call(bytes);
  }
  bytes.push(128);
  const l = bytes.length / 4 + 2;
  const N = Math.ceil(l / 16);
  const M = new Array(N);
  for (let i = 0; i < N; ++i) {
    const arr = new Uint32Array(16);
    for (let j = 0; j < 16; ++j) {
      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];
    }
    M[i] = arr;
  }
  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (bytes.length - 1) * 8 & 4294967295;
  for (let i = 0; i < N; ++i) {
    const W = new Uint32Array(80);
    for (let t = 0; t < 16; ++t) {
      W[t] = M[i][t];
    }
    for (let t = 16; t < 80; ++t) {
      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);
    }
    let a = H[0];
    let b = H[1];
    let c = H[2];
    let d = H[3];
    let e = H[4];
    for (let t = 0; t < 80; ++t) {
      const s = Math.floor(t / 20);
      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;
      e = d;
      d = c;
      c = ROTL(b, 30) >>> 0;
      b = a;
      a = T;
    }
    H[0] = H[0] + a >>> 0;
    H[1] = H[1] + b >>> 0;
    H[2] = H[2] + c >>> 0;
    H[3] = H[3] + d >>> 0;
    H[4] = H[4] + e >>> 0;
  }
  return [H[0] >> 24 & 255, H[0] >> 16 & 255, H[0] >> 8 & 255, H[0] & 255, H[1] >> 24 & 255, H[1] >> 16 & 255, H[1] >> 8 & 255, H[1] & 255, H[2] >> 24 & 255, H[2] >> 16 & 255, H[2] >> 8 & 255, H[2] & 255, H[3] >> 24 & 255, H[3] >> 16 & 255, H[3] >> 8 & 255, H[3] & 255, H[4] >> 24 & 255, H[4] >> 16 & 255, H[4] >> 8 & 255, H[4] & 255];
}
var sha1_default = sha1;

// node_modules/uuid/dist/esm-browser/v5.js
var v5 = v35("v5", 80, sha1_default);

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js
var createGuid = () => v4_default();
var createNoDashGuid = () => createGuid().replace(new RegExp("-", "g"), "").toUpperCase();

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js
var EventType;
(function(EventType2) {
  EventType2[EventType2["Debug"] = 0] = "Debug";
  EventType2[EventType2["Info"] = 1] = "Info";
  EventType2[EventType2["Warning"] = 2] = "Warning";
  EventType2[EventType2["Error"] = 3] = "Error";
  EventType2[EventType2["None"] = 4] = "None";
})(EventType || (EventType = {}));
var PlatformEvent = class {
  constructor(eventName, eventType) {
    this.privName = eventName;
    this.privEventId = createNoDashGuid();
    this.privEventTime = (/* @__PURE__ */ new Date()).toISOString();
    this.privEventType = eventType;
    this.privMetadata = {};
  }
  get name() {
    return this.privName;
  }
  get eventId() {
    return this.privEventId;
  }
  get eventTime() {
    return this.privEventTime;
  }
  get eventType() {
    return this.privEventType;
  }
  get metadata() {
    return this.privMetadata;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js
var AudioSourceEvent = class extends PlatformEvent {
  constructor(eventName, audioSourceId, eventType = EventType.Info) {
    super(eventName, eventType);
    this.privAudioSourceId = audioSourceId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
};
var AudioSourceInitializingEvent = class extends AudioSourceEvent {
  constructor(audioSourceId) {
    super("AudioSourceInitializingEvent", audioSourceId);
  }
};
var AudioSourceReadyEvent = class extends AudioSourceEvent {
  constructor(audioSourceId) {
    super("AudioSourceReadyEvent", audioSourceId);
  }
};
var AudioSourceOffEvent = class extends AudioSourceEvent {
  constructor(audioSourceId) {
    super("AudioSourceOffEvent", audioSourceId);
  }
};
var AudioSourceErrorEvent = class extends AudioSourceEvent {
  constructor(audioSourceId, error) {
    super("AudioSourceErrorEvent", audioSourceId, EventType.Error);
    this.privError = error;
  }
  get error() {
    return this.privError;
  }
};
var AudioStreamNodeEvent = class extends AudioSourceEvent {
  constructor(eventName, audioSourceId, audioNodeId) {
    super(eventName, audioSourceId);
    this.privAudioNodeId = audioNodeId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
};
var AudioStreamNodeAttachingEvent = class extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId) {
    super("AudioStreamNodeAttachingEvent", audioSourceId, audioNodeId);
  }
};
var AudioStreamNodeAttachedEvent = class extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId) {
    super("AudioStreamNodeAttachedEvent", audioSourceId, audioNodeId);
  }
};
var AudioStreamNodeDetachedEvent = class extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId) {
    super("AudioStreamNodeDetachedEvent", audioSourceId, audioNodeId);
  }
};
var AudioStreamNodeErrorEvent = class extends AudioStreamNodeEvent {
  constructor(audioSourceId, audioNodeId, error) {
    super("AudioStreamNodeErrorEvent", audioSourceId, audioNodeId);
    this.privError = error;
  }
  get error() {
    return this.privError;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js
var ServiceEvent = class extends PlatformEvent {
  constructor(eventName, jsonstring, eventType = EventType.Info) {
    super(eventName, eventType);
    this.privJsonResult = jsonstring;
  }
  get jsonString() {
    return this.privJsonResult;
  }
};
var ConnectionEvent = class extends PlatformEvent {
  constructor(eventName, connectionId, eventType = EventType.Info) {
    super(eventName, eventType);
    this.privConnectionId = connectionId;
  }
  get connectionId() {
    return this.privConnectionId;
  }
};
var ConnectionStartEvent = class extends ConnectionEvent {
  constructor(connectionId, uri, headers) {
    super("ConnectionStartEvent", connectionId);
    this.privUri = uri;
    this.privHeaders = headers;
  }
  get uri() {
    return this.privUri;
  }
  get headers() {
    return this.privHeaders;
  }
};
var ConnectionEstablishedEvent = class extends ConnectionEvent {
  constructor(connectionId) {
    super("ConnectionEstablishedEvent", connectionId);
  }
};
var ConnectionClosedEvent = class extends ConnectionEvent {
  constructor(connectionId, statusCode, reason) {
    super("ConnectionClosedEvent", connectionId, EventType.Debug);
    this.privReason = reason;
    this.privStatusCode = statusCode;
  }
  get reason() {
    return this.privReason;
  }
  get statusCode() {
    return this.privStatusCode;
  }
};
var ConnectionErrorEvent = class extends ConnectionEvent {
  constructor(connectionId, message, type2) {
    super("ConnectionErrorEvent", connectionId, EventType.Debug);
    this.privMessage = message;
    this.privType = type2;
  }
  get message() {
    return this.privMessage;
  }
  get type() {
    return this.privType;
  }
};
var ConnectionEstablishErrorEvent = class extends ConnectionEvent {
  constructor(connectionId, statuscode, reason) {
    super("ConnectionEstablishErrorEvent", connectionId, EventType.Error);
    this.privStatusCode = statuscode;
    this.privReason = reason;
  }
  get reason() {
    return this.privReason;
  }
  get statusCode() {
    return this.privStatusCode;
  }
};
var ConnectionMessageReceivedEvent = class extends ConnectionEvent {
  constructor(connectionId, networkReceivedTimeISO, message) {
    super("ConnectionMessageReceivedEvent", connectionId);
    this.privNetworkReceivedTime = networkReceivedTimeISO;
    this.privMessage = message;
  }
  get networkReceivedTime() {
    return this.privNetworkReceivedTime;
  }
  get message() {
    return this.privMessage;
  }
};
var ConnectionMessageSentEvent = class extends ConnectionEvent {
  constructor(connectionId, networkSentTimeISO, message) {
    super("ConnectionMessageSentEvent", connectionId);
    this.privNetworkSentTime = networkSentTimeISO;
    this.privMessage = message;
  }
  get networkSentTime() {
    return this.privNetworkSentTime;
  }
  get message() {
    return this.privMessage;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js
var ArgumentNullError = class extends Error {
  /**
   * Creates an instance of ArgumentNullError.
   *
   * @param {string} argumentName - Name of the argument that is null
   *
   * @memberOf ArgumentNullError
   */
  constructor(argumentName) {
    super(argumentName);
    this.name = "ArgumentNull";
    this.message = argumentName;
  }
};
var InvalidOperationError = class extends Error {
  /**
   * Creates an instance of InvalidOperationError.
   *
   * @param {string} error - The error
   *
   * @memberOf InvalidOperationError
   */
  constructor(error) {
    super(error);
    this.name = "InvalidOperation";
    this.message = error;
  }
};
var ObjectDisposedError = class extends Error {
  /**
   * Creates an instance of ObjectDisposedError.
   *
   * @param {string} objectName - The object that is disposed
   * @param {string} error - The error
   *
   * @memberOf ObjectDisposedError
   */
  constructor(objectName, error) {
    super(error);
    this.name = objectName + "ObjectDisposed";
    this.message = error;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js
var MessageType;
(function(MessageType2) {
  MessageType2[MessageType2["Text"] = 0] = "Text";
  MessageType2[MessageType2["Binary"] = 1] = "Binary";
})(MessageType || (MessageType = {}));
var ConnectionMessage = class {
  constructor(messageType, body, headers, id) {
    this.privBody = null;
    if (messageType === MessageType.Text && body && !(typeof body === "string")) {
      throw new InvalidOperationError("Payload must be a string");
    }
    if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {
      throw new InvalidOperationError("Payload must be ArrayBuffer");
    }
    this.privMessageType = messageType;
    this.privBody = body;
    this.privHeaders = headers ? headers : {};
    this.privId = id ? id : createNoDashGuid();
    switch (this.messageType) {
      case MessageType.Binary:
        this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;
        break;
      case MessageType.Text:
        this.privSize = this.textBody.length;
    }
  }
  get messageType() {
    return this.privMessageType;
  }
  get headers() {
    return this.privHeaders;
  }
  get body() {
    return this.privBody;
  }
  get textBody() {
    if (this.privMessageType === MessageType.Binary) {
      throw new InvalidOperationError("Not supported for binary message");
    }
    return this.privBody;
  }
  get binaryBody() {
    if (this.privMessageType === MessageType.Text) {
      throw new InvalidOperationError("Not supported for text message");
    }
    return this.privBody;
  }
  get id() {
    return this.privId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js
var ConnectionOpenResponse = class {
  constructor(statusCode, reason) {
    this.privStatusCode = statusCode;
    this.privReason = reason;
  }
  get statusCode() {
    return this.privStatusCode;
  }
  get reason() {
    return this.privReason;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DeferralMap.js
var DeferralMap = class {
  constructor() {
    this.privMap = {};
  }
  add(id, deferral) {
    this.privMap[id] = deferral;
  }
  getId(id) {
    return this.privMap[id];
  }
  complete(id, result) {
    try {
      this.privMap[id].resolve(result);
    } catch (error) {
      this.privMap[id].reject(error);
    } finally {
      this.privMap[id] = void 0;
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js
var DialogEvent = class extends PlatformEvent {
  constructor(eventName, eventType = EventType.Info) {
    super(eventName, eventType);
  }
};
var SendingAgentContextMessageEvent = class extends DialogEvent {
  constructor(agentConfig) {
    super("SendingAgentContextMessageEvent");
    this.privAgentConfig = agentConfig;
  }
  get agentConfig() {
    return this.privAgentConfig;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js
var EventSource = class {
  constructor(metadata) {
    this.privEventListeners = {};
    this.privIsDisposed = false;
    this.privConsoleListener = void 0;
    this.privMetadata = metadata;
  }
  onEvent(event) {
    if (this.isDisposed()) {
      throw new ObjectDisposedError("EventSource");
    }
    if (this.metadata) {
      for (const paramName in this.metadata) {
        if (paramName) {
          if (event.metadata) {
            if (!event.metadata[paramName]) {
              event.metadata[paramName] = this.metadata[paramName];
            }
          }
        }
      }
    }
    for (const eventId in this.privEventListeners) {
      if (eventId && this.privEventListeners[eventId]) {
        this.privEventListeners[eventId](event);
      }
    }
  }
  attach(onEventCallback) {
    const id = createNoDashGuid();
    this.privEventListeners[id] = onEventCallback;
    return {
      detach: () => {
        delete this.privEventListeners[id];
        return Promise.resolve();
      }
    };
  }
  attachListener(listener) {
    return this.attach((e) => listener.onEvent(e));
  }
  attachConsoleListener(listener) {
    if (!!this.privConsoleListener) {
      void this.privConsoleListener.detach();
    }
    this.privConsoleListener = this.attach((e) => listener.onEvent(e));
    return this.privConsoleListener;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose() {
    this.privEventListeners = null;
    this.privIsDisposed = true;
  }
  get metadata() {
    return this.privMetadata;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js
var Events = class {
  static setEventSource(eventSource) {
    if (!eventSource) {
      throw new ArgumentNullError("eventSource");
    }
    Events.privInstance = eventSource;
  }
  static get instance() {
    return Events.privInstance;
  }
};
Events.privInstance = new EventSource();

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js
var ConnectionState;
(function(ConnectionState2) {
  ConnectionState2[ConnectionState2["None"] = 0] = "None";
  ConnectionState2[ConnectionState2["Connected"] = 1] = "Connected";
  ConnectionState2[ConnectionState2["Connecting"] = 2] = "Connecting";
  ConnectionState2[ConnectionState2["Disconnected"] = 3] = "Disconnected";
})(ConnectionState || (ConnectionState = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js
var List = class {
  constructor(list) {
    this.privSubscriptionIdCounter = 0;
    this.privAddSubscriptions = {};
    this.privRemoveSubscriptions = {};
    this.privDisposedSubscriptions = {};
    this.privDisposeReason = null;
    this.privList = [];
    if (list) {
      for (const item of list) {
        this.privList.push(item);
      }
    }
  }
  get(itemIndex) {
    this.throwIfDisposed();
    return this.privList[itemIndex];
  }
  first() {
    return this.get(0);
  }
  last() {
    return this.get(this.length() - 1);
  }
  add(item) {
    this.throwIfDisposed();
    this.insertAt(this.privList.length, item);
  }
  insertAt(index, item) {
    this.throwIfDisposed();
    if (index === 0) {
      this.privList.unshift(item);
    } else if (index === this.privList.length) {
      this.privList.push(item);
    } else {
      this.privList.splice(index, 0, item);
    }
    this.triggerSubscriptions(this.privAddSubscriptions);
  }
  removeFirst() {
    this.throwIfDisposed();
    return this.removeAt(0);
  }
  removeLast() {
    this.throwIfDisposed();
    return this.removeAt(this.length() - 1);
  }
  removeAt(index) {
    this.throwIfDisposed();
    return this.remove(index, 1)[0];
  }
  remove(index, count) {
    this.throwIfDisposed();
    const removedElements = this.privList.splice(index, count);
    this.triggerSubscriptions(this.privRemoveSubscriptions);
    return removedElements;
  }
  clear() {
    this.throwIfDisposed();
    this.remove(0, this.length());
  }
  length() {
    this.throwIfDisposed();
    return this.privList.length;
  }
  onAdded(addedCallback) {
    this.throwIfDisposed();
    const subscriptionId = this.privSubscriptionIdCounter++;
    this.privAddSubscriptions[subscriptionId] = addedCallback;
    return {
      detach: () => {
        delete this.privAddSubscriptions[subscriptionId];
        return Promise.resolve();
      }
    };
  }
  onRemoved(removedCallback) {
    this.throwIfDisposed();
    const subscriptionId = this.privSubscriptionIdCounter++;
    this.privRemoveSubscriptions[subscriptionId] = removedCallback;
    return {
      detach: () => {
        delete this.privRemoveSubscriptions[subscriptionId];
        return Promise.resolve();
      }
    };
  }
  onDisposed(disposedCallback) {
    this.throwIfDisposed();
    const subscriptionId = this.privSubscriptionIdCounter++;
    this.privDisposedSubscriptions[subscriptionId] = disposedCallback;
    return {
      detach: () => {
        delete this.privDisposedSubscriptions[subscriptionId];
        return Promise.resolve();
      }
    };
  }
  join(seperator) {
    this.throwIfDisposed();
    return this.privList.join(seperator);
  }
  toArray() {
    const cloneCopy = Array();
    this.privList.forEach((val) => {
      cloneCopy.push(val);
    });
    return cloneCopy;
  }
  any(callback) {
    this.throwIfDisposed();
    if (callback) {
      return this.where(callback).length() > 0;
    } else {
      return this.length() > 0;
    }
  }
  all(callback) {
    this.throwIfDisposed();
    return this.where(callback).length() === this.length();
  }
  forEach(callback) {
    this.throwIfDisposed();
    for (let i = 0; i < this.length(); i++) {
      callback(this.privList[i], i);
    }
  }
  select(callback) {
    this.throwIfDisposed();
    const selectList = [];
    for (let i = 0; i < this.privList.length; i++) {
      selectList.push(callback(this.privList[i], i));
    }
    return new List(selectList);
  }
  where(callback) {
    this.throwIfDisposed();
    const filteredList = new List();
    for (let i = 0; i < this.privList.length; i++) {
      if (callback(this.privList[i], i)) {
        filteredList.add(this.privList[i]);
      }
    }
    return filteredList;
  }
  orderBy(compareFn) {
    this.throwIfDisposed();
    const clonedArray = this.toArray();
    const orderedArray = clonedArray.sort(compareFn);
    return new List(orderedArray);
  }
  orderByDesc(compareFn) {
    this.throwIfDisposed();
    return this.orderBy((a, b) => compareFn(b, a));
  }
  clone() {
    this.throwIfDisposed();
    return new List(this.toArray());
  }
  concat(list) {
    this.throwIfDisposed();
    return new List(this.privList.concat(list.toArray()));
  }
  concatArray(array) {
    this.throwIfDisposed();
    return new List(this.privList.concat(array));
  }
  isDisposed() {
    return this.privList == null;
  }
  dispose(reason) {
    if (!this.isDisposed()) {
      this.privDisposeReason = reason;
      this.privList = null;
      this.privAddSubscriptions = null;
      this.privRemoveSubscriptions = null;
      this.triggerSubscriptions(this.privDisposedSubscriptions);
    }
  }
  throwIfDisposed() {
    if (this.isDisposed()) {
      throw new ObjectDisposedError("List", this.privDisposeReason);
    }
  }
  triggerSubscriptions(subscriptions) {
    if (subscriptions) {
      for (const subscriptionId in subscriptions) {
        if (subscriptionId) {
          subscriptions[subscriptionId]();
        }
      }
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js
var PromiseState;
(function(PromiseState2) {
  PromiseState2[PromiseState2["None"] = 0] = "None";
  PromiseState2[PromiseState2["Resolved"] = 1] = "Resolved";
  PromiseState2[PromiseState2["Rejected"] = 2] = "Rejected";
})(PromiseState || (PromiseState = {}));
var Deferred = class {
  constructor() {
    this.resolve = (result) => {
      this.privResolve(result);
      return this;
    };
    this.reject = (error) => {
      this.privReject(error);
      return this;
    };
    this.privPromise = new Promise((resolve, reject) => {
      this.privResolve = resolve;
      this.privReject = reject;
    });
  }
  get promise() {
    return this.privPromise;
  }
};
function marshalPromiseToCallbacks(promise, cb, err) {
  promise.then((val) => {
    try {
      if (!!cb) {
        cb(val);
      }
    } catch (error) {
      if (!!err) {
        try {
          if (error instanceof Error) {
            const typedError = error;
            err(typedError.name + ": " + typedError.message);
          } else {
            err(error);
          }
        } catch (error2) {
        }
      }
    }
  }, (error) => {
    if (!!err) {
      try {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      } catch (error2) {
      }
    }
  });
}

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js
var __awaiter = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SubscriberType;
(function(SubscriberType2) {
  SubscriberType2[SubscriberType2["Dequeue"] = 0] = "Dequeue";
  SubscriberType2[SubscriberType2["Peek"] = 1] = "Peek";
})(SubscriberType || (SubscriberType = {}));
var Queue = class {
  constructor(list) {
    this.privPromiseStore = new List();
    this.privIsDrainInProgress = false;
    this.privIsDisposing = false;
    this.privDisposeReason = null;
    this.privList = list ? list : new List();
    this.privDetachables = [];
    this.privSubscribers = new List();
    this.privDetachables.push(this.privList.onAdded(() => this.drain()));
  }
  enqueue(item) {
    this.throwIfDispose();
    this.enqueueFromPromise(new Promise((resolve) => resolve(item)));
  }
  enqueueFromPromise(promise) {
    this.throwIfDispose();
    promise.then((val) => {
      this.privList.add(val);
    }, () => {
    });
  }
  dequeue() {
    this.throwIfDispose();
    const deferredSubscriber = new Deferred();
    if (this.privSubscribers) {
      this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Dequeue });
      this.drain();
    }
    return deferredSubscriber.promise;
  }
  peek() {
    this.throwIfDispose();
    const deferredSubscriber = new Deferred();
    const subs = this.privSubscribers;
    if (subs) {
      this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Peek });
      this.drain();
    }
    return deferredSubscriber.promise;
  }
  length() {
    this.throwIfDispose();
    return this.privList.length();
  }
  isDisposed() {
    return this.privSubscribers == null;
  }
  drainAndDispose(pendingItemProcessor, reason) {
    return __awaiter(this, void 0, void 0, function* () {
      if (!this.isDisposed() && !this.privIsDisposing) {
        this.privDisposeReason = reason;
        this.privIsDisposing = true;
        const subs = this.privSubscribers;
        if (subs) {
          while (subs.length() > 0) {
            const subscriber = subs.removeFirst();
            subscriber.deferral.resolve(void 0);
          }
          if (this.privSubscribers === subs) {
            this.privSubscribers = subs;
          }
        }
        for (const detachable of this.privDetachables) {
          yield detachable.detach();
        }
        if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {
          const promiseArray = [];
          this.privPromiseStore.toArray().forEach((wrapper) => {
            promiseArray.push(wrapper);
          });
          return Promise.all(promiseArray).finally(() => {
            this.privSubscribers = null;
            this.privList.forEach((item) => {
              pendingItemProcessor(item);
            });
            this.privList = null;
            return;
          }).then();
        } else {
          this.privSubscribers = null;
          this.privList = null;
        }
      }
    });
  }
  dispose(reason) {
    return __awaiter(this, void 0, void 0, function* () {
      yield this.drainAndDispose(null, reason);
    });
  }
  drain() {
    if (!this.privIsDrainInProgress && !this.privIsDisposing) {
      this.privIsDrainInProgress = true;
      const subs = this.privSubscribers;
      const lists = this.privList;
      if (subs && lists) {
        while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {
          const subscriber = subs.removeFirst();
          if (subscriber.type === SubscriberType.Peek) {
            subscriber.deferral.resolve(lists.first());
          } else {
            const dequeuedItem = lists.removeFirst();
            subscriber.deferral.resolve(dequeuedItem);
          }
        }
        if (this.privSubscribers === subs) {
          this.privSubscribers = subs;
        }
        if (this.privList === lists) {
          this.privList = lists;
        }
      }
      this.privIsDrainInProgress = false;
    }
  }
  throwIfDispose() {
    if (this.isDisposed()) {
      if (this.privDisposeReason) {
        throw new InvalidOperationError(this.privDisposeReason);
      }
      throw new ObjectDisposedError("Queue");
    } else if (this.privIsDisposing) {
      throw new InvalidOperationError("Queue disposing");
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js
var RawWebsocketMessage = class {
  constructor(messageType, payload, id) {
    this.privPayload = null;
    if (!payload) {
      throw new ArgumentNullError("payload");
    }
    if (messageType === MessageType.Binary && payload.__proto__.constructor.name !== "ArrayBuffer") {
      throw new InvalidOperationError("Payload must be ArrayBuffer");
    }
    if (messageType === MessageType.Text && !(typeof payload === "string")) {
      throw new InvalidOperationError("Payload must be a string");
    }
    this.privMessageType = messageType;
    this.privPayload = payload;
    this.privId = id ? id : createNoDashGuid();
  }
  get messageType() {
    return this.privMessageType;
  }
  get payload() {
    return this.privPayload;
  }
  get textContent() {
    if (this.privMessageType === MessageType.Binary) {
      throw new InvalidOperationError("Not supported for binary message");
    }
    return this.privPayload;
  }
  get binaryContent() {
    if (this.privMessageType === MessageType.Text) {
      throw new InvalidOperationError("Not supported for text message");
    }
    return this.privPayload;
  }
  get id() {
    return this.privId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js
var RiffPcmEncoder = class {
  constructor(actualSampleRate, desiredSampleRate) {
    this.privActualSampleRate = actualSampleRate;
    this.privDesiredSampleRate = desiredSampleRate;
  }
  encode(actualAudioFrame) {
    const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);
    if (!audioFrame) {
      return null;
    }
    const audioLength = audioFrame.length * 2;
    const buffer = new ArrayBuffer(audioLength);
    const view = new DataView(buffer);
    this.floatTo16BitPCM(view, 0, audioFrame);
    return buffer;
  }
  setString(view, offset, str) {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset + i, str.charCodeAt(i));
    }
  }
  floatTo16BitPCM(view, offset, input) {
    for (let i = 0; i < input.length; i++, offset += 2) {
      const s = Math.max(-1, Math.min(1, input[i]));
      view.setInt16(offset, s < 0 ? s * 32768 : s * 32767, true);
    }
  }
  downSampleAudioFrame(srcFrame, srcRate, dstRate) {
    if (!srcFrame) {
      return null;
    }
    if (dstRate === srcRate || dstRate > srcRate) {
      return srcFrame;
    }
    const ratio = srcRate / dstRate;
    const dstLength = Math.round(srcFrame.length / ratio);
    const dstFrame = new Float32Array(dstLength);
    let srcOffset = 0;
    let dstOffset = 0;
    while (dstOffset < dstLength) {
      const nextSrcOffset = Math.round((dstOffset + 1) * ratio);
      let accum = 0;
      let count = 0;
      while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {
        accum += srcFrame[srcOffset++];
        count++;
      }
      dstFrame[dstOffset++] = accum / count;
    }
    return dstFrame;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js
var __awaiter2 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var Stream = class {
  constructor(streamId) {
    this.privIsWriteEnded = false;
    this.privIsReadEnded = false;
    this.privId = streamId ? streamId : createNoDashGuid();
    this.privReaderQueue = new Queue();
  }
  get isClosed() {
    return this.privIsWriteEnded;
  }
  get isReadEnded() {
    return this.privIsReadEnded;
  }
  get id() {
    return this.privId;
  }
  close() {
    if (!this.privIsWriteEnded) {
      this.writeStreamChunk({
        buffer: null,
        isEnd: true,
        timeReceived: Date.now()
      });
      this.privIsWriteEnded = true;
    }
  }
  writeStreamChunk(streamChunk) {
    this.throwIfClosed();
    if (!this.privReaderQueue.isDisposed()) {
      try {
        this.privReaderQueue.enqueue(streamChunk);
      } catch (e) {
      }
    }
  }
  read() {
    if (this.privIsReadEnded) {
      throw new InvalidOperationError("Stream read has already finished");
    }
    return this.privReaderQueue.dequeue().then((streamChunk) => __awaiter2(this, void 0, void 0, function* () {
      if (streamChunk === void 0 || streamChunk.isEnd) {
        yield this.privReaderQueue.dispose("End of stream reached");
      }
      return streamChunk;
    }));
  }
  readEnded() {
    if (!this.privIsReadEnded) {
      this.privIsReadEnded = true;
      this.privReaderQueue = new Queue();
    }
  }
  throwIfClosed() {
    if (this.privIsWriteEnded) {
      throw new InvalidOperationError("Stream closed");
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js
var TranslationStatus;
(function(TranslationStatus2) {
  TranslationStatus2[TranslationStatus2["Success"] = 0] = "Success";
  TranslationStatus2[TranslationStatus2["Error"] = 1] = "Error";
})(TranslationStatus || (TranslationStatus = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js
var ChunkedArrayBufferStream = class extends Stream {
  constructor(targetChunkSize, streamId) {
    super(streamId);
    this.privTargetChunkSize = targetChunkSize;
    this.privNextBufferReadyBytes = 0;
  }
  writeStreamChunk(chunk) {
    if (chunk.isEnd || 0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize) {
      super.writeStreamChunk(chunk);
      return;
    }
    let bytesCopiedFromBuffer = 0;
    while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {
      if (void 0 === this.privNextBufferToWrite) {
        this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);
        this.privNextBufferStartTime = chunk.timeReceived;
      }
      const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);
      const targetView = new Uint8Array(this.privNextBufferToWrite);
      const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));
      targetView.set(sourceView, this.privNextBufferReadyBytes);
      this.privNextBufferReadyBytes += bytesToCopy;
      bytesCopiedFromBuffer += bytesToCopy;
      if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {
        super.writeStreamChunk({
          buffer: this.privNextBufferToWrite,
          isEnd: false,
          timeReceived: this.privNextBufferStartTime
        });
        this.privNextBufferReadyBytes = 0;
        this.privNextBufferToWrite = void 0;
      }
    }
  }
  close() {
    if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {
      super.writeStreamChunk({
        buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),
        isEnd: false,
        timeReceived: this.privNextBufferStartTime
      });
    }
    super.close();
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js
var Timeout = class {
  static load() {
    const scheduledTimeoutFunctions = /* @__PURE__ */ new Map([[0, () => {
    }]]);
    const unhandledRequests = /* @__PURE__ */ new Map();
    const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="",n(n.s=14)}([function(e,t,n){"use strict";n.d(t,"a",(function(){return i})),n.d(t,"b",(function(){return u})),n.d(t,"c",(function(){return a})),n.d(t,"d",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id "'.concat(e,'".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id "'.concat(e,'".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if("performance"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o="performance"in self?performance.now():Date.now();o>n?postMessage({id:null,method:"call",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){"use strict";n.r(t);var r=n(2);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)"default"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)"default"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)"default"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)"default"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)"default"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(11);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(0),o=n(1);for(var i in o)"default"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)"default"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener("message",({data:e})=>{try{if("clear"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if("set"!==e.method)throw new Error('The given method "'.concat(e.method,'" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;
    const workerUrl = "data:text/javascript;base64," + btoa(workerScript);
    const worker = new Worker(workerUrl);
    worker.addEventListener("message", ({ data }) => {
      if (Timeout.isCallNotification(data)) {
        const { params: { timerId } } = data;
        const idOrFunc = scheduledTimeoutFunctions.get(timerId);
        if (typeof idOrFunc === "number") {
          const unhandledTimerId = unhandledRequests.get(idOrFunc);
          if (unhandledTimerId === void 0 || unhandledTimerId !== timerId) {
            throw new Error("The timer is in an undefined state.");
          }
        } else if (typeof idOrFunc !== "undefined") {
          idOrFunc();
          scheduledTimeoutFunctions.delete(timerId);
        } else {
          throw new Error("The timer is in an undefined state.");
        }
      } else if (Timeout.isClearResponse(data)) {
        const { id } = data;
        const unhandledTimerId = unhandledRequests.get(id);
        if (unhandledTimerId === void 0) {
          throw new Error("The timer is in an undefined state.");
        }
        unhandledRequests.delete(id);
        scheduledTimeoutFunctions.delete(unhandledTimerId);
      } else {
        const { error: { message } } = data;
        throw new Error(message);
      }
    });
    const clearTimeout2 = (timerId) => {
      const id = Math.random();
      unhandledRequests.set(id, timerId);
      scheduledTimeoutFunctions.set(timerId, id);
      worker.postMessage({
        id,
        method: "clear",
        params: { timerId }
      });
    };
    const setTimeout2 = (func, delay) => {
      const timerId = Math.random();
      scheduledTimeoutFunctions.set(timerId, func);
      worker.postMessage({
        id: null,
        method: "set",
        params: {
          delay,
          now: performance.now(),
          timerId
        }
      });
      return timerId;
    };
    return {
      clearTimeout: clearTimeout2,
      setTimeout: setTimeout2
    };
  }
  static loadWorkerTimers() {
    return () => {
      if (Timeout.workerTimers !== null) {
        return Timeout.workerTimers;
      }
      Timeout.workerTimers = Timeout.load();
      return Timeout.workerTimers;
    };
  }
  static isCallNotification(message) {
    return message.method !== void 0 && message.method === "call";
  }
  static isClearResponse(message) {
    return message.error === null && typeof message.id === "number";
  }
};
Timeout.workerTimers = null;
Timeout.clearTimeout = (timerId) => Timeout.timers().clearTimeout(timerId);
Timeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);
Timeout.timers = Timeout.loadWorkerTimers();

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js
var BackgroundEvent = class extends PlatformEvent {
  constructor(error) {
    super("BackgroundEvent", EventType.Error);
    this.privError = error;
  }
  get error() {
    return this.privError;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js
var Contracts = class {
  static throwIfNullOrUndefined(param, name) {
    if (param === void 0 || param === null) {
      throw new Error("throwIfNullOrUndefined:" + name);
    }
  }
  static throwIfNull(param, name) {
    if (param === null) {
      throw new Error("throwIfNull:" + name);
    }
  }
  static throwIfNullOrWhitespace(param, name) {
    Contracts.throwIfNullOrUndefined(param, name);
    if (("" + param).trim().length < 1) {
      throw new Error("throwIfNullOrWhitespace:" + name);
    }
  }
  static throwIfNullOrTooLong(param, name, maxLength) {
    Contracts.throwIfNullOrUndefined(param, name);
    if (("" + param).length > maxLength) {
      throw new Error("throwIfNullOrTooLong:" + name + " (more than " + maxLength.toString() + " characters)");
    }
  }
  static throwIfNullOrTooShort(param, name, minLength) {
    Contracts.throwIfNullOrUndefined(param, name);
    if (("" + param).length < minLength) {
      throw new Error("throwIfNullOrTooShort:" + name + " (less than " + minLength.toString() + " characters)");
    }
  }
  static throwIfDisposed(isDisposed) {
    if (isDisposed) {
      throw new Error("the object is already disposed");
    }
  }
  static throwIfArrayEmptyOrWhitespace(array, name) {
    Contracts.throwIfNullOrUndefined(array, name);
    if (array.length === 0) {
      throw new Error("throwIfArrayEmptyOrWhitespace:" + name);
    }
    for (const item of array) {
      Contracts.throwIfNullOrWhitespace(item, name);
    }
  }
  static throwIfFileDoesNotExist(param, name) {
    Contracts.throwIfNullOrWhitespace(param, name);
  }
  static throwIfNotUndefined(param, name) {
    if (param !== void 0) {
      throw new Error("throwIfNotUndefined:" + name);
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js
var ConsoleLoggingListener = class {
  constructor(logLevelFilter = EventType.None) {
    this.privLogPath = void 0;
    this.privEnableConsoleOutput = true;
    this.privLogLevelFilter = logLevelFilter;
  }
  set logPath(path) {
    Contracts.throwIfNullOrUndefined(fs.openSync, "\nFile System access not available");
    this.privLogPath = path;
  }
  set enableConsoleOutput(enableOutput) {
    this.privEnableConsoleOutput = enableOutput;
  }
  onEvent(event) {
    if (event.eventType >= this.privLogLevelFilter) {
      const log = this.toString(event);
      if (!!this.privLogPath) {
        fs.writeFileSync(this.privLogPath, log + "\n", { flag: "a+" });
      }
      if (this.privEnableConsoleOutput) {
        switch (event.eventType) {
          case EventType.Debug:
            console.debug(log);
            break;
          case EventType.Info:
            console.info(log);
            break;
          case EventType.Warning:
            console.warn(log);
            break;
          case EventType.Error:
            console.error(log);
            break;
          default:
            console.log(log);
            break;
        }
      }
    }
  }
  toString(event) {
    const logFragments = [
      `${event.eventTime}`,
      `${event.name}`
    ];
    const e = event;
    for (const prop in e) {
      if (prop && event.hasOwnProperty(prop) && prop !== "eventTime" && prop !== "eventType" && prop !== "eventId" && prop !== "name" && prop !== "constructor") {
        const value = e[prop];
        let valueToLog = "<NULL>";
        if (value !== void 0 && value !== null) {
          if (typeof value === "number" || typeof value === "string") {
            valueToLog = value.toString();
          } else {
            valueToLog = JSON.stringify(value);
          }
        }
        logFragments.push(`${prop}: ${valueToLog}`);
      }
    }
    return logFragments.join(" | ");
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js
var HeaderNames = class {
};
HeaderNames.AuthKey = "Ocp-Apim-Subscription-Key";
HeaderNames.Authorization = "Authorization";
HeaderNames.SpIDAuthKey = "Apim-Subscription-Id";
HeaderNames.ConnectionId = "X-ConnectionId";
HeaderNames.ContentType = "Content-Type";
HeaderNames.CustomCommandsAppId = "X-CommandsAppId";
HeaderNames.Path = "Path";
HeaderNames.RequestId = "X-RequestId";
HeaderNames.RequestStreamId = "X-StreamId";
HeaderNames.RequestTimestamp = "X-Timestamp";

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js
var AuthInfo = class {
  constructor(headerName, token) {
    this.privHeaderName = headerName;
    this.privToken = token;
  }
  get headerName() {
    return this.privHeaderName;
  }
  get token() {
    return this.privToken;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js
var CognitiveSubscriptionKeyAuthentication = class {
  /**
   * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.
   * @constructor
   * @param {string} subscriptionKey - The subscription key
   */
  constructor(subscriptionKey) {
    if (!subscriptionKey) {
      throw new ArgumentNullError("subscriptionKey");
    }
    this.privAuthInfo = new AuthInfo(HeaderNames.AuthKey, subscriptionKey);
  }
  /**
   * Fetches the subscription key.
   * @member
   * @function
   * @public
   * @param {string} authFetchEventId - The id to fetch.
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  fetch(authFetchEventId) {
    return Promise.resolve(this.privAuthInfo);
  }
  /**
   * Fetches the subscription key.
   * @member
   * @function
   * @public
   * @param {string} authFetchEventId - The id to fetch.
   */
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  fetchOnExpiry(authFetchEventId) {
    return Promise.resolve(this.privAuthInfo);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js
var CognitiveTokenAuthentication = class {
  constructor(fetchCallback, fetchOnExpiryCallback) {
    if (!fetchCallback) {
      throw new ArgumentNullError("fetchCallback");
    }
    if (!fetchOnExpiryCallback) {
      throw new ArgumentNullError("fetchOnExpiryCallback");
    }
    this.privFetchCallback = fetchCallback;
    this.privFetchOnExpiryCallback = fetchOnExpiryCallback;
  }
  fetch(authFetchEventId) {
    return this.privFetchCallback(authFetchEventId).then((token) => new AuthInfo(HeaderNames.Authorization, token === void 0 ? void 0 : CognitiveTokenAuthentication.privTokenPrefix + token));
  }
  fetchOnExpiry(authFetchEventId) {
    return this.privFetchOnExpiryCallback(authFetchEventId).then((token) => new AuthInfo(HeaderNames.Authorization, token === void 0 ? void 0 : CognitiveTokenAuthentication.privTokenPrefix + token));
  }
};
CognitiveTokenAuthentication.privTokenPrefix = "bearer ";

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js
var fs2 = __toESM(require_fs());
var AudioFileWriter = class {
  constructor(filename) {
    Contracts.throwIfNullOrUndefined(fs2.openSync, "\nFile System access not available, please use Push or PullAudioOutputStream");
    this.privFd = fs2.openSync(filename, "w");
  }
  set format(format) {
    Contracts.throwIfNotUndefined(this.privAudioFormat, "format is already set");
    this.privAudioFormat = format;
    let headerOffset = 0;
    if (this.privAudioFormat.hasHeader) {
      headerOffset = this.privAudioFormat.header.byteLength;
    }
    if (this.privFd !== void 0) {
      this.privWriteStream = fs2.createWriteStream("", { fd: this.privFd, start: headerOffset, autoClose: false });
    }
  }
  write(buffer) {
    Contracts.throwIfNullOrUndefined(this.privAudioFormat, "must set format before writing.");
    if (this.privWriteStream !== void 0) {
      this.privWriteStream.write(new Uint8Array(buffer.slice(0)));
    }
  }
  close() {
    if (this.privFd !== void 0) {
      this.privWriteStream.on("finish", () => {
        if (this.privAudioFormat.hasHeader) {
          this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);
          fs2.writeSync(this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);
        }
        fs2.closeSync(this.privFd);
        this.privFd = void 0;
      });
      this.privWriteStream.end();
    }
  }
  id() {
    return this.privId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js
var AudioFormatTag;
(function(AudioFormatTag2) {
  AudioFormatTag2[AudioFormatTag2["PCM"] = 1] = "PCM";
  AudioFormatTag2[AudioFormatTag2["MuLaw"] = 2] = "MuLaw";
  AudioFormatTag2[AudioFormatTag2["Siren"] = 3] = "Siren";
  AudioFormatTag2[AudioFormatTag2["MP3"] = 4] = "MP3";
  AudioFormatTag2[AudioFormatTag2["SILKSkype"] = 5] = "SILKSkype";
  AudioFormatTag2[AudioFormatTag2["OGG_OPUS"] = 6] = "OGG_OPUS";
  AudioFormatTag2[AudioFormatTag2["WEBM_OPUS"] = 7] = "WEBM_OPUS";
  AudioFormatTag2[AudioFormatTag2["ALaw"] = 8] = "ALaw";
  AudioFormatTag2[AudioFormatTag2["FLAC"] = 9] = "FLAC";
  AudioFormatTag2[AudioFormatTag2["OPUS"] = 10] = "OPUS";
})(AudioFormatTag || (AudioFormatTag = {}));
var AudioStreamFormat = class {
  /**
   * Creates an audio stream format object representing the default audio stream
   * format (16KHz 16bit mono PCM).
   * @member AudioStreamFormat.getDefaultInputFormat
   * @function
   * @public
   * @returns {AudioStreamFormat} The audio stream format being created.
   */
  static getDefaultInputFormat() {
    return AudioStreamFormatImpl.getDefaultInputFormat();
  }
  /**
   * Creates an audio stream format object with the specified format characteristics.
   * @member AudioStreamFormat.getWaveFormat
   * @function
   * @public
   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
   * @param {number} bitsPerSample - Bits per sample, typically 16.
   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
   * uses one channel and stereo data uses two channels.
   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
   * @returns {AudioStreamFormat} The audio stream format being created.
   */
  static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {
    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);
  }
  /**
   * Creates an audio stream format object with the specified pcm waveformat characteristics.
   * @member AudioStreamFormat.getWaveFormatPCM
   * @function
   * @public
   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
   * @param {number} bitsPerSample - Bits per sample, typically 16.
   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
   * uses one channel and stereo data uses two channels.
   * @returns {AudioStreamFormat} The audio stream format being created.
   */
  static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {
    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);
  }
};
var AudioStreamFormatImpl = class extends AudioStreamFormat {
  /**
   * Creates an instance with the given values.
   * @constructor
   * @param {number} samplesPerSec - Samples per second.
   * @param {number} bitsPerSample - Bits per sample.
   * @param {number} channels - Number of channels.
   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
   */
  constructor(samplesPerSec = 16e3, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {
    super();
    let isWavFormat = true;
    switch (format) {
      case AudioFormatTag.PCM:
        this.formatTag = 1;
        break;
      case AudioFormatTag.ALaw:
        this.formatTag = 6;
        break;
      case AudioFormatTag.MuLaw:
        this.formatTag = 7;
        break;
      default:
        isWavFormat = false;
    }
    this.bitsPerSample = bitsPerSample;
    this.samplesPerSec = samplesPerSec;
    this.channels = channels;
    this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);
    this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);
    if (isWavFormat) {
      this.privHeader = new ArrayBuffer(44);
      const view = new DataView(this.privHeader);
      this.setString(view, 0, "RIFF");
      view.setUint32(4, 0, true);
      this.setString(view, 8, "WAVEfmt ");
      view.setUint32(16, 16, true);
      view.setUint16(20, this.formatTag, true);
      view.setUint16(22, this.channels, true);
      view.setUint32(24, this.samplesPerSec, true);
      view.setUint32(28, this.avgBytesPerSec, true);
      view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);
      view.setUint16(34, this.bitsPerSample, true);
      this.setString(view, 36, "data");
      view.setUint32(40, 0, true);
    }
  }
  /**
   * Retrieves the default input format.
   * @member AudioStreamFormatImpl.getDefaultInputFormat
   * @function
   * @public
   * @returns {AudioStreamFormatImpl} The default input format.
   */
  static getDefaultInputFormat() {
    return new AudioStreamFormatImpl();
  }
  /**
   * Creates an audio context appropriate to current browser
   * @member AudioStreamFormatImpl.getAudioContext
   * @function
   * @public
   * @returns {AudioContext} An audio context instance
   */
  /* eslint-disable */
  static getAudioContext(sampleRate) {
    const AudioContext2 = window.AudioContext || window.webkitAudioContext || false;
    if (!!AudioContext2) {
      if (sampleRate !== void 0 && navigator.mediaDevices.getSupportedConstraints().sampleRate) {
        return new AudioContext2({ sampleRate });
      } else {
        return new AudioContext2();
      }
    } else {
      throw new Error("Browser does not support Web Audio API (AudioContext is not available).");
    }
  }
  /* eslint-enable */
  /**
   * Closes the configuration object.
   * @member AudioStreamFormatImpl.prototype.close
   * @function
   * @public
   */
  close() {
    return;
  }
  get header() {
    return this.privHeader;
  }
  setString(view, offset, str) {
    for (let i = 0; i < str.length; i++) {
      view.setUint8(offset + i, str.charCodeAt(i));
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js
var __awaiter3 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var AudioInputStream = class {
  /**
   * Creates and initializes an instance.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Creates a memory backed PushAudioInputStream with the specified audio format.
   * @member AudioInputStream.createPushStream
   * @function
   * @public
   * @param {AudioStreamFormat} format - The audio data format in which audio will be
   * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PushAudioInputStream} The audio input stream being created.
   */
  static createPushStream(format) {
    return PushAudioInputStream.create(format);
  }
  /**
   * Creates a PullAudioInputStream that delegates to the specified callback interface for read()
   * and close() methods.
   * @member AudioInputStream.createPullStream
   * @function
   * @public
   * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from
   * PullAudioInputStreamCallback
   * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from
   * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PullAudioInputStream} The audio input stream being created.
   */
  static createPullStream(callback, format) {
    return PullAudioInputStream.create(callback, format);
  }
};
var PushAudioInputStream = class extends AudioInputStream {
  /**
   * Creates a memory backed PushAudioInputStream with the specified audio format.
   * @member PushAudioInputStream.create
   * @function
   * @public
   * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the
   * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PushAudioInputStream} The push audio input stream being created.
   */
  static create(format) {
    return new PushAudioInputStreamImpl(format);
  }
};
var PushAudioInputStreamImpl = class extends PushAudioInputStream {
  /**
   * Creates and initalizes an instance with the given values.
   * @constructor
   * @param {AudioStreamFormat} format - The audio stream format.
   */
  constructor(format) {
    super();
    if (format === void 0) {
      this.privFormat = AudioStreamFormatImpl.getDefaultInputFormat();
    } else {
      this.privFormat = format;
    }
    this.privEvents = new EventSource();
    this.privId = createNoDashGuid();
    this.privStream = new ChunkedArrayBufferStream(this.privFormat.avgBytesPerSec / 10);
  }
  /**
   * Format information for the audio
   */
  get format() {
    return Promise.resolve(this.privFormat);
  }
  /**
   * Writes the audio data specified by making an internal copy of the data.
   * @member PushAudioInputStreamImpl.prototype.write
   * @function
   * @public
   * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
   */
  write(dataBuffer) {
    this.privStream.writeStreamChunk({
      buffer: dataBuffer,
      isEnd: false,
      timeReceived: Date.now()
    });
  }
  /**
   * Closes the stream.
   * @member PushAudioInputStreamImpl.prototype.close
   * @function
   * @public
   */
  close() {
    this.privStream.close();
  }
  id() {
    return this.privId;
  }
  turnOn() {
    this.onEvent(new AudioSourceInitializingEvent(this.privId));
    this.onEvent(new AudioSourceReadyEvent(this.privId));
    return;
  }
  attach(audioNodeId) {
    return __awaiter3(this, void 0, void 0, function* () {
      this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
      yield this.turnOn();
      const stream = this.privStream;
      this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return {
        detach: () => __awaiter3(this, void 0, void 0, function* () {
          this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          return this.turnOff();
        }),
        id: () => audioNodeId,
        read: () => stream.read()
      };
    });
  }
  detach(audioNodeId) {
    this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
  }
  turnOff() {
    return;
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return Promise.resolve({
      bitspersample: this.privFormat.bitsPerSample,
      channelcount: this.privFormat.channels,
      connectivity: connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: "PushStream",
      samplerate: this.privFormat.samplesPerSec,
      type: type.Stream
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    Events.instance.onEvent(event);
  }
  toBuffer(arrayBuffer) {
    const buf = Buffer.alloc(arrayBuffer.byteLength);
    const view = new Uint8Array(arrayBuffer);
    for (let i = 0; i < buf.length; ++i) {
      buf[i] = view[i];
    }
    return buf;
  }
};
var PullAudioInputStream = class extends AudioInputStream {
  /**
   * Creates and initializes and instance.
   * @constructor
   */
  constructor() {
    super();
  }
  /**
   * Creates a PullAudioInputStream that delegates to the specified callback interface for
   * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
   * @member PullAudioInputStream.create
   * @function
   * @public
   * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
   * derived from PullAudioInputStreamCustomCallback
   * @param {AudioStreamFormat} format - The audio data format in which audio will be
   * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
   * @returns {PullAudioInputStream} The push audio input stream being created.
   */
  static create(callback, format) {
    return new PullAudioInputStreamImpl(callback, format);
  }
};
var PullAudioInputStreamImpl = class extends PullAudioInputStream {
  /**
   * Creates a PullAudioInputStream that delegates to the specified callback interface for
   * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
   * @constructor
   * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
   * derived from PullAudioInputStreamCustomCallback
   * @param {AudioStreamFormat} format - The audio data format in which audio will be
   * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
   */
  constructor(callback, format) {
    super();
    if (void 0 === format) {
      this.privFormat = AudioStreamFormat.getDefaultInputFormat();
    } else {
      this.privFormat = format;
    }
    this.privEvents = new EventSource();
    this.privId = createNoDashGuid();
    this.privCallback = callback;
    this.privIsClosed = false;
    this.privBufferSize = this.privFormat.avgBytesPerSec / 10;
  }
  /**
   * Format information for the audio
   */
  get format() {
    return Promise.resolve(this.privFormat);
  }
  /**
   * Closes the stream.
   * @member PullAudioInputStreamImpl.prototype.close
   * @function
   * @public
   */
  close() {
    this.privIsClosed = true;
    this.privCallback.close();
  }
  id() {
    return this.privId;
  }
  turnOn() {
    this.onEvent(new AudioSourceInitializingEvent(this.privId));
    this.onEvent(new AudioSourceReadyEvent(this.privId));
    return;
  }
  attach(audioNodeId) {
    return __awaiter3(this, void 0, void 0, function* () {
      this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
      yield this.turnOn();
      this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return {
        detach: () => {
          this.privCallback.close();
          this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          return this.turnOff();
        },
        id: () => audioNodeId,
        read: () => {
          let totalBytes = 0;
          let transmitBuff;
          while (totalBytes < this.privBufferSize) {
            const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);
            const pulledBytes = this.privCallback.read(readBuff);
            if (void 0 === transmitBuff) {
              transmitBuff = readBuff;
            } else {
              const intView = new Int8Array(transmitBuff);
              intView.set(new Int8Array(readBuff), totalBytes);
            }
            if (0 === pulledBytes) {
              break;
            }
            totalBytes += pulledBytes;
          }
          return Promise.resolve({
            buffer: transmitBuff.slice(0, totalBytes),
            isEnd: this.privIsClosed || totalBytes === 0,
            timeReceived: Date.now()
          });
        }
      };
    });
  }
  detach(audioNodeId) {
    this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
  }
  turnOff() {
    return;
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return Promise.resolve({
      bitspersample: this.privFormat.bitsPerSample,
      channelcount: this.privFormat.channels,
      connectivity: connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: "PullStream",
      samplerate: this.privFormat.samplesPerSec,
      type: type.Stream
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    Events.instance.onEvent(event);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js
var SpeechSynthesisOutputFormat;
(function(SpeechSynthesisOutputFormat2) {
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw8Khz8BitMonoMULaw"] = 0] = "Raw8Khz8BitMonoMULaw";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff16Khz16KbpsMonoSiren"] = 1] = "Riff16Khz16KbpsMonoSiren";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio16Khz16KbpsMonoSiren"] = 2] = "Audio16Khz16KbpsMonoSiren";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio16Khz32KBitRateMonoMp3"] = 3] = "Audio16Khz32KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio16Khz128KBitRateMonoMp3"] = 4] = "Audio16Khz128KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio16Khz64KBitRateMonoMp3"] = 5] = "Audio16Khz64KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio24Khz48KBitRateMonoMp3"] = 6] = "Audio24Khz48KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio24Khz96KBitRateMonoMp3"] = 7] = "Audio24Khz96KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio24Khz160KBitRateMonoMp3"] = 8] = "Audio24Khz160KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw16Khz16BitMonoTrueSilk"] = 9] = "Raw16Khz16BitMonoTrueSilk";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff16Khz16BitMonoPcm"] = 10] = "Riff16Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff8Khz16BitMonoPcm"] = 11] = "Riff8Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff24Khz16BitMonoPcm"] = 12] = "Riff24Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff8Khz8BitMonoMULaw"] = 13] = "Riff8Khz8BitMonoMULaw";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw16Khz16BitMonoPcm"] = 14] = "Raw16Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw24Khz16BitMonoPcm"] = 15] = "Raw24Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw8Khz16BitMonoPcm"] = 16] = "Raw8Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Ogg16Khz16BitMonoOpus"] = 17] = "Ogg16Khz16BitMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Ogg24Khz16BitMonoOpus"] = 18] = "Ogg24Khz16BitMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw48Khz16BitMonoPcm"] = 19] = "Raw48Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff48Khz16BitMonoPcm"] = 20] = "Riff48Khz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio48Khz96KBitRateMonoMp3"] = 21] = "Audio48Khz96KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio48Khz192KBitRateMonoMp3"] = 22] = "Audio48Khz192KBitRateMonoMp3";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Ogg48Khz16BitMonoOpus"] = 23] = "Ogg48Khz16BitMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Webm16Khz16BitMonoOpus"] = 24] = "Webm16Khz16BitMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Webm24Khz16BitMonoOpus"] = 25] = "Webm24Khz16BitMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw24Khz16BitMonoTrueSilk"] = 26] = "Raw24Khz16BitMonoTrueSilk";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw8Khz8BitMonoALaw"] = 27] = "Raw8Khz8BitMonoALaw";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff8Khz8BitMonoALaw"] = 28] = "Riff8Khz8BitMonoALaw";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Webm24Khz16Bit24KbpsMonoOpus"] = 29] = "Webm24Khz16Bit24KbpsMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio16Khz16Bit32KbpsMonoOpus"] = 30] = "Audio16Khz16Bit32KbpsMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio24Khz16Bit48KbpsMonoOpus"] = 31] = "Audio24Khz16Bit48KbpsMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Audio24Khz16Bit24KbpsMonoOpus"] = 32] = "Audio24Khz16Bit24KbpsMonoOpus";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw22050Hz16BitMonoPcm"] = 33] = "Raw22050Hz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff22050Hz16BitMonoPcm"] = 34] = "Riff22050Hz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Raw44100Hz16BitMonoPcm"] = 35] = "Raw44100Hz16BitMonoPcm";
  SpeechSynthesisOutputFormat2[SpeechSynthesisOutputFormat2["Riff44100Hz16BitMonoPcm"] = 36] = "Riff44100Hz16BitMonoPcm";
})(SpeechSynthesisOutputFormat || (SpeechSynthesisOutputFormat = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js
var AudioOutputFormatImpl = class extends AudioStreamFormatImpl {
  /**
   * Creates an instance with the given values.
   * @constructor
   * @param formatTag
   * @param {number} channels - Number of channels.
   * @param {number} samplesPerSec - Samples per second.
   * @param {number} avgBytesPerSec - Average bytes per second.
   * @param {number} blockAlign - Block alignment.
   * @param {number} bitsPerSample - Bits per sample.
   * @param {string} audioFormatString - Audio format string
   * @param {string} requestAudioFormatString - Audio format string sent to service.
   * @param {boolean} hasHeader - If the format has header or not.
   */
  constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {
    super(samplesPerSec, bitsPerSample, channels, formatTag);
    this.formatTag = formatTag;
    this.avgBytesPerSec = avgBytesPerSec;
    this.blockAlign = blockAlign;
    this.priAudioFormatString = audioFormatString;
    this.priRequestAudioFormatString = requestAudioFormatString;
    this.priHasHeader = hasHeader;
  }
  static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {
    if (speechSynthesisOutputFormat === void 0) {
      return AudioOutputFormatImpl.getDefaultOutputFormat();
    }
    return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);
  }
  static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {
    switch (speechSynthesisOutputFormatString) {
      case "raw-8khz-8bit-mono-mulaw":
        return new AudioOutputFormatImpl(AudioFormatTag.MuLaw, 1, 8e3, 8e3, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-16khz-16kbps-mono-siren":
        return new AudioOutputFormatImpl(AudioFormatTag.Siren, 1, 16e3, 2e3, 40, 0, speechSynthesisOutputFormatString, "audio-16khz-16kbps-mono-siren", true);
      case "audio-16khz-16kbps-mono-siren":
        return new AudioOutputFormatImpl(AudioFormatTag.Siren, 1, 16e3, 2e3, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-32kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 16e3, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-128kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 16e3, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-64kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 16e3, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-48kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 24e3, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-96kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 24e3, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-160kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 24e3, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-16khz-16bit-mono-truesilk":
        return new AudioOutputFormatImpl(AudioFormatTag.SILKSkype, 1, 16e3, 32e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-8khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 8e3, 16e3, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", true);
      case "riff-24khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 24e3, 48e3, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", true);
      case "riff-8khz-8bit-mono-mulaw":
        return new AudioOutputFormatImpl(AudioFormatTag.MuLaw, 1, 8e3, 8e3, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-mulaw", true);
      case "raw-16khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 16e3, 32e3, 2, 16, speechSynthesisOutputFormatString, "raw-16khz-16bit-mono-pcm", false);
      case "raw-24khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 24e3, 48e3, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", false);
      case "raw-8khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 8e3, 16e3, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", false);
      case "ogg-16khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.OGG_OPUS, 1, 16e3, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "ogg-24khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.OGG_OPUS, 1, 24e3, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-48khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 48e3, 96e3, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", false);
      case "riff-48khz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 48e3, 96e3, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", true);
      case "audio-48khz-96kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 48e3, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-48khz-192kbitrate-mono-mp3":
        return new AudioOutputFormatImpl(AudioFormatTag.MP3, 1, 48e3, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "ogg-48khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.OGG_OPUS, 1, 48e3, 12e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "webm-16khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.WEBM_OPUS, 1, 16e3, 4e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "webm-24khz-16bit-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.WEBM_OPUS, 1, 24e3, 6e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "webm-24khz-16bit-24kbps-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.WEBM_OPUS, 1, 24e3, 3e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-16khz-16bit-32kbps-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.OPUS, 1, 16e3, 4e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-16bit-48kbps-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.OPUS, 1, 24e3, 6e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-16bit-24kbps-mono-opus":
        return new AudioOutputFormatImpl(AudioFormatTag.OPUS, 1, 24e3, 3e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-24khz-16bit-mono-flac":
        return new AudioOutputFormatImpl(AudioFormatTag.FLAC, 1, 24e3, 24e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "audio-48khz-16bit-mono-flac":
        return new AudioOutputFormatImpl(AudioFormatTag.FLAC, 1, 48e3, 3e4, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-24khz-16bit-mono-truesilk":
        return new AudioOutputFormatImpl(AudioFormatTag.SILKSkype, 1, 24e3, 48e3, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "raw-8khz-8bit-mono-alaw":
        return new AudioOutputFormatImpl(AudioFormatTag.ALaw, 1, 8e3, 8e3, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-8khz-8bit-mono-alaw":
        return new AudioOutputFormatImpl(AudioFormatTag.ALaw, 1, 8e3, 8e3, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-alaw", true);
      case "raw-22050hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-22050hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, "raw-22050hz-16bit-mono-pcm", true);
      case "raw-44100hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
      case "riff-44100hz-16bit-mono-pcm":
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, "raw-44100hz-16bit-mono-pcm", true);
      case "riff-16khz-16bit-mono-pcm":
      default:
        return new AudioOutputFormatImpl(AudioFormatTag.PCM, 1, 16e3, 32e3, 2, 16, "riff-16khz-16bit-mono-pcm", "raw-16khz-16bit-mono-pcm", true);
    }
  }
  static getDefaultOutputFormat() {
    return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(typeof window !== "undefined" ? "audio-24khz-48kbitrate-mono-mp3" : "riff-16khz-16bit-mono-pcm");
  }
  /**
   * Specifies if this audio output format has a header
   * @boolean AudioOutputFormatImpl.prototype.hasHeader
   * @function
   * @public
   */
  get hasHeader() {
    return this.priHasHeader;
  }
  /**
   * Specifies the header of this format
   * @ArrayBuffer AudioOutputFormatImpl.prototype.header
   * @function
   * @public
   */
  get header() {
    if (this.hasHeader) {
      return this.privHeader;
    }
    return void 0;
  }
  /**
   * Updates the header based on the audio length
   * @member AudioOutputFormatImpl.updateHeader
   * @function
   * @public
   * @param {number} audioLength - the audio length
   */
  updateHeader(audioLength) {
    if (this.priHasHeader) {
      const view = new DataView(this.privHeader);
      view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);
      view.setUint32(40, audioLength, true);
    }
  }
  /**
   * Specifies the audio format string to be sent to the service
   * @string AudioOutputFormatImpl.prototype.requestAudioFormatString
   * @function
   * @public
   */
  get requestAudioFormatString() {
    return this.priRequestAudioFormatString;
  }
};
AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {
  [SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw]: "raw-8khz-8bit-mono-mulaw",
  [SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren]: "riff-16khz-16kbps-mono-siren",
  [SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren]: "audio-16khz-16kbps-mono-siren",
  [SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3]: "audio-16khz-32kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3]: "audio-16khz-128kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3]: "audio-16khz-64kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3]: "audio-24khz-48kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3]: "audio-24khz-96kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3]: "audio-24khz-160kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk]: "raw-16khz-16bit-mono-truesilk",
  [SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm]: "riff-16khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm]: "riff-8khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm]: "riff-24khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw]: "riff-8khz-8bit-mono-mulaw",
  [SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm]: "raw-16khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm]: "raw-24khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm]: "raw-8khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus]: "ogg-16khz-16bit-mono-opus",
  [SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus]: "ogg-24khz-16bit-mono-opus",
  [SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm]: "raw-48khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm]: "riff-48khz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3]: "audio-48khz-96kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3]: "audio-48khz-192kbitrate-mono-mp3",
  [SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus]: "ogg-48khz-16bit-mono-opus",
  [SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus]: "webm-16khz-16bit-mono-opus",
  [SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus]: "webm-24khz-16bit-mono-opus",
  [SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus]: "webm-24khz-16bit-24kbps-mono-opus",
  [SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk]: "raw-24khz-16bit-mono-truesilk",
  [SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw]: "raw-8khz-8bit-mono-alaw",
  [SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw]: "riff-8khz-8bit-mono-alaw",
  [SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus]: "audio-16khz-16bit-32kbps-mono-opus",
  [SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus]: "audio-24khz-16bit-48kbps-mono-opus",
  [SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus]: "audio-24khz-16bit-24kbps-mono-opus",
  [SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm]: "raw-22050hz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm]: "riff-22050hz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm]: "raw-44100hz-16bit-mono-pcm",
  [SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm]: "riff-44100hz-16bit-mono-pcm"
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js
var __awaiter4 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var AudioOutputStream = class {
  /**
   * Creates and initializes an instance.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Creates a memory backed PullAudioOutputStream with the specified audio format.
   * @member AudioOutputStream.createPullStream
   * @function
   * @public
   * @returns {PullAudioOutputStream} The audio output stream being created.
   */
  static createPullStream() {
    return PullAudioOutputStream.create();
  }
};
var PullAudioOutputStream = class extends AudioOutputStream {
  /**
   * Creates a memory backed PullAudioOutputStream with the specified audio format.
   * @member PullAudioOutputStream.create
   * @function
   * @public
   * @returns {PullAudioOutputStream} The push audio output stream being created.
   */
  static create() {
    return new PullAudioOutputStreamImpl();
  }
};
var PullAudioOutputStreamImpl = class extends PullAudioOutputStream {
  /**
   * Creates and initializes an instance with the given values.
   * @constructor
   */
  constructor() {
    super();
    this.privId = createNoDashGuid();
    this.privStream = new Stream();
  }
  /**
   * Sets the format information to the stream. For internal use only.
   * @param {AudioStreamFormat} format - the format to be set.
   */
  set format(format) {
    if (format === void 0 || format === null) {
      this.privFormat = AudioOutputFormatImpl.getDefaultOutputFormat();
    }
    this.privFormat = format;
  }
  /**
   * Format information for the audio
   */
  get format() {
    return this.privFormat;
  }
  /**
   * Checks if the stream is closed
   * @member PullAudioOutputStreamImpl.prototype.isClosed
   * @property
   * @public
   */
  get isClosed() {
    return this.privStream.isClosed;
  }
  /**
   * Gets the id of the stream
   * @member PullAudioOutputStreamImpl.prototype.id
   * @property
   * @public
   */
  id() {
    return this.privId;
  }
  /**
   * Reads audio data from the internal buffer.
   * @member PullAudioOutputStreamImpl.prototype.read
   * @function
   * @public
   * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.
   * @returns {Promise<number>} - Audio buffer length has been read.
   */
  read(dataBuffer) {
    return __awaiter4(this, void 0, void 0, function* () {
      const intView = new Int8Array(dataBuffer);
      let totalBytes = 0;
      if (this.privLastChunkView !== void 0) {
        if (this.privLastChunkView.length > dataBuffer.byteLength) {
          intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));
          this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);
          return Promise.resolve(dataBuffer.byteLength);
        }
        intView.set(this.privLastChunkView);
        totalBytes = this.privLastChunkView.length;
        this.privLastChunkView = void 0;
      }
      while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {
        const chunk = yield this.privStream.read();
        if (chunk !== void 0 && !chunk.isEnd) {
          let tmpBuffer;
          if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {
            tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);
            this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));
          } else {
            tmpBuffer = chunk.buffer;
          }
          intView.set(new Int8Array(tmpBuffer), totalBytes);
          totalBytes += tmpBuffer.byteLength;
        } else {
          this.privStream.readEnded();
        }
      }
      return totalBytes;
    });
  }
  /**
   * Writes the audio data specified by making an internal copy of the data.
   * @member PullAudioOutputStreamImpl.prototype.write
   * @function
   * @public
   * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
   */
  write(dataBuffer) {
    Contracts.throwIfNullOrUndefined(this.privStream, "must set format before writing");
    this.privStream.writeStreamChunk({
      buffer: dataBuffer,
      isEnd: false,
      timeReceived: Date.now()
    });
  }
  /**
   * Closes the stream.
   * @member PullAudioOutputStreamImpl.prototype.close
   * @function
   * @public
   */
  close() {
    this.privStream.close();
  }
};
var PushAudioOutputStream = class extends AudioOutputStream {
  /**
   * Creates and initializes and instance.
   * @constructor
   */
  constructor() {
    super();
  }
  /**
   * Creates a PushAudioOutputStream that delegates to the specified callback interface for
   * write() and close() methods.
   * @member PushAudioOutputStream.create
   * @function
   * @public
   * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
   * derived from PushAudioOutputStreamCallback
   * @returns {PushAudioOutputStream} The push audio output stream being created.
   */
  static create(callback) {
    return new PushAudioOutputStreamImpl(callback);
  }
};
var PushAudioOutputStreamImpl = class extends PushAudioOutputStream {
  /**
   * Creates a PushAudioOutputStream that delegates to the specified callback interface for
   * read() and close() methods.
   * @constructor
   * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
   * derived from PushAudioOutputStreamCallback
   */
  constructor(callback) {
    super();
    this.privId = createNoDashGuid();
    this.privCallback = callback;
  }
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  set format(format) {
  }
  write(buffer) {
    if (!!this.privCallback.write) {
      this.privCallback.write(buffer);
    }
  }
  close() {
    if (!!this.privCallback.close) {
      this.privCallback.close();
    }
  }
  id() {
    return this.privId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js
var AudioConfig = class {
  /**
   * Creates an AudioConfig object representing the default microphone on the system.
   * @member AudioConfig.fromDefaultMicrophoneInput
   * @function
   * @public
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromDefaultMicrophoneInput() {
    const pcmRecorder = new PcmRecorder(true);
    return new AudioConfigImpl(new MicAudioSource(pcmRecorder));
  }
  /**
   * Creates an AudioConfig object representing a microphone with the specified device ID.
   * @member AudioConfig.fromMicrophoneInput
   * @function
   * @public
   * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.
   * Default microphone is used the value is omitted.
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromMicrophoneInput(deviceId) {
    const pcmRecorder = new PcmRecorder(true);
    return new AudioConfigImpl(new MicAudioSource(pcmRecorder, deviceId));
  }
  /**
   * Creates an AudioConfig object representing the specified file.
   * @member AudioConfig.fromWavFileInput
   * @function
   * @public
   * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromWavFileInput(file, name = "unnamedBuffer.wav") {
    return new AudioConfigImpl(new FileAudioSource(file, name));
  }
  /**
   * Creates an AudioConfig object representing the specified stream.
   * @member AudioConfig.fromStreamInput
   * @function
   * @public
   * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input
   * stream. Currently, only WAV / PCM is supported.
   * @returns {AudioConfig} The audio input configuration being created.
   */
  static fromStreamInput(audioStream) {
    if (audioStream instanceof PullAudioInputStreamCallback) {
      return new AudioConfigImpl(new PullAudioInputStreamImpl(audioStream));
    }
    if (audioStream instanceof AudioInputStream) {
      return new AudioConfigImpl(audioStream);
    }
    if (typeof MediaStream !== "undefined" && audioStream instanceof MediaStream) {
      const pcmRecorder = new PcmRecorder(false);
      return new AudioConfigImpl(new MicAudioSource(pcmRecorder, null, null, audioStream));
    }
    throw new Error("Not Supported Type");
  }
  /**
   * Creates an AudioConfig object representing the default speaker.
   * @member AudioConfig.fromDefaultSpeakerOutput
   * @function
   * @public
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.11.0
   */
  static fromDefaultSpeakerOutput() {
    return new AudioOutputConfigImpl(new SpeakerAudioDestination());
  }
  /**
   * Creates an AudioConfig object representing the custom IPlayer object.
   * You can use the IPlayer object to control pause, resume, etc.
   * @member AudioConfig.fromSpeakerOutput
   * @function
   * @public
   * @param {IPlayer} player - the IPlayer object for playback.
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.12.0
   */
  static fromSpeakerOutput(player) {
    if (player === void 0) {
      return AudioConfig.fromDefaultSpeakerOutput();
    }
    if (player instanceof SpeakerAudioDestination) {
      return new AudioOutputConfigImpl(player);
    }
    throw new Error("Not Supported Type");
  }
  /**
   * Creates an AudioConfig object representing a specified output audio file
   * @member AudioConfig.fromAudioFileOutput
   * @function
   * @public
   * @param {PathLike} filename - the filename of the output audio file
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.11.0
   */
  static fromAudioFileOutput(filename) {
    return new AudioOutputConfigImpl(new AudioFileWriter(filename));
  }
  /**
   * Creates an AudioConfig object representing a specified audio output stream
   * @member AudioConfig.fromStreamOutput
   * @function
   * @public
   * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output
   * stream.
   * @returns {AudioConfig} The audio output configuration being created.
   * Added in version 1.11.0
   */
  static fromStreamOutput(audioStream) {
    if (audioStream instanceof PushAudioOutputStreamCallback) {
      return new AudioOutputConfigImpl(new PushAudioOutputStreamImpl(audioStream));
    }
    if (audioStream instanceof PushAudioOutputStream) {
      return new AudioOutputConfigImpl(audioStream);
    }
    if (audioStream instanceof PullAudioOutputStream) {
      return new AudioOutputConfigImpl(audioStream);
    }
    throw new Error("Not Supported Type");
  }
};
var AudioConfigImpl = class extends AudioConfig {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {IAudioSource} source - An audio source.
   */
  constructor(source) {
    super();
    this.privSource = source;
  }
  /**
   * Format information for the audio
   */
  get format() {
    return this.privSource.format;
  }
  /**
   * @member AudioConfigImpl.prototype.close
   * @function
   * @public
   */
  close(cb, err) {
    this.privSource.turnOff().then(() => {
      if (!!cb) {
        cb();
      }
    }, (error) => {
      if (!!err) {
        err(error);
      }
    });
  }
  /**
   * @member AudioConfigImpl.prototype.id
   * @function
   * @public
   */
  id() {
    return this.privSource.id();
  }
  /**
   * @member AudioConfigImpl.prototype.turnOn
   * @function
   * @public
   * @returns {Promise<void>} A promise.
   */
  turnOn() {
    return this.privSource.turnOn();
  }
  /**
   * @member AudioConfigImpl.prototype.attach
   * @function
   * @public
   * @param {string} audioNodeId - The audio node id.
   * @returns {Promise<IAudioStreamNode>} A promise.
   */
  attach(audioNodeId) {
    return this.privSource.attach(audioNodeId);
  }
  /**
   * @member AudioConfigImpl.prototype.detach
   * @function
   * @public
   * @param {string} audioNodeId - The audio node id.
   */
  detach(audioNodeId) {
    return this.privSource.detach(audioNodeId);
  }
  /**
   * @member AudioConfigImpl.prototype.turnOff
   * @function
   * @public
   * @returns {Promise<void>} A promise.
   */
  turnOff() {
    return this.privSource.turnOff();
  }
  /**
   * @member AudioConfigImpl.prototype.events
   * @function
   * @public
   * @returns {EventSource<AudioSourceEvent>} An event source for audio events.
   */
  get events() {
    return this.privSource.events;
  }
  setProperty(name, value) {
    Contracts.throwIfNull(value, "value");
    if (void 0 !== this.privSource.setProperty) {
      this.privSource.setProperty(name, value);
    } else {
      throw new Error("This AudioConfig instance does not support setting properties.");
    }
  }
  getProperty(name, def) {
    if (void 0 !== this.privSource.getProperty) {
      return this.privSource.getProperty(name, def);
    } else {
      throw new Error("This AudioConfig instance does not support getting properties.");
    }
    return def;
  }
  get deviceInfo() {
    return this.privSource.deviceInfo;
  }
};
var AudioOutputConfigImpl = class extends AudioConfig {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {IAudioDestination} destination - An audio destination.
   */
  constructor(destination) {
    super();
    this.privDestination = destination;
  }
  set format(format) {
    this.privDestination.format = format;
  }
  write(buffer) {
    this.privDestination.write(buffer);
  }
  close() {
    this.privDestination.close();
  }
  id() {
    return this.privDestination.id();
  }
  setProperty() {
    throw new Error("This AudioConfig instance does not support setting properties.");
  }
  getProperty() {
    throw new Error("This AudioConfig instance does not support getting properties.");
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js
var CancellationReason;
(function(CancellationReason2) {
  CancellationReason2[CancellationReason2["Error"] = 0] = "Error";
  CancellationReason2[CancellationReason2["EndOfStream"] = 1] = "EndOfStream";
})(CancellationReason || (CancellationReason = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js
var PullAudioInputStreamCallback = class {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js
var PushAudioOutputStreamCallback = class {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js
var KeywordRecognitionModel = class {
  /**
   * Create and initializes a new instance.
   * @constructor
   */
  constructor() {
    this.privDisposed = false;
    return;
  }
  /**
   * Creates a keyword recognition model using the specified filename.
   * @member KeywordRecognitionModel.fromFile
   * @function
   * @public
   * @param {string} fileName - A string that represents file name for the keyword recognition model.
   * Note, the file can point to a zip file in which case the model
   * will be extracted from the zip.
   * @returns {KeywordRecognitionModel} The keyword recognition model being created.
   */
  static fromFile(fileName) {
    Contracts.throwIfFileDoesNotExist(fileName, "fileName");
    throw new Error("Not yet implemented.");
  }
  /**
   * Creates a keyword recognition model using the specified filename.
   * @member KeywordRecognitionModel.fromStream
   * @function
   * @public
   * @param {string} file - A File that represents file for the keyword recognition model.
   * Note, the file can point to a zip file in which case the model will be extracted from the zip.
   * @returns {KeywordRecognitionModel} The keyword recognition model being created.
   */
  static fromStream(file) {
    Contracts.throwIfNull(file, "file");
    throw new Error("Not yet implemented.");
  }
  /**
   * Dispose of associated resources.
   * @member KeywordRecognitionModel.prototype.close
   * @function
   * @public
   */
  close() {
    if (this.privDisposed) {
      return;
    }
    this.privDisposed = true;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js
var SessionEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} sessionId - The session id.
   */
  constructor(sessionId) {
    this.privSessionId = sessionId;
  }
  /**
   * Represents the session identifier.
   * @member SessionEventArgs.prototype.sessionId
   * @function
   * @public
   * @returns {string} Represents the session identifier.
   */
  get sessionId() {
    return this.privSessionId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js
var RecognitionEventArgs = class extends SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(offset, sessionId) {
    super(sessionId);
    this.privOffset = offset;
  }
  /**
   * Represents the message offset
   * @member RecognitionEventArgs.prototype.offset
   * @function
   * @public
   */
  get offset() {
    return this.privOffset;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js
var OutputFormat;
(function(OutputFormat2) {
  OutputFormat2[OutputFormat2["Simple"] = 0] = "Simple";
  OutputFormat2[OutputFormat2["Detailed"] = 1] = "Detailed";
})(OutputFormat || (OutputFormat = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js
var IntentRecognitionEventArgs = class extends RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param result - The result of the intent recognition.
   * @param offset - The offset.
   * @param sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Represents the intent recognition result.
   * @member IntentRecognitionEventArgs.prototype.result
   * @function
   * @public
   * @returns {IntentRecognitionResult} Represents the intent recognition result.
   */
  get result() {
    return this.privResult;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js
var RecognitionResult = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} text - The recognized text.
   * @param {number} duration - The duration.
   * @param {number} offset - The offset into the stream.
   * @param {string} language - Primary Language detected, if provided.
   * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param {string} errorDetails - Error details, if provided.
   * @param {string} json - Additional Json, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
    this.privResultId = resultId;
    this.privReason = reason;
    this.privText = text;
    this.privDuration = duration;
    this.privOffset = offset;
    this.privLanguage = language;
    this.privLanguageDetectionConfidence = languageDetectionConfidence;
    this.privErrorDetails = errorDetails;
    this.privJson = json;
    this.privProperties = properties;
  }
  /**
   * Specifies the result identifier.
   * @member RecognitionResult.prototype.resultId
   * @function
   * @public
   * @returns {string} Specifies the result identifier.
   */
  get resultId() {
    return this.privResultId;
  }
  /**
   * Specifies status of the result.
   * @member RecognitionResult.prototype.reason
   * @function
   * @public
   * @returns {ResultReason} Specifies status of the result.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * Presents the recognized text in the result.
   * @member RecognitionResult.prototype.text
   * @function
   * @public
   * @returns {string} Presents the recognized text in the result.
   */
  get text() {
    return this.privText;
  }
  /**
   * Duration of recognized speech in 100 nano second increments.
   * @member RecognitionResult.prototype.duration
   * @function
   * @public
   * @returns {number} Duration of recognized speech in 100 nano second increments.
   */
  get duration() {
    return this.privDuration;
  }
  /**
   * Offset of recognized speech in 100 nano second increments.
   * @member RecognitionResult.prototype.offset
   * @function
   * @public
   * @returns {number} Offset of recognized speech in 100 nano second increments.
   */
  get offset() {
    return this.privOffset;
  }
  /**
   * Primary Language detected.
   * @member RecognitionResult.prototype.language
   * @function
   * @public
   * @returns {string} language detected.
   */
  get language() {
    return this.privLanguage;
  }
  /**
   * Primary Language detection confidence (Unknown, Low, Medium, High).
   * @member RecognitionResult.prototype.languageDetectionConfidence
   * @function
   * @public
   * @returns {string} detection confidence strength.
   */
  get languageDetectionConfidence() {
    return this.privLanguageDetectionConfidence;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member RecognitionResult.prototype.errorDetails
   * @function
   * @public
   * @returns {string} a brief description of an error.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
  /**
   * A string containing Json serialized recognition result as it was received from the service.
   * @member RecognitionResult.prototype.json
   * @function
   * @private
   * @returns {string} Json serialized representation of the result.
   */
  get json() {
    return this.privJson;
  }
  /**
   * The set of properties exposed in the result.
   * @member RecognitionResult.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The set of properties exposed in the result.
   */
  get properties() {
    return this.privProperties;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js
var SpeechRecognitionResult = class extends RecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @public
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} text - The recognized text.
   * @param {number} duration - The duration.
   * @param {number} offset - The offset into the stream.
   * @param {string} language - Primary Language detected, if provided.
   * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param {string} speakerId - speaker id for conversation transcription, if provided.
   * @param {string} errorDetails - Error details, if provided.
   * @param {string} json - Additional Json, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {
    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);
    this.privSpeakerId = speakerId;
  }
  /**
   * speaker id from conversation transcription/id scenarios
   * @member SpeechRecognitionResult.prototype.speakerId
   * @function
   * @public
   * @returns {string} id of speaker in given result
   */
  get speakerId() {
    return this.privSpeakerId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js
var IntentRecognitionResult = class extends SpeechRecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param intentId - The intent id.
   * @param resultId - The result id.
   * @param reason - The reason.
   * @param text - The recognized text.
   * @param duration - The duration.
   * @param offset - The offset into the stream.
   * @param language - Primary Language detected, if provided.
   * @param languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
   * @param errorDetails - Error details, if provided.
   * @param json - Additional Json, if provided.
   * @param properties - Additional properties, if provided.
   */
  constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, void 0, errorDetails, json, properties);
    this.privIntentId = intentId;
  }
  /**
   * A String that represents the intent identifier being recognized.
   * @member IntentRecognitionResult.prototype.intentId
   * @function
   * @public
   * @returns {string} A String that represents the intent identifier being recognized.
   */
  get intentId() {
    return this.privIntentId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js
var LanguageUnderstandingModel = class {
  /**
   * Creates and initializes a new instance
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Creates an language understanding model using the specified endpoint.
   * @member LanguageUnderstandingModel.fromEndpoint
   * @function
   * @public
   * @param {URL} uri - A String that represents the endpoint of the language understanding model.
   * @returns {LanguageUnderstandingModel} The language understanding model being created.
   */
  static fromEndpoint(uri) {
    Contracts.throwIfNull(uri, "uri");
    Contracts.throwIfNullOrWhitespace(uri.hostname, "uri");
    const langModelImp = new LanguageUnderstandingModelImpl();
    const firstDot = uri.host.indexOf(".");
    if (-1 === firstDot) {
      throw new Error("Could not determine region from endpoint");
    }
    langModelImp.region = uri.host.substr(0, firstDot);
    const lastSegment = uri.pathname.lastIndexOf("/") + 1;
    if (-1 === lastSegment) {
      throw new Error("Could not determine appId from endpoint");
    }
    langModelImp.appId = uri.pathname.substr(lastSegment);
    langModelImp.subscriptionKey = uri.searchParams.get("subscription-key");
    if (void 0 === langModelImp.subscriptionKey) {
      throw new Error("Could not determine subscription key from endpoint");
    }
    return langModelImp;
  }
  /**
   * Creates an language understanding model using the application id of Language Understanding service.
   * @member LanguageUnderstandingModel.fromAppId
   * @function
   * @public
   * @param {string} appId - A String that represents the application id of Language Understanding service.
   * @returns {LanguageUnderstandingModel} The language understanding model being created.
   */
  static fromAppId(appId) {
    Contracts.throwIfNullOrWhitespace(appId, "appId");
    const langModelImp = new LanguageUnderstandingModelImpl();
    langModelImp.appId = appId;
    return langModelImp;
  }
  /**
   * Creates a language understanding model using hostname, subscription key and application
   * id of Language Understanding service.
   * @member LanguageUnderstandingModel.fromSubscription
   * @function
   * @public
   * @param {string} subscriptionKey - A String that represents the subscription key of
   * Language Understanding service.
   * @param {string} appId - A String that represents the application id of Language
   * Understanding service.
   * @param {LanguageUnderstandingModel} region - A String that represents the region
   * of the Language Understanding service (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {LanguageUnderstandingModel} The language understanding model being created.
   */
  static fromSubscription(subscriptionKey, appId, region) {
    Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
    Contracts.throwIfNullOrWhitespace(appId, "appId");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const langModelImp = new LanguageUnderstandingModelImpl();
    langModelImp.appId = appId;
    langModelImp.region = region;
    langModelImp.subscriptionKey = subscriptionKey;
    return langModelImp;
  }
};
var LanguageUnderstandingModelImpl = class extends LanguageUnderstandingModel {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js
var SpeechRecognitionEventArgs = class extends RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {SpeechRecognitionResult} result - The speech recognition result.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the recognition result.
   * @member SpeechRecognitionEventArgs.prototype.result
   * @function
   * @public
   * @returns {SpeechRecognitionResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
};
var ConversationTranscriptionEventArgs = class extends SpeechRecognitionEventArgs {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js
var CancellationEventArgsBase = class extends RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {CancellationReason} reason - The cancellation reason.
   * @param {string} errorDetails - Error details, if provided.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(reason, errorDetails, errorCode, offset, sessionId) {
    super(offset, sessionId);
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privErrorCode = errorCode;
  }
  /**
   * The reason the recognition was canceled.
   * @member CancellationEventArgsBase.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * The error code in case of an unsuccessful operation.
   * @return An error code that represents the error reason.
   */
  get errorCode() {
    return this.privErrorCode;
  }
  /**
   * In case of an unsuccessful operation, provides details of the occurred error.
   * @member CancellationEventArgsBase.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js
var SpeechRecognitionCanceledEventArgs = class extends CancellationEventArgsBase {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js
var TranslationRecognitionEventArgs = class extends RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {TranslationRecognitionResult} result - The translation recognition result.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the recognition result.
   * @member TranslationRecognitionEventArgs.prototype.result
   * @function
   * @public
   * @returns {TranslationRecognitionResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js
var TranslationSynthesisEventArgs = class extends SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {TranslationSynthesisResult} result - The translation synthesis result.
   * @param {string} sessionId - The session id.
   */
  constructor(result, sessionId) {
    super(sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the translation synthesis result.
   * @member TranslationSynthesisEventArgs.prototype.result
   * @function
   * @public
   * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.
   */
  get result() {
    return this.privResult;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js
var TranslationRecognitionResult = class extends SpeechRecognitionResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {Translations} translations - The translations.
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} text - The recognized text.
   * @param {number} duration - The duration.
   * @param {number} offset - The offset into the stream.
   * @param {string} errorDetails - Error details, if provided.
   * @param {string} json - Additional Json, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(translations, resultId, reason, text, duration, offset, errorDetails, json, properties) {
    super(resultId, reason, text, duration, offset, void 0, void 0, void 0, errorDetails, json, properties);
    this.privTranslations = translations;
  }
  static fromSpeechRecognitionResult(result) {
    return new TranslationRecognitionResult(void 0, result.resultId, result.reason, result.text, result.duration, result.offset, result.errorDetails, result.json, result.properties);
  }
  /**
   * Presents the translation results. Each item in the dictionary represents
   * a translation result in one of target languages, where the key is the name
   * of the target language, in BCP-47 format, and the value is the translation
   * text in the specified language.
   * @member TranslationRecognitionResult.prototype.translations
   * @function
   * @public
   * @returns {Translations} the current translation map that holds all translations requested.
   */
  get translations() {
    return this.privTranslations;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js
var TranslationSynthesisResult = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {ResultReason} reason - The synthesis reason.
   * @param {ArrayBuffer} audio - The audio data.
   */
  constructor(reason, audio) {
    this.privReason = reason;
    this.privAudio = audio;
  }
  /**
   * Translated text in the target language.
   * @member TranslationSynthesisResult.prototype.audio
   * @function
   * @public
   * @returns {ArrayBuffer} Translated audio in the target language.
   */
  get audio() {
    return this.privAudio;
  }
  /**
   * The synthesis status.
   * @member TranslationSynthesisResult.prototype.reason
   * @function
   * @public
   * @returns {ResultReason} The synthesis status.
   */
  get reason() {
    return this.privReason;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js
var ResultReason;
(function(ResultReason2) {
  ResultReason2[ResultReason2["NoMatch"] = 0] = "NoMatch";
  ResultReason2[ResultReason2["Canceled"] = 1] = "Canceled";
  ResultReason2[ResultReason2["RecognizingSpeech"] = 2] = "RecognizingSpeech";
  ResultReason2[ResultReason2["RecognizedSpeech"] = 3] = "RecognizedSpeech";
  ResultReason2[ResultReason2["RecognizedKeyword"] = 4] = "RecognizedKeyword";
  ResultReason2[ResultReason2["RecognizingIntent"] = 5] = "RecognizingIntent";
  ResultReason2[ResultReason2["RecognizedIntent"] = 6] = "RecognizedIntent";
  ResultReason2[ResultReason2["TranslatingSpeech"] = 7] = "TranslatingSpeech";
  ResultReason2[ResultReason2["TranslatedSpeech"] = 8] = "TranslatedSpeech";
  ResultReason2[ResultReason2["SynthesizingAudio"] = 9] = "SynthesizingAudio";
  ResultReason2[ResultReason2["SynthesizingAudioCompleted"] = 10] = "SynthesizingAudioCompleted";
  ResultReason2[ResultReason2["SynthesizingAudioStarted"] = 11] = "SynthesizingAudioStarted";
  ResultReason2[ResultReason2["EnrollingVoiceProfile"] = 12] = "EnrollingVoiceProfile";
  ResultReason2[ResultReason2["EnrolledVoiceProfile"] = 13] = "EnrolledVoiceProfile";
  ResultReason2[ResultReason2["RecognizedSpeakers"] = 14] = "RecognizedSpeakers";
  ResultReason2[ResultReason2["RecognizedSpeaker"] = 15] = "RecognizedSpeaker";
  ResultReason2[ResultReason2["ResetVoiceProfile"] = 16] = "ResetVoiceProfile";
  ResultReason2[ResultReason2["DeletedVoiceProfile"] = 17] = "DeletedVoiceProfile";
  ResultReason2[ResultReason2["VoicesListRetrieved"] = 18] = "VoicesListRetrieved";
})(ResultReason || (ResultReason = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js
var SpeechConfig = class {
  /**
   * Creates and initializes an instance.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Static instance of SpeechConfig returned by passing subscriptionKey and service region.
   * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
   * @member SpeechConfig.fromSubscription
   * @function
   * @public
   * @param {string} subscriptionKey - The subscription key.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechConfig} The speech factory
   */
  static fromSubscription(subscriptionKey, region) {
    Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_IntentRegion, region);
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    return speechImpl;
  }
  /**
   * Creates an instance of the speech config with specified endpoint and subscription key.
   * This method is intended only for users who use a non-standard service endpoint or parameters.
   * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
   * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
   * For example, if language is defined in the uri as query parameter "language=de-DE", and also set by
   * SpeechConfig.speechRecognitionLanguage = "en-US", the language setting in uri takes precedence,
   * and the effective language is "de-DE". Only the parameters that are not specified in the
   * endpoint URL can be set by other APIs.
   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
   * fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
   * use the authorization token.
   * @member SpeechConfig.fromEndpoint
   * @function
   * @public
   * @param {URL} endpoint - The service endpoint to connect to.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromEndpoint(endpoint, subscriptionKey) {
    Contracts.throwIfNull(endpoint, "endpoint");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);
    if (void 0 !== subscriptionKey) {
      speechImpl.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return speechImpl;
  }
  /**
   * Creates an instance of the speech config with specified host and subscription key.
   * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
   * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
   * Note: To use an authorization token with fromHost, use fromHost(URL),
   * and then set the AuthorizationToken property on the created SpeechConfig instance.
   * Note: Added in version 1.9.0.
   * @member SpeechConfig.fromHost
   * @function
   * @public
   * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromHost(hostName, subscriptionKey) {
    Contracts.throwIfNull(hostName, "hostName");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
    if (void 0 !== subscriptionKey) {
      speechImpl.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return speechImpl;
  }
  /**
   * Creates an instance of the speech factory with specified initial authorization token and region.
   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
   * expires, the caller needs to refresh it by calling this setter with a new valid token.
   * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want
   * to use the Intent recognizer. As configuration values are copied when creating a new recognizer,
   * the new token value will not apply to recognizers that have already been created. For recognizers
   * that have been created before, you need to set authorization token of the corresponding recognizer
   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
   * @member SpeechConfig.fromAuthorizationToken
   * @function
   * @public
   * @param {string} authorizationToken - The initial authorization token.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromAuthorizationToken(authorizationToken, region) {
    Contracts.throwIfNull(authorizationToken, "authorizationToken");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const speechImpl = new SpeechConfigImpl();
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_IntentRegion, region);
    speechImpl.authorizationToken = authorizationToken;
    return speechImpl;
  }
  /**
   * Closes the configuration.
   * @member SpeechConfig.prototype.close
   * @function
   * @public
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  close() {
  }
};
var SpeechConfigImpl = class extends SpeechConfig {
  constructor() {
    super();
    this.privProperties = new PropertyCollection();
    this.speechRecognitionLanguage = "en-US";
    this.outputFormat = OutputFormat.Simple;
  }
  get properties() {
    return this.privProperties;
  }
  get endPoint() {
    return new URL(this.privProperties.getProperty(PropertyId.SpeechServiceConnection_Endpoint));
  }
  get subscriptionKey() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_Key);
  }
  get region() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_Region);
  }
  get authorizationToken() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  set authorizationToken(value) {
    this.privProperties.setProperty(PropertyId.SpeechServiceAuthorization_Token, value);
  }
  get speechRecognitionLanguage() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  set speechRecognitionLanguage(value) {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_RecoLanguage, value);
  }
  get autoDetectSourceLanguages() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);
  }
  set autoDetectSourceLanguages(value) {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, value);
  }
  get outputFormat() {
    return OutputFormat[this.privProperties.getProperty(OutputFormatPropertyName, void 0)];
  }
  set outputFormat(value) {
    this.privProperties.setProperty(OutputFormatPropertyName, OutputFormat[value]);
  }
  get endpointId() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_EndpointId);
  }
  set endpointId(value) {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_EndpointId, value);
  }
  setProperty(name, value) {
    Contracts.throwIfNull(value, "value");
    this.privProperties.setProperty(name, value);
  }
  getProperty(name, def) {
    return this.privProperties.getProperty(name, def);
  }
  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);
  }
  setServiceProperty(name, value) {
    const currentProperties = JSON.parse(this.privProperties.getProperty(ServicePropertiesPropertyName, "{}"));
    currentProperties[name] = value;
    this.privProperties.setProperty(ServicePropertiesPropertyName, JSON.stringify(currentProperties));
  }
  setProfanity(profanity) {
    this.privProperties.setProperty(PropertyId.SpeechServiceResponse_ProfanityOption, ProfanityOption[profanity]);
  }
  enableAudioLogging() {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_EnableAudioLogging, "true");
  }
  requestWordLevelTimestamps() {
    this.privProperties.setProperty(PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "true");
  }
  enableDictation() {
    this.privProperties.setProperty(ForceDictationPropertyName, "true");
  }
  clone() {
    const ret = new SpeechConfigImpl();
    ret.privProperties = this.privProperties.clone();
    return ret;
  }
  get speechSynthesisLanguage() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_SynthLanguage);
  }
  set speechSynthesisLanguage(language) {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_SynthLanguage, language);
  }
  get speechSynthesisVoiceName() {
    return this.privProperties.getProperty(PropertyId.SpeechServiceConnection_SynthVoice);
  }
  set speechSynthesisVoiceName(voice) {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_SynthVoice, voice);
  }
  get speechSynthesisOutputFormat() {
    return SpeechSynthesisOutputFormat[this.privProperties.getProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, void 0)];
  }
  set speechSynthesisOutputFormat(format) {
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, SpeechSynthesisOutputFormat[format]);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js
var SpeechTranslationConfig = class extends SpeechConfig {
  /**
   * Creates an instance of recognizer config.
   */
  constructor() {
    super();
  }
  /**
   * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.
   * @member SpeechTranslationConfig.fromSubscription
   * @function
   * @public
   * @param {string} subscriptionKey - The subscription key.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechTranslationConfig} The speech translation config.
   */
  static fromSubscription(subscriptionKey, region) {
    Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const ret = new SpeechTranslationConfigImpl();
    ret.properties.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    ret.properties.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    return ret;
  }
  /**
   * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.
   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
   * expires, the caller needs to refresh it by setting the property authorizationToken with a new
   * valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance
   * will encounter errors during recognition.
   * As configuration values are copied when creating a new recognizer, the new token value will not apply
   * to recognizers that have already been created.
   * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
   * @member SpeechTranslationConfig.fromAuthorizationToken
   * @function
   * @public
   * @param {string} authorizationToken - The authorization token.
   * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {SpeechTranslationConfig} The speech translation config.
   */
  static fromAuthorizationToken(authorizationToken, region) {
    Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const ret = new SpeechTranslationConfigImpl();
    ret.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
    ret.properties.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    return ret;
  }
  /**
   * Creates an instance of the speech config with specified host and subscription key.
   * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
   * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
   * Note: To use an authorization token with fromHost, use fromHost(URL),
   * and then set the AuthorizationToken property on the created SpeechConfig instance.
   * Note: Added in version 1.9.0.
   * @member SpeechConfig.fromHost
   * @function
   * @public
   * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
   * @returns {SpeechConfig} A speech factory instance.
   */
  static fromHost(hostName, subscriptionKey) {
    Contracts.throwIfNull(hostName, "hostName");
    const speechImpl = new SpeechTranslationConfigImpl();
    speechImpl.setProperty(PropertyId.SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
    if (void 0 !== subscriptionKey) {
      speechImpl.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return speechImpl;
  }
  /**
   * Creates an instance of the speech translation config with specified endpoint and subscription key.
   * This method is intended only for users who use a non-standard service endpoint or paramters.
   * Note: The query properties specified in the endpoint URL are not changed, even if they are
   * set by any other APIs. For example, if language is defined in the uri as query parameter
   * "language=de-DE", and also set by the speechRecognitionLanguage property, the language
   * setting in uri takes precedence, and the effective language is "de-DE".
   * Only the properties that are not specified in the endpoint URL can be set by other APIs.
   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
   * fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
   * use the authorization token.
   * @member SpeechTranslationConfig.fromEndpoint
   * @function
   * @public
   * @param {URL} endpoint - The service endpoint to connect to.
   * @param {string} subscriptionKey - The subscription key.
   * @returns {SpeechTranslationConfig} A speech config instance.
   */
  static fromEndpoint(endpoint, subscriptionKey) {
    Contracts.throwIfNull(endpoint, "endpoint");
    Contracts.throwIfNull(subscriptionKey, "subscriptionKey");
    const ret = new SpeechTranslationConfigImpl();
    ret.properties.setProperty(PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);
    ret.properties.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    return ret;
  }
};
var SpeechTranslationConfigImpl = class extends SpeechTranslationConfig {
  constructor() {
    super();
    this.privSpeechProperties = new PropertyCollection();
    this.outputFormat = OutputFormat.Simple;
  }
  /**
   * Gets/Sets the authorization token.
   * If this is set, subscription key is ignored.
   * User needs to make sure the provided authorization token is valid and not expired.
   * @member SpeechTranslationConfigImpl.prototype.authorizationToken
   * @function
   * @public
   * @param {string} value - The authorization token.
   */
  set authorizationToken(value) {
    Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceAuthorization_Token, value);
  }
  /**
   * Sets the speech recognition language.
   * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @param {string} value - The authorization token.
   */
  set speechRecognitionLanguage(value) {
    Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_RecoLanguage, value);
  }
  /**
   * Gets the speech recognition language.
   * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @return {string} The speechRecognitionLanguage.
   */
  get speechRecognitionLanguage() {
    return this.privSpeechProperties.getProperty(PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
  }
  /**
   * @member SpeechTranslationConfigImpl.prototype.subscriptionKey
   * @function
   * @public
   */
  get subscriptionKey() {
    return this.privSpeechProperties.getProperty(PropertyId[PropertyId.SpeechServiceConnection_Key]);
  }
  /**
   * Gets the output format
   * @member SpeechTranslationConfigImpl.prototype.outputFormat
   * @function
   * @public
   */
  get outputFormat() {
    return OutputFormat[this.privSpeechProperties.getProperty(OutputFormatPropertyName, void 0)];
  }
  /**
   * Gets/Sets the output format
   * @member SpeechTranslationConfigImpl.prototype.outputFormat
   * @function
   * @public
   */
  set outputFormat(value) {
    this.privSpeechProperties.setProperty(OutputFormatPropertyName, OutputFormat[value]);
  }
  /**
   * Gets the endpoint id.
   * @member SpeechTranslationConfigImpl.prototype.endpointId
   * @function
   * @public
   */
  get endpointId() {
    return this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_EndpointId);
  }
  /**
   * Gets/Sets the endpoint id.
   * @member SpeechTranslationConfigImpl.prototype.endpointId
   * @function
   * @public
   */
  set endpointId(value) {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_EndpointId, value);
  }
  /**
   * Add a (text) target language to translate into.
   * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage
   * @function
   * @public
   * @param {string} value - The language such as de-DE
   */
  addTargetLanguage(value) {
    Contracts.throwIfNullOrWhitespace(value, "value");
    const languages = this.targetLanguages;
    languages.push(value);
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
  }
  /**
   * Gets the (text) target language to translate into.
   * @member SpeechTranslationConfigImpl.prototype.targetLanguages
   * @function
   * @public
   * @param {string} value - The language such as de-DE
   */
  get targetLanguages() {
    if (this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, void 0) !== void 0) {
      return this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
    } else {
      return [];
    }
  }
  /**
   * Gets the voice name.
   * @member SpeechTranslationConfigImpl.prototype.voiceName
   * @function
   * @public
   */
  get voiceName() {
    return this.getProperty(PropertyId[PropertyId.SpeechServiceConnection_TranslationVoice]);
  }
  /**
   * Gets/Sets the voice of the translated language, enable voice synthesis output.
   * @member SpeechTranslationConfigImpl.prototype.voiceName
   * @function
   * @public
   * @param {string} value - The name of the voice.
   */
  set voiceName(value) {
    Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_TranslationVoice, value);
  }
  /**
   * Provides the region.
   * @member SpeechTranslationConfigImpl.prototype.region
   * @function
   * @public
   * @returns {string} The region.
   */
  get region() {
    return this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_Region);
  }
  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);
    this.setProperty(PropertyId[PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);
  }
  /**
   * Gets an arbitrary property value.
   * @member SpeechTranslationConfigImpl.prototype.getProperty
   * @function
   * @public
   * @param {string} name - The name of the property.
   * @param {string} def - The default value of the property in case it is not set.
   * @returns {string} The value of the property.
   */
  getProperty(name, def) {
    return this.privSpeechProperties.getProperty(name, def);
  }
  /**
   * Gets/Sets an arbitrary property value.
   * @member SpeechTranslationConfigImpl.prototype.setProperty
   * @function
   * @public
   * @param {string} name - The name of the property.
   * @param {string} value - The value of the property.
   */
  setProperty(name, value) {
    this.privSpeechProperties.setProperty(name, value);
  }
  /**
   * Provides access to custom properties.
   * @member SpeechTranslationConfigImpl.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The properties.
   */
  get properties() {
    return this.privSpeechProperties;
  }
  /**
   * Dispose of associated resources.
   * @member SpeechTranslationConfigImpl.prototype.close
   * @function
   * @public
   */
  close() {
    return;
  }
  setServiceProperty(name, value) {
    const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(ServicePropertiesPropertyName, "{}"));
    currentProperties[name] = value;
    this.privSpeechProperties.setProperty(ServicePropertiesPropertyName, JSON.stringify(currentProperties));
  }
  setProfanity(profanity) {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceResponse_ProfanityOption, ProfanityOption[profanity]);
  }
  enableAudioLogging() {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_EnableAudioLogging, "true");
  }
  requestWordLevelTimestamps() {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "true");
  }
  enableDictation() {
    this.privSpeechProperties.setProperty(ForceDictationPropertyName, "true");
  }
  get speechSynthesisLanguage() {
    return this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_SynthLanguage);
  }
  set speechSynthesisLanguage(language) {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_SynthLanguage, language);
  }
  get speechSynthesisVoiceName() {
    return this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_SynthVoice);
  }
  set speechSynthesisVoiceName(voice) {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_SynthVoice, voice);
  }
  get speechSynthesisOutputFormat() {
    return SpeechSynthesisOutputFormat[this.privSpeechProperties.getProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, void 0)];
  }
  set speechSynthesisOutputFormat(format) {
    this.privSpeechProperties.setProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, SpeechSynthesisOutputFormat[format]);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js
var PropertyCollection = class {
  constructor() {
    this.privKeys = [];
    this.privValues = [];
  }
  /**
   * Returns the property value in type String.
   * Currently only String, int and bool are allowed.
   * If the name is not available, the specified defaultValue is returned.
   * @member PropertyCollection.prototype.getProperty
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string | number | boolean} def - The default value which is returned if the parameter
   * is not available in the collection.
   * @returns {string} value of the parameter.
   */
  getProperty(key, def) {
    let keyToUse;
    if (typeof key === "string") {
      keyToUse = key;
    } else {
      keyToUse = PropertyId[key];
    }
    for (let n = 0; n < this.privKeys.length; n++) {
      if (this.privKeys[n] === keyToUse) {
        return this.privValues[n];
      }
    }
    if (def === void 0) {
      return void 0;
    }
    return String(def);
  }
  /**
   * Sets the String value of the parameter specified by name.
   * @member PropertyCollection.prototype.setProperty
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string} value - The value of the parameter.
   */
  setProperty(key, value) {
    let keyToUse;
    if (typeof key === "string") {
      keyToUse = key;
    } else {
      keyToUse = PropertyId[key];
    }
    for (let n = 0; n < this.privKeys.length; n++) {
      if (this.privKeys[n] === keyToUse) {
        this.privValues[n] = value;
        return;
      }
    }
    this.privKeys.push(keyToUse);
    this.privValues.push(value);
  }
  /**
   * Clones the collection.
   * @member PropertyCollection.prototype.clone
   * @function
   * @public
   * @returns {PropertyCollection} A copy of the collection.
   */
  clone() {
    const clonedMap = new PropertyCollection();
    for (let n = 0; n < this.privKeys.length; n++) {
      clonedMap.privKeys.push(this.privKeys[n]);
      clonedMap.privValues.push(this.privValues[n]);
    }
    return clonedMap;
  }
  /**
   * Merges this set of properties into another, no overwrites.
   * @member PropertyCollection.prototype.mergeTo
   * @function
   * @public
   * @param {PropertyCollection}  destinationCollection - The collection to merge into.
   */
  mergeTo(destinationCollection) {
    this.privKeys.forEach((key) => {
      if (destinationCollection.getProperty(key, void 0) === void 0) {
        const value = this.getProperty(key);
        destinationCollection.setProperty(key, value);
      }
    });
  }
  /**
   * Get the keys in Property Collection.
   * @member PropertyCollection.prototype.keys
   * @function
   * @public
   * @returns {string []} Keys in the collection.
   */
  get keys() {
    return this.privKeys;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js
var PropertyId;
(function(PropertyId2) {
  PropertyId2[PropertyId2["SpeechServiceConnection_Key"] = 0] = "SpeechServiceConnection_Key";
  PropertyId2[PropertyId2["SpeechServiceConnection_Endpoint"] = 1] = "SpeechServiceConnection_Endpoint";
  PropertyId2[PropertyId2["SpeechServiceConnection_Region"] = 2] = "SpeechServiceConnection_Region";
  PropertyId2[PropertyId2["SpeechServiceAuthorization_Token"] = 3] = "SpeechServiceAuthorization_Token";
  PropertyId2[PropertyId2["SpeechServiceAuthorization_Type"] = 4] = "SpeechServiceAuthorization_Type";
  PropertyId2[PropertyId2["SpeechServiceConnection_EndpointId"] = 5] = "SpeechServiceConnection_EndpointId";
  PropertyId2[PropertyId2["SpeechServiceConnection_TranslationToLanguages"] = 6] = "SpeechServiceConnection_TranslationToLanguages";
  PropertyId2[PropertyId2["SpeechServiceConnection_TranslationVoice"] = 7] = "SpeechServiceConnection_TranslationVoice";
  PropertyId2[PropertyId2["SpeechServiceConnection_TranslationFeatures"] = 8] = "SpeechServiceConnection_TranslationFeatures";
  PropertyId2[PropertyId2["SpeechServiceConnection_IntentRegion"] = 9] = "SpeechServiceConnection_IntentRegion";
  PropertyId2[PropertyId2["SpeechServiceConnection_ProxyHostName"] = 10] = "SpeechServiceConnection_ProxyHostName";
  PropertyId2[PropertyId2["SpeechServiceConnection_ProxyPort"] = 11] = "SpeechServiceConnection_ProxyPort";
  PropertyId2[PropertyId2["SpeechServiceConnection_ProxyUserName"] = 12] = "SpeechServiceConnection_ProxyUserName";
  PropertyId2[PropertyId2["SpeechServiceConnection_ProxyPassword"] = 13] = "SpeechServiceConnection_ProxyPassword";
  PropertyId2[PropertyId2["SpeechServiceConnection_RecoMode"] = 14] = "SpeechServiceConnection_RecoMode";
  PropertyId2[PropertyId2["SpeechServiceConnection_RecoLanguage"] = 15] = "SpeechServiceConnection_RecoLanguage";
  PropertyId2[PropertyId2["Speech_SessionId"] = 16] = "Speech_SessionId";
  PropertyId2[PropertyId2["SpeechServiceConnection_SynthLanguage"] = 17] = "SpeechServiceConnection_SynthLanguage";
  PropertyId2[PropertyId2["SpeechServiceConnection_SynthVoice"] = 18] = "SpeechServiceConnection_SynthVoice";
  PropertyId2[PropertyId2["SpeechServiceConnection_SynthOutputFormat"] = 19] = "SpeechServiceConnection_SynthOutputFormat";
  PropertyId2[PropertyId2["SpeechServiceConnection_AutoDetectSourceLanguages"] = 20] = "SpeechServiceConnection_AutoDetectSourceLanguages";
  PropertyId2[PropertyId2["SpeechServiceResponse_RequestDetailedResultTrueFalse"] = 21] = "SpeechServiceResponse_RequestDetailedResultTrueFalse";
  PropertyId2[PropertyId2["SpeechServiceResponse_RequestProfanityFilterTrueFalse"] = 22] = "SpeechServiceResponse_RequestProfanityFilterTrueFalse";
  PropertyId2[PropertyId2["SpeechServiceResponse_JsonResult"] = 23] = "SpeechServiceResponse_JsonResult";
  PropertyId2[PropertyId2["SpeechServiceResponse_JsonErrorDetails"] = 24] = "SpeechServiceResponse_JsonErrorDetails";
  PropertyId2[PropertyId2["CancellationDetails_Reason"] = 25] = "CancellationDetails_Reason";
  PropertyId2[PropertyId2["CancellationDetails_ReasonText"] = 26] = "CancellationDetails_ReasonText";
  PropertyId2[PropertyId2["CancellationDetails_ReasonDetailedText"] = 27] = "CancellationDetails_ReasonDetailedText";
  PropertyId2[PropertyId2["LanguageUnderstandingServiceResponse_JsonResult"] = 28] = "LanguageUnderstandingServiceResponse_JsonResult";
  PropertyId2[PropertyId2["SpeechServiceConnection_Url"] = 29] = "SpeechServiceConnection_Url";
  PropertyId2[PropertyId2["SpeechServiceConnection_InitialSilenceTimeoutMs"] = 30] = "SpeechServiceConnection_InitialSilenceTimeoutMs";
  PropertyId2[PropertyId2["SpeechServiceConnection_EndSilenceTimeoutMs"] = 31] = "SpeechServiceConnection_EndSilenceTimeoutMs";
  PropertyId2[PropertyId2["Speech_SegmentationSilenceTimeoutMs"] = 32] = "Speech_SegmentationSilenceTimeoutMs";
  PropertyId2[PropertyId2["SpeechServiceConnection_EnableAudioLogging"] = 33] = "SpeechServiceConnection_EnableAudioLogging";
  PropertyId2[PropertyId2["SpeechServiceConnection_LanguageIdMode"] = 34] = "SpeechServiceConnection_LanguageIdMode";
  PropertyId2[PropertyId2["SpeechServiceConnection_RecognitionEndpointVersion"] = 35] = "SpeechServiceConnection_RecognitionEndpointVersion";
  PropertyId2[PropertyId2["SpeechServiceConnection_SpeakerIdMode"] = 36] = "SpeechServiceConnection_SpeakerIdMode";
  PropertyId2[PropertyId2["SpeechServiceResponse_ProfanityOption"] = 37] = "SpeechServiceResponse_ProfanityOption";
  PropertyId2[PropertyId2["SpeechServiceResponse_PostProcessingOption"] = 38] = "SpeechServiceResponse_PostProcessingOption";
  PropertyId2[PropertyId2["SpeechServiceResponse_RequestWordLevelTimestamps"] = 39] = "SpeechServiceResponse_RequestWordLevelTimestamps";
  PropertyId2[PropertyId2["SpeechServiceResponse_StablePartialResultThreshold"] = 40] = "SpeechServiceResponse_StablePartialResultThreshold";
  PropertyId2[PropertyId2["SpeechServiceResponse_OutputFormatOption"] = 41] = "SpeechServiceResponse_OutputFormatOption";
  PropertyId2[PropertyId2["SpeechServiceResponse_TranslationRequestStablePartialResult"] = 42] = "SpeechServiceResponse_TranslationRequestStablePartialResult";
  PropertyId2[PropertyId2["SpeechServiceResponse_RequestWordBoundary"] = 43] = "SpeechServiceResponse_RequestWordBoundary";
  PropertyId2[PropertyId2["SpeechServiceResponse_RequestPunctuationBoundary"] = 44] = "SpeechServiceResponse_RequestPunctuationBoundary";
  PropertyId2[PropertyId2["SpeechServiceResponse_RequestSentenceBoundary"] = 45] = "SpeechServiceResponse_RequestSentenceBoundary";
  PropertyId2[PropertyId2["Conversation_ApplicationId"] = 46] = "Conversation_ApplicationId";
  PropertyId2[PropertyId2["Conversation_DialogType"] = 47] = "Conversation_DialogType";
  PropertyId2[PropertyId2["Conversation_Initial_Silence_Timeout"] = 48] = "Conversation_Initial_Silence_Timeout";
  PropertyId2[PropertyId2["Conversation_From_Id"] = 49] = "Conversation_From_Id";
  PropertyId2[PropertyId2["Conversation_Conversation_Id"] = 50] = "Conversation_Conversation_Id";
  PropertyId2[PropertyId2["Conversation_Custom_Voice_Deployment_Ids"] = 51] = "Conversation_Custom_Voice_Deployment_Ids";
  PropertyId2[PropertyId2["Conversation_Speech_Activity_Template"] = 52] = "Conversation_Speech_Activity_Template";
  PropertyId2[PropertyId2["Conversation_Request_Bot_Status_Messages"] = 53] = "Conversation_Request_Bot_Status_Messages";
  PropertyId2[PropertyId2["Conversation_Agent_Connection_Id"] = 54] = "Conversation_Agent_Connection_Id";
  PropertyId2[PropertyId2["SpeechServiceConnection_Host"] = 55] = "SpeechServiceConnection_Host";
  PropertyId2[PropertyId2["ConversationTranslator_Host"] = 56] = "ConversationTranslator_Host";
  PropertyId2[PropertyId2["ConversationTranslator_Name"] = 57] = "ConversationTranslator_Name";
  PropertyId2[PropertyId2["ConversationTranslator_CorrelationId"] = 58] = "ConversationTranslator_CorrelationId";
  PropertyId2[PropertyId2["ConversationTranslator_Token"] = 59] = "ConversationTranslator_Token";
  PropertyId2[PropertyId2["PronunciationAssessment_ReferenceText"] = 60] = "PronunciationAssessment_ReferenceText";
  PropertyId2[PropertyId2["PronunciationAssessment_GradingSystem"] = 61] = "PronunciationAssessment_GradingSystem";
  PropertyId2[PropertyId2["PronunciationAssessment_Granularity"] = 62] = "PronunciationAssessment_Granularity";
  PropertyId2[PropertyId2["PronunciationAssessment_EnableMiscue"] = 63] = "PronunciationAssessment_EnableMiscue";
  PropertyId2[PropertyId2["PronunciationAssessment_Json"] = 64] = "PronunciationAssessment_Json";
  PropertyId2[PropertyId2["PronunciationAssessment_Params"] = 65] = "PronunciationAssessment_Params";
  PropertyId2[PropertyId2["SpeakerRecognition_Api_Version"] = 66] = "SpeakerRecognition_Api_Version";
})(PropertyId || (PropertyId = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js
var __awaiter5 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var Recognizer = class {
  /**
   * Creates and initializes an instance of a Recognizer
   * @constructor
   * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer
   */
  constructor(audioConfig, properties, connectionFactory) {
    this.audioConfig = audioConfig !== void 0 ? audioConfig : AudioConfig.fromDefaultMicrophoneInput();
    this.privDisposed = false;
    this.privProperties = properties.clone();
    this.privConnectionFactory = connectionFactory;
    this.implCommonRecognizerSetup();
  }
  /**
   * Dispose of associated resources.
   * @member Recognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    Contracts.throwIfDisposed(this.privDisposed);
    marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);
  }
  /**
   * @Internal
   * Internal data member to support fromRecognizer* pattern methods on other classes.
   * Do not use externally, object returned will change without warning or notice.
   */
  get internalData() {
    return this.privReco;
  }
  /**
   * This method performs cleanup of resources.
   * The Boolean parameter disposing indicates whether the method is called
   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
   * Derived classes should override this method to dispose resource if needed.
   * @member Recognizer.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - Flag to request disposal.
   */
  dispose(disposing) {
    return __awaiter5(this, void 0, void 0, function* () {
      if (this.privDisposed) {
        return;
      }
      this.privDisposed = true;
      if (disposing) {
        if (this.privReco) {
          yield this.privReco.audioSource.turnOff();
          yield this.privReco.dispose();
        }
      }
    });
  }
  /**
   * This method returns the current state of the telemetry setting.
   * @member Recognizer.prototype.telemetryEnabled
   * @function
   * @public
   * @returns true if the telemetry is enabled, false otherwise.
   */
  static get telemetryEnabled() {
    return ServiceRecognizerBase.telemetryDataEnabled;
  }
  /**
   * This method globally enables or disables telemetry.
   * @member Recognizer.prototype.enableTelemetry
   * @function
   * @public
   * @param enabled - Global setting for telemetry collection.
   * If set to true, telemetry information like microphone errors,
   * recognition errors are collected and sent to Microsoft.
   * If set to false, no telemetry is sent to Microsoft.
   */
  static enableTelemetry(enabled) {
    ServiceRecognizerBase.telemetryDataEnabled = enabled;
  }
  // Does the generic recognizer setup that is common across all recognizer types.
  implCommonRecognizerSetup() {
    let osPlatform = typeof window !== "undefined" ? "Browser" : "Node";
    let osName = "unknown";
    let osVersion = "unknown";
    if (typeof navigator !== "undefined") {
      osPlatform = osPlatform + "/" + navigator.platform;
      osName = navigator.userAgent;
      osVersion = navigator.appVersion;
    }
    const recognizerConfig = this.createRecognizerConfig(new SpeechServiceConfig(new Context(new OS(osPlatform, osName, osVersion))));
    this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);
  }
  recognizeOnceAsyncImpl(recognitionMode) {
    return __awaiter5(this, void 0, void 0, function* () {
      Contracts.throwIfDisposed(this.privDisposed);
      const ret = new Deferred();
      yield this.implRecognizerStop();
      yield this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);
      const result = yield ret.promise;
      yield this.implRecognizerStop();
      return result;
    });
  }
  startContinuousRecognitionAsyncImpl(recognitionMode) {
    return __awaiter5(this, void 0, void 0, function* () {
      Contracts.throwIfDisposed(this.privDisposed);
      yield this.implRecognizerStop();
      yield this.privReco.recognize(recognitionMode, void 0, void 0);
    });
  }
  stopContinuousRecognitionAsyncImpl() {
    return __awaiter5(this, void 0, void 0, function* () {
      Contracts.throwIfDisposed(this.privDisposed);
      yield this.implRecognizerStop();
    });
  }
  implRecognizerStop() {
    return __awaiter5(this, void 0, void 0, function* () {
      if (this.privReco) {
        yield this.privReco.stopRecognizing();
      }
      return;
    });
  }
  static getAuthFromProperties(properties) {
    const subscriptionKey = properties.getProperty(PropertyId.SpeechServiceConnection_Key, void 0);
    const authentication = subscriptionKey && subscriptionKey !== "" ? new CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new CognitiveTokenAuthentication(() => {
      const authorizationToken = properties.getProperty(PropertyId.SpeechServiceAuthorization_Token, void 0);
      return Promise.resolve(authorizationToken);
    }, () => {
      const authorizationToken = properties.getProperty(PropertyId.SpeechServiceAuthorization_Token, void 0);
      return Promise.resolve(authorizationToken);
    });
    return authentication;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js
var __awaiter6 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SpeechRecognizer = class extends Recognizer {
  /**
   * SpeechRecognizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  constructor(speechConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    Contracts.throwIfNull(speechConfigImpl, "speechConfig");
    Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage), PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
    super(audioConfig, speechConfigImpl.properties, new SpeechConnectionFactory());
    this.privDisposedRecognizer = false;
  }
  /**
   * SpeechRecognizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
    const recognizer = new SpeechRecognizer(speechConfig, audioConfig);
    return recognizer;
  }
  /**
   * Gets the endpoint id of a customized speech model that is used for speech recognition.
   * @member SpeechRecognizer.prototype.endpointId
   * @function
   * @public
   * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.
   */
  get endpointId() {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_EndpointId, "00000000-0000-0000-0000-000000000000");
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member SpeechRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member SpeechRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * Gets the spoken language of recognition.
   * @member SpeechRecognizer.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} The spoken language of recognition.
   */
  get speechRecognitionLanguage() {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * Gets the output format of recognition.
   * @member SpeechRecognizer.prototype.outputFormat
   * @function
   * @public
   * @returns {OutputFormat} The output format of recognition.
   */
  get outputFormat() {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    if (this.properties.getProperty(OutputFormatPropertyName, OutputFormat[OutputFormat.Simple]) === OutputFormat[OutputFormat.Simple]) {
      return OutputFormat.Simple;
    } else {
      return OutputFormat.Detailed;
    }
  }
  /**
   * The collection of properties and their values defined for this SpeechRecognizer.
   * @member SpeechRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Starts speech recognition, and stops after the first utterance is recognized.
   * The task returns the recognition text as result.
   * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
   * so it is suitable only for single shot recognition
   * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
   * @member SpeechRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the SpeechRecognitionResult.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(cb, err) {
    marshalPromiseToCallbacks(this.recognizeOnceAsyncImpl(RecognitionMode.Interactive), cb, err);
  }
  /**
   * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(RecognitionMode.Conversation), cb, err);
  }
  /**
   * Stops continuous speech recognition.
   * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  /**
   * Starts speech recognition with keyword spotting, until
   * stopKeywordRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * Note: Key word spotting functionality is only available on the
   * Speech Devices SDK. This functionality is currently not included in the SDK itself.
   * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync
   * @function
   * @public
   * @param {KeywordRecognitionModel} model The keyword recognition model that
   * specifies the keyword to be recognized.
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startKeywordRecognitionAsync(model, cb, err) {
    Contracts.throwIfNull(model, "model");
    if (!!err) {
      err("Not yet implemented.");
    }
  }
  /**
   * Stops continuous speech recognition.
   * Note: Key word spotting functionality is only available on the
   * Speech Devices SDK. This functionality is currently not included in the SDK itself.
   * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopKeywordRecognitionAsync(cb) {
    if (!!cb) {
      cb();
    }
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member SpeechRecognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);
  }
  /**
   * Disposes any resources held by the object.
   * @member SpeechRecognizer.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - true if disposing the object.
   */
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter6(this, void 0, void 0, function* () {
      if (this.privDisposedRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedRecognizer = true;
        yield this.implRecognizerStop();
      }
      yield _super.dispose.call(this, disposing);
    });
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const configImpl = audioConfig;
    return new SpeechServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js
var __awaiter7 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var IntentRecognizer = class extends Recognizer {
  /**
   * Initializes an instance of the IntentRecognizer.
   * @constructor
   * @param {SpeechConfig} speechConfig - The set of configuration properties.
   * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer
   */
  constructor(speechConfig, audioConfig) {
    Contracts.throwIfNullOrUndefined(speechConfig, "speechConfig");
    const configImpl = speechConfig;
    Contracts.throwIfNullOrUndefined(configImpl, "speechConfig");
    super(audioConfig, configImpl.properties, new IntentConnectionFactory());
    this.privAddedIntents = [];
    this.privAddedLmIntents = {};
    this.privDisposedIntentRecognizer = false;
    this.privProperties = configImpl.properties;
    Contracts.throwIfNullOrWhitespace(this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage), PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
  }
  /**
   * Gets the spoken language of recognition.
   * @member IntentRecognizer.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} the spoken language of recognition.
   */
  get speechRecognitionLanguage() {
    Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member IntentRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.
   * @member IntentRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} value - Authorization token.
   */
  set authorizationToken(value) {
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, value);
  }
  /**
   * The collection of properties and their values defined for this IntentRecognizer.
   * @member IntentRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their
   * values defined for this IntentRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Starts intent recognition, and stops after the first utterance is recognized.
   * The task returns the recognition text and intent as result.
   * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
   * so it is suitable only for single shot recognition like command or query.
   * For long-running recognition, use StartContinuousRecognitionAsync() instead.
   * @member IntentRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(cb, err) {
    Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    if (Object.keys(this.privAddedLmIntents).length !== 0 || void 0 !== this.privUmbrellaIntent) {
      const context = this.buildSpeechContext();
      this.privReco.speechContext.setSection("intent", context.Intent);
      this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);
      const intentReco = this.privReco;
      intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);
    }
    marshalPromiseToCallbacks(this.recognizeOnceAsyncImpl(RecognitionMode.Interactive), cb, err);
  }
  /**
   * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * @member IntentRecognizer.prototype.startContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startContinuousRecognitionAsync(cb, err) {
    if (Object.keys(this.privAddedLmIntents).length !== 0 || void 0 !== this.privUmbrellaIntent) {
      const context = this.buildSpeechContext();
      this.privReco.speechContext.setSection("intent", context.Intent);
      this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);
      const intentReco = this.privReco;
      intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);
    }
    marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(RecognitionMode.Conversation), cb, err);
  }
  /**
   * Stops continuous intent recognition.
   * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  /**
   * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.
   * User must subscribe to events to receive recognition results.
   * Note: Key word spotting functionality is only available on the Speech Devices SDK.
   * This functionality is currently not included in the SDK itself.
   * @member IntentRecognizer.prototype.startKeywordRecognitionAsync
   * @function
   * @public
   * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.
   * @param cb - Callback invoked once the recognition has started.
   * @param err - Callback invoked in case of an error.
   */
  startKeywordRecognitionAsync(model, cb, err) {
    Contracts.throwIfNull(model, "model");
    if (!!err) {
      err("Not yet implemented.");
    }
  }
  /**
   * Stops continuous speech recognition.
   * Note: Key word spotting functionality is only available on the Speech Devices SDK.
   * This functionality is currently not included in the SDK itself.
   * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync
   * @function
   * @public
   * @param cb - Callback invoked once the recognition has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopKeywordRecognitionAsync(cb, err) {
    if (!!cb) {
      try {
        cb();
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
    }
  }
  /**
   * Adds a phrase that should be recognized as intent.
   * @member IntentRecognizer.prototype.addIntent
   * @function
   * @public
   * @param {string} intentId - A String that represents the identifier of the intent to be recognized.
   * @param {string} phrase - A String that specifies the phrase representing the intent.
   */
  addIntent(simplePhrase, intentId) {
    Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    Contracts.throwIfNullOrWhitespace(intentId, "intentId");
    Contracts.throwIfNullOrWhitespace(simplePhrase, "simplePhrase");
    this.privAddedIntents.push([intentId, simplePhrase]);
  }
  /**
   * Adds an intent from Language Understanding service for recognition.
   * @member IntentRecognizer.prototype.addIntentWithLanguageModel
   * @function
   * @public
   * @param {string} intentId - A String that represents the identifier of the intent
   * to be recognized. Ignored if intentName is empty.
   * @param {string} model - The intent model from Language Understanding service.
   * @param {string} intentName - The intent name defined in the intent model. If it
   * is empty, all intent names defined in the model will be added.
   */
  addIntentWithLanguageModel(intentId, model, intentName) {
    Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    Contracts.throwIfNullOrWhitespace(intentId, "intentId");
    Contracts.throwIfNull(model, "model");
    const modelImpl = model;
    Contracts.throwIfNullOrWhitespace(modelImpl.appId, "model.appId");
    this.privAddedLmIntents[intentId] = new AddedLmIntent(modelImpl, intentName);
  }
  /**
   * @summary Adds all intents from the specified Language Understanding Model.
   * @member IntentRecognizer.prototype.addAllIntents
   * @function
   * @public
   * @function
   * @public
   * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.
   * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.
   */
  addAllIntents(model, intentId) {
    Contracts.throwIfNull(model, "model");
    const modelImpl = model;
    Contracts.throwIfNullOrWhitespace(modelImpl.appId, "model.appId");
    this.privUmbrellaIntent = new AddedLmIntent(modelImpl, intentId);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member IntentRecognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);
    marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioImpl = audioConfig;
    return new IntentServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter7(this, void 0, void 0, function* () {
      if (this.privDisposedIntentRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedIntentRecognizer = true;
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  buildSpeechContext() {
    let appId;
    let region;
    let subscriptionKey;
    const refGrammers = [];
    if (void 0 !== this.privUmbrellaIntent) {
      appId = this.privUmbrellaIntent.modelImpl.appId;
      region = this.privUmbrellaIntent.modelImpl.region;
      subscriptionKey = this.privUmbrellaIntent.modelImpl.subscriptionKey;
    }
    for (const intentId of Object.keys(this.privAddedLmIntents)) {
      const addedLmIntent = this.privAddedLmIntents[intentId];
      if (appId === void 0) {
        appId = addedLmIntent.modelImpl.appId;
      } else {
        if (appId !== addedLmIntent.modelImpl.appId) {
          throw new Error("Intents must all be from the same LUIS model");
        }
      }
      if (region === void 0) {
        region = addedLmIntent.modelImpl.region;
      } else {
        if (region !== addedLmIntent.modelImpl.region) {
          throw new Error("Intents must all be from the same LUIS model in a single region");
        }
      }
      if (subscriptionKey === void 0) {
        subscriptionKey = addedLmIntent.modelImpl.subscriptionKey;
      } else {
        if (subscriptionKey !== addedLmIntent.modelImpl.subscriptionKey) {
          throw new Error("Intents must all use the same subscription key");
        }
      }
      const grammer = "luis/" + appId + "-PRODUCTION#" + intentId;
      refGrammers.push(grammer);
    }
    return {
      Intent: {
        id: appId,
        key: subscriptionKey === void 0 ? this.privProperties.getProperty(PropertyId[PropertyId.SpeechServiceConnection_Key]) : subscriptionKey,
        provider: "LUIS"
      },
      ReferenceGrammars: void 0 === this.privUmbrellaIntent ? refGrammers : ["luis/" + appId + "-PRODUCTION"]
    };
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js
var VoiceProfileType;
(function(VoiceProfileType2) {
  VoiceProfileType2[VoiceProfileType2["TextIndependentIdentification"] = 0] = "TextIndependentIdentification";
  VoiceProfileType2[VoiceProfileType2["TextDependentVerification"] = 1] = "TextDependentVerification";
  VoiceProfileType2[VoiceProfileType2["TextIndependentVerification"] = 2] = "TextIndependentVerification";
})(VoiceProfileType || (VoiceProfileType = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js
var ConnectionMessage2 = class {
};
var ConnectionMessageImpl = class {
  constructor(message) {
    this.privConnectionMessage = message;
    this.privProperties = new PropertyCollection();
    if (!!this.privConnectionMessage.headers[HeaderNames.ConnectionId]) {
      this.privProperties.setProperty(PropertyId.Speech_SessionId, this.privConnectionMessage.headers[HeaderNames.ConnectionId]);
    }
    Object.keys(this.privConnectionMessage.headers).forEach((header) => {
      this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);
    });
  }
  /**
   * The message path.
   */
  get path() {
    return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find((key) => key.toLowerCase() === "path".toLowerCase())];
  }
  /**
   * Checks to see if the ConnectionMessage is a text message.
   * See also IsBinaryMessage().
   */
  get isTextMessage() {
    return this.privConnectionMessage.messageType === MessageType.Text;
  }
  /**
   * Checks to see if the ConnectionMessage is a binary message.
   * See also GetBinaryMessage().
   */
  get isBinaryMessage() {
    return this.privConnectionMessage.messageType === MessageType.Binary;
  }
  /**
   * Gets the text message payload. Typically the text message content-type is
   * application/json. To determine other content-types use
   * Properties.GetProperty("Content-Type").
   */
  get TextMessage() {
    return this.privConnectionMessage.textBody;
  }
  /**
   * Gets the binary message payload.
   */
  get binaryMessage() {
    return this.privConnectionMessage.binaryBody;
  }
  /**
   * A collection of properties and their values defined for this <see cref="ConnectionMessage"/>.
   * Message headers can be accessed via this collection (e.g. "Content-Type").
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Returns a string that represents the connection message.
   */
  toString() {
    return "";
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js
var Connection = class {
  /**
   * Gets the Connection instance from the specified recognizer.
   * @param recognizer The recognizer associated with the connection.
   * @return The Connection instance of the recognizer.
   */
  static fromRecognizer(recognizer) {
    const recoBase = recognizer.internalData;
    const ret = new Connection();
    ret.privInternalData = recoBase;
    ret.setupEvents();
    return ret;
  }
  /**
   * Gets the Connection instance from the specified synthesizer.
   * @param synthesizer The synthesizer associated with the connection.
   * @return The Connection instance of the synthesizer.
   */
  static fromSynthesizer(synthesizer) {
    const synthBase = synthesizer.internalData;
    const ret = new Connection();
    ret.privInternalData = synthBase;
    ret.setupEvents();
    return ret;
  }
  /**
   * Starts to set up connection to the service.
   * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the
   * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect
   *
   * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
   * be notified when the connection is established.
   */
  openConnection(cb, err) {
    marshalPromiseToCallbacks(this.privInternalData.connect(), cb, err);
  }
  /**
   * Closes the connection the service.
   * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.
   *
   * If closeConnection() is called during recognition, recognition will fail and cancel with an error.
   */
  closeConnection(cb, err) {
    if (this.privInternalData instanceof SynthesisAdapterBase) {
      throw new Error("Disconnecting a synthesizer's connection is currently not supported");
    } else {
      marshalPromiseToCallbacks(this.privInternalData.disconnect(), cb, err);
    }
  }
  /**
   * Appends a parameter in a message to service.
   * Added in version 1.12.1.
   * @param path The path of the network message.
   * @param propertyName Name of the property
   * @param propertyValue Value of the property. This is a json string.
   */
  setMessageProperty(path, propertyName, propertyValue) {
    Contracts.throwIfNullOrWhitespace(propertyName, "propertyName");
    if (this.privInternalData instanceof ServiceRecognizerBase) {
      if (path.toLowerCase() !== "speech.context") {
        throw new Error("Only speech.context message property sets are currently supported for recognizer");
      } else {
        this.privInternalData.speechContext.setSection(propertyName, propertyValue);
      }
    } else if (this.privInternalData instanceof SynthesisAdapterBase) {
      if (path.toLowerCase() !== "synthesis.context") {
        throw new Error("Only synthesis.context message property sets are currently supported for synthesizer");
      } else {
        this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);
      }
    }
  }
  /**
   * Sends a message to the speech service.
   * Added in version 1.13.0.
   * @param path The WebSocket path of the message
   * @param payload The payload of the message. This is a json string or a ArrayBuffer.
   * @param success A callback to indicate success.
   * @param error A callback to indicate an error.
   */
  sendMessageAsync(path, payload, success, error) {
    marshalPromiseToCallbacks(this.privInternalData.sendNetworkMessage(path, payload), success, error);
  }
  /**
   * Dispose of associated resources.
   */
  close() {
  }
  setupEvents() {
    this.privEventListener = this.privInternalData.connectionEvents.attach((connectionEvent) => {
      if (connectionEvent.name === "ConnectionEstablishedEvent") {
        if (!!this.connected) {
          this.connected(new ConnectionEventArgs(connectionEvent.connectionId));
        }
      } else if (connectionEvent.name === "ConnectionClosedEvent") {
        if (!!this.disconnected) {
          this.disconnected(new ConnectionEventArgs(connectionEvent.connectionId));
        }
      } else if (connectionEvent.name === "ConnectionMessageSentEvent") {
        if (!!this.messageSent) {
          this.messageSent(new ConnectionMessageEventArgs(new ConnectionMessageImpl(connectionEvent.message)));
        }
      } else if (connectionEvent.name === "ConnectionMessageReceivedEvent") {
        if (!!this.messageReceived) {
          this.messageReceived(new ConnectionMessageEventArgs(new ConnectionMessageImpl(connectionEvent.message)));
        }
      }
    });
    this.privServiceEventListener = this.privInternalData.serviceEvents.attach((e) => {
      if (!!this.receivedServiceMessage) {
        this.receivedServiceMessage(new ServiceEventArgs(e.jsonString, e.name));
      }
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js
var __awaiter8 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var TranslationRecognizer = class extends Recognizer {
  /**
   * Initializes an instance of the TranslationRecognizer.
   * @constructor
   * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.
   * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
   * @param {IConnectionFactory} connectionFactory - An optional connection factory to use to generate the endpoint URIs, headers to set, etc...
   */
  constructor(speechConfig, audioConfig, connectionFactory) {
    const configImpl = speechConfig;
    Contracts.throwIfNull(configImpl, "speechConfig");
    super(audioConfig, configImpl.properties, connectionFactory || new TranslationConnectionFactory());
    this.privDisposedTranslationRecognizer = false;
    if (this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationVoice, void 0) !== void 0) {
      Contracts.throwIfNullOrWhitespace(this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationVoice), PropertyId[PropertyId.SpeechServiceConnection_TranslationVoice]);
    }
    Contracts.throwIfNullOrWhitespace(this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages), PropertyId[PropertyId.SpeechServiceConnection_TranslationToLanguages]);
    Contracts.throwIfNullOrWhitespace(this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage), PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
  }
  /**
   * Gets the language name that was set when the recognizer was created.
   * @member TranslationRecognizer.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} Gets the language name that was set when the recognizer was created.
   */
  get speechRecognitionLanguage() {
    Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * Gets target languages for translation that were set when the recognizer was created.
   * The language is specified in BCP-47 format. The translation will provide translated text for each of language.
   * @member TranslationRecognizer.prototype.targetLanguages
   * @function
   * @public
   * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.
   */
  get targetLanguages() {
    Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
  }
  /**
   * Gets the name of output voice.
   * @member TranslationRecognizer.prototype.voiceName
   * @function
   * @public
   * @returns {string} the name of output voice.
   */
  get voiceName() {
    Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationVoice, void 0);
  }
  /**
   * The collection of properties and their values defined for this TranslationRecognizer.
   * @member TranslationRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member TranslationRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member TranslationRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} value - Authorization token.
   */
  set authorizationToken(value) {
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, value);
  }
  /**
   * Starts recognition and translation, and stops after the first utterance is recognized.
   * The task returns the translation text as result.
   * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitable only
   * for single shot recognition like command or query. For long-running recognition,
   * use startContinuousRecognitionAsync() instead.
   * @member TranslationRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the result when the translation has completed.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(cb, err) {
    Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    marshalPromiseToCallbacks(this.recognizeOnceAsyncImpl(RecognitionMode.Conversation), cb, err);
  }
  /**
   * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.
   * User must subscribe to events to receive translation results.
   * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback that received the translation has started.
   * @param err - Callback invoked in case of an error.
   */
  startContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(RecognitionMode.Conversation), cb, err);
  }
  /**
   * Stops continuous recognition and translation.
   * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync
   * @function
   * @public
   * @param cb - Callback that received the translation has stopped.
   * @param err - Callback invoked in case of an error.
   */
  stopContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  /**
   * dynamically remove a language from list of target language
   * (can be used while recognition is ongoing)
   * @member TranslationRecognizer.prototype.removeTargetLanguage
   * @function
   * @param lang - language to be removed
   * @public
   */
  removeTargetLanguage(lang) {
    Contracts.throwIfNullOrUndefined(lang, "language to be removed");
    if (this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, void 0) !== void 0) {
      const languages = this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
      const index = languages.indexOf(lang);
      if (index > -1) {
        languages.splice(index, 1);
        this.properties.setProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
        this.updateLanguages(languages);
      }
    }
  }
  /**
   * dynamically add a language to list of target language
   * (can be used while recognition is ongoing)
   * @member TranslationRecognizer.prototype.addTargetLanguage
   * @function
   * @param lang - language to be added
   * @public
   */
  addTargetLanguage(lang) {
    Contracts.throwIfNullOrUndefined(lang, "language to be added");
    let languages = [];
    if (this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, void 0) !== void 0) {
      languages = this.properties.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
      if (!languages.includes(lang)) {
        languages.push(lang);
        this.properties.setProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
      }
    } else {
      this.properties.setProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages, lang);
      languages = [lang];
    }
    this.updateLanguages(languages);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member TranslationRecognizer.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
    marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);
  }
  /**
   * handles ConnectionEstablishedEvent for conversation translation scenarios.
   * @member TranslationRecognizer.prototype.onConnection
   * @function
   * @public
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  onConnection() {
  }
  /**
   * handles disconnection events for conversation translation scenarios.
   * @member TranslationRecognizer.prototype.onDisconnection
   * @function
   * @public
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  onDisconnection() {
    return __awaiter8(this, void 0, void 0, function* () {
    });
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter8(this, void 0, void 0, function* () {
      if (this.privDisposedTranslationRecognizer) {
        return;
      }
      this.privDisposedTranslationRecognizer = true;
      if (disposing) {
        yield this.implRecognizerStop();
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const configImpl = audioConfig;
    return new TranslationServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
  }
  updateLanguages(languages) {
    const conn = Connection.fromRecognizer(this);
    if (!!conn) {
      conn.setMessageProperty("speech.context", "translationcontext", { to: languages });
      conn.sendMessageAsync("event", JSON.stringify({
        id: "translation",
        name: "updateLanguage",
        to: languages
      }));
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js
var Translations = class {
  constructor() {
    this.privMap = new PropertyCollection();
  }
  /**
   * Get the languages in the object in a String array.
   * @member Translations.prototype.languages
   * @function
   * @public
   * @returns {string[]} languages in translations object.
   */
  get languages() {
    return this.privMap.keys;
  }
  /**
   * Returns the parameter value in type String. The parameter must have the same type as String.
   * Currently only String, int and bool are allowed.
   * If the name is not available, the specified defaultValue is returned.
   * @member Translations.prototype.get
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string} def - The default value which is returned if the parameter is not available in the collection.
   * @returns {string} value of the parameter.
   */
  get(key, def) {
    return this.privMap.getProperty(key, def);
  }
  /**
   * Sets the String value of the parameter specified by name.
   * @member Translations.prototype.set
   * @function
   * @public
   * @param {string} key - The parameter name.
   * @param {string} value - The value of the parameter.
   */
  set(key, value) {
    this.privMap.setProperty(key, value);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js
var NoMatchReason;
(function(NoMatchReason2) {
  NoMatchReason2[NoMatchReason2["NotRecognized"] = 0] = "NotRecognized";
  NoMatchReason2[NoMatchReason2["InitialSilenceTimeout"] = 1] = "InitialSilenceTimeout";
  NoMatchReason2[NoMatchReason2["InitialBabbleTimeout"] = 2] = "InitialBabbleTimeout";
})(NoMatchReason || (NoMatchReason = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js
var NoMatchDetails = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {NoMatchReason} reason - The no-match reason.
   */
  constructor(reason) {
    this.privReason = reason;
  }
  /**
   * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.
   * @member NoMatchDetails.fromResult
   * @function
   * @public
   * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}
   * result - The recognition result that was not recognized.
   * @returns {NoMatchDetails} The no match details object being created.
   */
  static fromResult(result) {
    const simpleSpeech = SimpleSpeechPhrase.fromJSON(result.json);
    let reason = NoMatchReason.NotRecognized;
    switch (simpleSpeech.RecognitionStatus) {
      case RecognitionStatus.BabbleTimeout:
        reason = NoMatchReason.InitialBabbleTimeout;
        break;
      case RecognitionStatus.InitialSilenceTimeout:
        reason = NoMatchReason.InitialSilenceTimeout;
        break;
      default:
        reason = NoMatchReason.NotRecognized;
        break;
    }
    return new NoMatchDetails(reason);
  }
  /**
   * The reason the recognition was canceled.
   * @member NoMatchDetails.prototype.reason
   * @function
   * @public
   * @returns {NoMatchReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js
var TranslationRecognitionCanceledEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} sessionid - The session id.
   * @param {CancellationReason} cancellationReason - The cancellation reason.
   * @param {string} errorDetails - Error details, if provided.
   * @param {TranslationRecognitionResult} result - The result.
   */
  constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {
    this.privCancelReason = cancellationReason;
    this.privErrorDetails = errorDetails;
    this.privResult = result;
    this.privSessionId = sessionid;
    this.privErrorCode = errorCode;
  }
  /**
   * Specifies the recognition result.
   * @member TranslationRecognitionCanceledEventArgs.prototype.result
   * @function
   * @public
   * @returns {TranslationRecognitionResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
  /**
   * Specifies the session identifier.
   * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId
   * @function
   * @public
   * @returns {string} the session identifier.
   */
  get sessionId() {
    return this.privSessionId;
  }
  /**
   * The reason the recognition was canceled.
   * @member TranslationRecognitionCanceledEventArgs.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privCancelReason;
  }
  /**
   * The error code in case of an unsuccessful recognition.
   * Added in version 1.1.0.
   * @return An error code that represents the error reason.
   */
  get errorCode() {
    return this.privErrorCode;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js
var IntentRecognitionCanceledEventArgs = class extends IntentRecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {CancellationReason} result - The result of the intent recognition.
   * @param {string} offset - The offset.
   * @param {IntentRecognitionResult} sessionId - The session id.
   */
  constructor(reason, errorDetails, errorCode, result, offset, sessionId) {
    super(result, offset, sessionId);
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privErrorCode = errorCode;
  }
  /**
   * The reason the recognition was canceled.
   * @member IntentRecognitionCanceledEventArgs.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * The error code in case of an unsuccessful recognition.
   * Added in version 1.1.0.
   * @return An error code that represents the error reason.
   */
  get errorCode() {
    return this.privErrorCode;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js
var CancellationDetailsBase = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {CancellationReason} reason - The cancellation reason.
   * @param {string} errorDetails - The error details, if provided.
   */
  constructor(reason, errorDetails, errorCode) {
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privErrorCode = errorCode;
  }
  /**
   * The reason the recognition was canceled.
   * @member CancellationDetailsBase.prototype.reason
   * @function
   * @public
   * @returns {CancellationReason} Specifies the reason canceled.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * In case of an unsuccessful recognition, provides details of the occurred error.
   * @member CancellationDetailsBase.prototype.errorDetails
   * @function
   * @public
   * @returns {string} A String that represents the error details.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
  /**
   * The error code in case of an unsuccessful recognition.
   * Added in version 1.1.0.
   * @return An error code that represents the error reason.
   */
  get ErrorCode() {
    return this.privErrorCode;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js
var CancellationDetails = class extends CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of CancellationDetails object for the canceled RecognitionResult.
   * @member CancellationDetails.fromResult
   * @function
   * @public
   * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.
   * @returns {CancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    let reason = CancellationReason.Error;
    let errorCode = CancellationErrorCode.NoError;
    if (result instanceof RecognitionResult && !!result.json) {
      const simpleSpeech = SimpleSpeechPhrase.fromJSON(result.json);
      reason = EnumTranslation.implTranslateCancelResult(simpleSpeech.RecognitionStatus);
    }
    if (!!result.properties) {
      errorCode = CancellationErrorCode[result.properties.getProperty(CancellationErrorCodePropertyName, CancellationErrorCode[CancellationErrorCode.NoError])];
    }
    return new CancellationDetails(reason, result.errorDetails || EnumTranslation.implTranslateErrorDetails(errorCode), errorCode);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js
var CancellationErrorCode;
(function(CancellationErrorCode2) {
  CancellationErrorCode2[CancellationErrorCode2["NoError"] = 0] = "NoError";
  CancellationErrorCode2[CancellationErrorCode2["AuthenticationFailure"] = 1] = "AuthenticationFailure";
  CancellationErrorCode2[CancellationErrorCode2["BadRequestParameters"] = 2] = "BadRequestParameters";
  CancellationErrorCode2[CancellationErrorCode2["TooManyRequests"] = 3] = "TooManyRequests";
  CancellationErrorCode2[CancellationErrorCode2["ConnectionFailure"] = 4] = "ConnectionFailure";
  CancellationErrorCode2[CancellationErrorCode2["ServiceTimeout"] = 5] = "ServiceTimeout";
  CancellationErrorCode2[CancellationErrorCode2["ServiceError"] = 6] = "ServiceError";
  CancellationErrorCode2[CancellationErrorCode2["RuntimeError"] = 7] = "RuntimeError";
  CancellationErrorCode2[CancellationErrorCode2["Forbidden"] = 8] = "Forbidden";
})(CancellationErrorCode || (CancellationErrorCode = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js
var ConnectionEventArgs = class extends SessionEventArgs {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js
var ServiceEventArgs = class extends SessionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} json - json payload of the USP message.
   */
  constructor(json, name, sessionId) {
    super(sessionId);
    this.privJsonResult = json;
    this.privEventName = name;
  }
  get jsonString() {
    return this.privJsonResult;
  }
  get eventName() {
    return this.privEventName;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js
var PhraseListGrammar = class {
  constructor(recogBase) {
    this.privGrammerBuilder = recogBase.dynamicGrammar;
  }
  /**
   * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.
   * @param recognizer The recognizer to add phrase lists to.
   */
  static fromRecognizer(recognizer) {
    const recoBase = recognizer.internalData;
    return new PhraseListGrammar(recoBase);
  }
  /**
   * Adds a single phrase to the current recognizer.
   * @param phrase Phrase to add.
   */
  addPhrase(phrase) {
    this.privGrammerBuilder.addPhrase(phrase);
  }
  /**
   * Adds multiple phrases to the current recognizer.
   * @param phrases Array of phrases to add.
   */
  addPhrases(phrases) {
    this.privGrammerBuilder.addPhrase(phrases);
  }
  /**
   * Clears all phrases added to the current recognizer.
   */
  clear() {
    this.privGrammerBuilder.clearPhrases();
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js
var DialogServiceConfig = class {
  /**
   * Creates an instance of DialogService config.
   * @constructor
   */
  constructor() {
    return;
  }
  /**
   * Sets the corresponding backend application identifier.
   * @member DialogServiceConfig.prototype.Conversation_ApplicationId
   * @function
   * @public
   * @param {string} value - The application identifier to set.
   */
  // eslint-disable-next-line @typescript-eslint/no-empty-function
  set applicationId(value) {
  }
  static get DialogTypes() {
    return {
      BotFramework: "bot_framework",
      CustomCommands: "custom_commands"
    };
  }
};
var DialogServiceConfigImpl = class extends DialogServiceConfig {
  /**
   * Creates an instance of dialogService config.
   */
  constructor() {
    super();
    this.privSpeechConfig = new SpeechConfigImpl();
  }
  /**
   * Provides access to custom properties.
   * @member DialogServiceConfigImpl.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The properties.
   */
  get properties() {
    return this.privSpeechConfig.properties;
  }
  /**
   * Gets the speech recognition language.
   * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   */
  get speechRecognitionLanguage() {
    return this.privSpeechConfig.speechRecognitionLanguage;
  }
  /**
   * Sets the speech recognition language.
   * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @param {string} value - The language to set.
   */
  set speechRecognitionLanguage(value) {
    Contracts.throwIfNullOrWhitespace(value, "value");
    this.privSpeechConfig.speechRecognitionLanguage = value;
  }
  get outputFormat() {
    return this.privSpeechConfig.outputFormat;
  }
  set outputFormat(value) {
    this.privSpeechConfig.outputFormat = value;
  }
  /**
   * Sets a named property as value
   * @member DialogServiceConfigImpl.prototype.setProperty
   * @function
   * @public
   * @param {PropertyId | string} name - The property to set.
   * @param {string} value - The value.
   */
  setProperty(name, value) {
    this.privSpeechConfig.setProperty(name, value);
  }
  /**
   * Sets a named property as value
   * @member DialogServiceConfigImpl.prototype.getProperty
   * @function
   * @public
   * @param {PropertyId | string} name - The property to get.
   * @param {string} def - The default value to return in case the property is not known.
   * @returns {string} The current value, or provided default, of the given property.
   */
  getProperty(name, def) {
    return this.privSpeechConfig.getProperty(name);
  }
  /**
   * Sets the proxy configuration.
   * Only relevant in Node.js environments.
   * Added in version 1.4.0.
   * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
   * @param proxyPort The port number of the proxy server.
   * @param proxyUserName The user name of the proxy server.
   * @param proxyPassword The password of the proxy server.
   */
  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.setProperty(PropertyId.SpeechServiceConnection_ProxyHostName, proxyHostName);
    this.setProperty(PropertyId.SpeechServiceConnection_ProxyPort, `${proxyPort}`);
    if (proxyUserName) {
      this.setProperty(PropertyId.SpeechServiceConnection_ProxyUserName, proxyUserName);
    }
    if (proxyPassword) {
      this.setProperty(PropertyId.SpeechServiceConnection_ProxyPassword, proxyPassword);
    }
  }
  setServiceProperty(name, value, channel) {
    this.privSpeechConfig.setServiceProperty(name, value);
  }
  /**
   * Dispose of associated resources.
   * @member DialogServiceConfigImpl.prototype.close
   * @function
   * @public
   */
  close() {
    return;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js
var BotFrameworkConfig = class extends DialogServiceConfigImpl {
  /**
   * Creates an instance of BotFrameworkConfig.
   */
  constructor() {
    super();
  }
  /**
   * Creates a bot framework configuration instance with the provided subscription information.
   * @member BotFrameworkConfig.fromSubscription
   * @function
   * @public
   * @param subscription Subscription key associated with the bot
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
   * resource name.
   * @returns {BotFrameworkConfig} A new bot framework configuration instance.
   */
  static fromSubscription(subscription, region, botId) {
    Contracts.throwIfNullOrWhitespace(subscription, "subscription");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const botFrameworkConfig = new DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(PropertyId.Conversation_DialogType, DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Key, subscription);
    botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    if (botId) {
      botFrameworkConfig.setProperty(PropertyId.Conversation_ApplicationId, botId);
    }
    return botFrameworkConfig;
  }
  /**
   * Creates a bot framework configuration instance for the specified authorization token and region.
   * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the
   * caller must refresh it by setting the authorizationToken property on the corresponding
   * DialogServiceConnector instance created with this config. The contents of configuration objects are copied
   * when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the
   * original configuration's authorization token. Create a new configuration instance or set the
   * SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create
   * further DialogServiceConnectors.
   * @member BotFrameworkConfig.fromAuthorizationToken
   * @function
   * @public
   * @param authorizationToken The authorization token associated with the bot
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
   * resource name.
   * @returns {BotFrameworkConfig} A new bot framework configuration instance.
   */
  static fromAuthorizationToken(authorizationToken, region, botId) {
    Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const botFrameworkConfig = new DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(PropertyId.Conversation_DialogType, DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
    botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    if (botId) {
      botFrameworkConfig.setProperty(PropertyId.Conversation_ApplicationId, botId);
    }
    return botFrameworkConfig;
  }
  /**
   * Creates an instance of a BotFrameworkConfig.
   * This method is intended only for users who use a non-default service host. The standard resource path will be
   * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.
   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
   * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken
   * property on the created BotFrameworkConfig instance.
   * Note: Added in version 1.15.0.
   * @member BotFrameworkConfig.fromHost
   * @function
   * @public
   * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.
   * wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in
   * wss://{host}.convai.speech.azure.us.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
   * token must be set.
   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
   * resource name.
   * @returns {BotFrameworkConfig} A new bot framework configuration instance.
   */
  static fromHost(host, subscriptionKey, botId) {
    Contracts.throwIfNullOrUndefined(host, "host");
    const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);
    Contracts.throwIfNullOrUndefined(resolvedHost, "resolvedHost");
    const botFrameworkConfig = new DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(PropertyId.Conversation_DialogType, DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Host, resolvedHost.toString());
    if (void 0 !== subscriptionKey) {
      botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return botFrameworkConfig;
  }
  /**
   * Creates an instance of a BotFrameworkConfig.
   * This method is intended only for users who use a non-standard service endpoint or parameters.
   * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
   * fromEndpoint method, and then set authorizationToken="token" on the created BotFrameworkConfig instance to
   * use the authorization token.
   * Note: Added in version 1.15.0.
   * @member BotFrameworkConfig.fromEndpoint
   * @function
   * @public
   * @param {URL} endpoint - The service endpoint to connect to.
   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
   * token must be set.
   * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.
   */
  static fromEndpoint(endpoint, subscriptionKey) {
    Contracts.throwIfNull(endpoint, "endpoint");
    const botFrameworkConfig = new DialogServiceConfigImpl();
    botFrameworkConfig.setProperty(PropertyId.Conversation_DialogType, DialogServiceConfig.DialogTypes.BotFramework);
    botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Endpoint, endpoint.toString());
    if (void 0 !== subscriptionKey) {
      botFrameworkConfig.setProperty(PropertyId.SpeechServiceConnection_Key, subscriptionKey);
    }
    return botFrameworkConfig;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js
var CustomCommandsConfig = class extends DialogServiceConfigImpl {
  /**
   * Creates an instance of CustomCommandsConfig.
   */
  constructor() {
    super();
  }
  /**
   * Creates an instance of the bot framework config with the specified subscription and region.
   * @member CustomCommandsConfig.fromSubscription
   * @function
   * @public
   * @param applicationId Speech Commands application id.
   * @param subscription Subscription key associated with the bot
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {CustomCommandsConfig} A new bot framework config.
   */
  static fromSubscription(applicationId, subscription, region) {
    Contracts.throwIfNullOrWhitespace(applicationId, "applicationId");
    Contracts.throwIfNullOrWhitespace(subscription, "subscription");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const customCommandsConfig = new DialogServiceConfigImpl();
    customCommandsConfig.setProperty(PropertyId.Conversation_DialogType, DialogServiceConfig.DialogTypes.CustomCommands);
    customCommandsConfig.setProperty(PropertyId.Conversation_ApplicationId, applicationId);
    customCommandsConfig.setProperty(PropertyId.SpeechServiceConnection_Key, subscription);
    customCommandsConfig.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    return customCommandsConfig;
  }
  /**
   * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.
   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
   * expires, the caller needs to refresh it by calling this setter with a new valid token.
   * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
   * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
   * @member CustomCommandsConfig.fromAuthorizationToken
   * @function
   * @public
   * @param applicationId Speech Commands application id.
   * @param authorizationToken The authorization token associated with the application.
   * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
   * @returns {CustomCommandsConfig} A new speech commands config.
   */
  static fromAuthorizationToken(applicationId, authorizationToken, region) {
    Contracts.throwIfNullOrWhitespace(applicationId, "applicationId");
    Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
    Contracts.throwIfNullOrWhitespace(region, "region");
    const customCommandsConfig = new DialogServiceConfigImpl();
    customCommandsConfig.setProperty(PropertyId.Conversation_DialogType, DialogServiceConfig.DialogTypes.CustomCommands);
    customCommandsConfig.setProperty(PropertyId.Conversation_ApplicationId, applicationId);
    customCommandsConfig.setProperty(PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
    customCommandsConfig.setProperty(PropertyId.SpeechServiceConnection_Region, region);
    return customCommandsConfig;
  }
  /**
   * Sets the corresponding backend application identifier.
   * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
   * @function
   * @public
   * @param {string} value - The application identifier to set.
   */
  set applicationId(value) {
    Contracts.throwIfNullOrWhitespace(value, "value");
    this.setProperty(PropertyId.Conversation_ApplicationId, value);
  }
  /**
   * Gets the corresponding backend application identifier.
   * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
   * @function
   * @public
   * @param {string} value - The application identifier to get.
   */
  get applicationId() {
    return this.getProperty(PropertyId.Conversation_ApplicationId);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js
var QueryParameterNames = class {
};
QueryParameterNames.BotId = "botid";
QueryParameterNames.CustomSpeechDeploymentId = "cid";
QueryParameterNames.CustomVoiceDeploymentId = "deploymentId";
QueryParameterNames.EnableAudioLogging = "storeAudio";
QueryParameterNames.EnableLanguageId = "lidEnabled";
QueryParameterNames.EnableWordLevelTimestamps = "wordLevelTimestamps";
QueryParameterNames.EndSilenceTimeoutMs = "endSilenceTimeoutMs";
QueryParameterNames.SegmentationSilenceTimeoutMs = "segmentationSilenceTimeoutMs";
QueryParameterNames.Format = "format";
QueryParameterNames.InitialSilenceTimeoutMs = "initialSilenceTimeoutMs";
QueryParameterNames.Language = "language";
QueryParameterNames.Profanity = "profanity";
QueryParameterNames.RequestBotStatusMessages = "enableBotMessageStatus";
QueryParameterNames.StableIntermediateThreshold = "stableIntermediateThreshold";
QueryParameterNames.StableTranslation = "stableTranslation";
QueryParameterNames.TestHooks = "testhooks";
QueryParameterNames.Postprocessing = "postprocessing";
QueryParameterNames.CtsMeetingId = "meetingId";
QueryParameterNames.CtsDeviceId = "deviceId";
QueryParameterNames.CtsIsParticipant = "isParticipant";

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js
var ConnectionFactoryBase = class {
  static getHostSuffix(region) {
    if (!!region) {
      if (region.toLowerCase().startsWith("china")) {
        return ".azure.cn";
      }
      if (region.toLowerCase().startsWith("usgov")) {
        return ".azure.us";
      }
    }
    return ".microsoft.com";
  }
  setCommonUrlParams(config, queryParams, endpoint) {
    const propertyIdToParameterMap = /* @__PURE__ */ new Map([
      [PropertyId.Speech_SegmentationSilenceTimeoutMs, QueryParameterNames.SegmentationSilenceTimeoutMs],
      [PropertyId.SpeechServiceConnection_EnableAudioLogging, QueryParameterNames.EnableAudioLogging],
      [PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, QueryParameterNames.EndSilenceTimeoutMs],
      [PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, QueryParameterNames.InitialSilenceTimeoutMs],
      [PropertyId.SpeechServiceResponse_PostProcessingOption, QueryParameterNames.Postprocessing],
      [PropertyId.SpeechServiceResponse_ProfanityOption, QueryParameterNames.Profanity],
      [PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, QueryParameterNames.EnableWordLevelTimestamps],
      [PropertyId.SpeechServiceResponse_StablePartialResultThreshold, QueryParameterNames.StableIntermediateThreshold]
    ]);
    propertyIdToParameterMap.forEach((parameterName, propertyId) => {
      this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);
    });
    const serviceProperties = JSON.parse(config.parameters.getProperty(ServicePropertiesPropertyName, "{}"));
    Object.keys(serviceProperties).forEach((value) => {
      queryParams[value] = serviceProperties[value];
    });
  }
  setUrlParameter(propId, parameterName, config, queryParams, endpoint) {
    const value = config.parameters.getProperty(propId, void 0);
    if (value && (!endpoint || endpoint.search(parameterName) === -1)) {
      queryParams[parameterName] = value.toLocaleLowerCase();
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js
var DialogConnectionFactory = class extends ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    const applicationId = config.parameters.getProperty(PropertyId.Conversation_ApplicationId, "");
    const dialogType = config.parameters.getProperty(PropertyId.Conversation_DialogType);
    const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region);
    const language = config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, "en-US");
    const requestTurnStatus = config.parameters.getProperty(PropertyId.Conversation_Request_Bot_Status_Messages, "true");
    const queryParams = {};
    queryParams[HeaderNames.ConnectionId] = connectionId;
    queryParams[QueryParameterNames.Format] = config.parameters.getProperty(OutputFormatPropertyName, OutputFormat[OutputFormat.Simple]).toLowerCase();
    queryParams[QueryParameterNames.Language] = language;
    queryParams[QueryParameterNames.RequestBotStatusMessages] = requestTurnStatus;
    if (applicationId) {
      queryParams[QueryParameterNames.BotId] = applicationId;
      if (dialogType === DialogServiceConfig.DialogTypes.CustomCommands) {
        queryParams[HeaderNames.CustomCommandsAppId] = applicationId;
      }
    }
    const resourceInfix = dialogType === DialogServiceConfig.DialogTypes.CustomCommands ? "commands/" : "";
    const version = dialogType === DialogServiceConfig.DialogTypes.CustomCommands ? "v1" : dialogType === DialogServiceConfig.DialogTypes.BotFramework ? "v3" : "v0";
    const headers = {};
    if (authInfo.token != null && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, "");
    if (!endpoint) {
      const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
      const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.BaseUrl}${hostSuffix}`);
      const standardizedHost = host.endsWith("/") ? host : host + "/";
      endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.ApiKey}/${version}`;
    }
    this.setCommonUrlParams(config, queryParams, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
};
DialogConnectionFactory.ApiKey = "api";
DialogConnectionFactory.BaseUrl = "convai.speech";

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js
var __awaiter9 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var DialogServiceConnector = class extends Recognizer {
  /**
   * Initializes an instance of the DialogServiceConnector.
   * @constructor
   * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.
   * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
   */
  constructor(dialogConfig, audioConfig) {
    const dialogServiceConfigImpl = dialogConfig;
    Contracts.throwIfNull(dialogConfig, "dialogConfig");
    super(audioConfig, dialogServiceConfigImpl.properties, new DialogConnectionFactory());
    this.isTurnComplete = true;
    this.privIsDisposed = false;
    this.privProperties = dialogServiceConfigImpl.properties.clone();
    const agentConfig = this.buildAgentConfig();
    this.privReco.agentConfig.set(agentConfig);
  }
  /**
   * Starts a connection to the service.
   * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.
   *
   * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
   * be notified when the connection is established.
   * @member DialogServiceConnector.prototype.connect
   * @function
   * @public
   */
  connect(cb, err) {
    marshalPromiseToCallbacks(this.privReco.connect(), cb, err);
  }
  /**
   * Closes the connection the service.
   * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.
   *
   * If disconnect() is called during a recognition, recognition will fail and cancel with an error.
   */
  disconnect(cb, err) {
    marshalPromiseToCallbacks(this.privReco.disconnect(), cb, err);
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member DialogServiceConnector.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Sets the authorization token used to communicate with the service.
   * @member DialogServiceConnector.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * The collection of properties and their values defined for this DialogServiceConnector.
   * @member DialogServiceConnector.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.
   */
  get properties() {
    return this.privProperties;
  }
  /** Gets the template for the activity generated by service from speech.
   * Properties from the template will be stamped on the generated activity.
   * It can be empty
   */
  get speechActivityTemplate() {
    return this.properties.getProperty(PropertyId.Conversation_Speech_Activity_Template);
  }
  /** Sets the template for the activity generated by service from speech.
   * Properties from the template will be stamped on the generated activity.
   * It can be null or empty.
   * Note: it has to be a valid Json object.
   */
  set speechActivityTemplate(speechActivityTemplate) {
    this.properties.setProperty(PropertyId.Conversation_Speech_Activity_Template, speechActivityTemplate);
  }
  /**
   * Starts recognition and stops after the first utterance is recognized.
   * @member DialogServiceConnector.prototype.listenOnceAsync
   * @function
   * @public
   * @param cb - Callback that received the result when the reco has completed.
   * @param err - Callback invoked in case of an error.
   */
  listenOnceAsync(cb, err) {
    if (this.isTurnComplete) {
      Contracts.throwIfDisposed(this.privIsDisposed);
      const callbackHolder = () => __awaiter9(this, void 0, void 0, function* () {
        yield this.privReco.connect();
        yield this.implRecognizerStop();
        this.isTurnComplete = false;
        const ret = new Deferred();
        yield this.privReco.recognize(RecognitionMode.Conversation, ret.resolve, ret.reject);
        const e = yield ret.promise;
        yield this.implRecognizerStop();
        return e;
      });
      const retPromise = callbackHolder();
      retPromise.catch(() => {
        this.dispose(true).catch(() => {
        });
      });
      marshalPromiseToCallbacks(retPromise.finally(() => {
        this.isTurnComplete = true;
      }), cb, err);
    }
  }
  sendActivityAsync(activity, cb, errCb) {
    marshalPromiseToCallbacks(this.privReco.sendMessage(activity), cb, errCb);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member DialogServiceConnector.prototype.close
   * @function
   * @public
   */
  close(cb, err) {
    Contracts.throwIfDisposed(this.privIsDisposed);
    marshalPromiseToCallbacks(this.dispose(true), cb, err);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter9(this, void 0, void 0, function* () {
      if (this.privIsDisposed) {
        return;
      }
      if (disposing) {
        this.privIsDisposed = true;
        yield this.implRecognizerStop();
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioSource = audioConfig;
    return new DialogServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);
  }
  buildAgentConfig() {
    const communicationType = this.properties.getProperty("Conversation_Communication_Type", "Default");
    return {
      botInfo: {
        commType: communicationType,
        commandsCulture: void 0,
        connectionId: this.properties.getProperty(PropertyId.Conversation_Agent_Connection_Id),
        conversationId: this.properties.getProperty(PropertyId.Conversation_Conversation_Id, void 0),
        fromId: this.properties.getProperty(PropertyId.Conversation_From_Id, void 0),
        ttsAudioFormat: this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, void 0)
      },
      version: 0.2
    };
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js
var ActivityReceivedEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {any} activity - The activity..
   */
  constructor(activity, audioStream) {
    this.privActivity = activity;
    this.privAudioStream = audioStream;
  }
  /**
   * Gets the received activity
   * @member ActivityReceivedEventArgs.prototype.activity
   * @function
   * @public
   * @returns {any} the received activity.
   */
  get activity() {
    return this.privActivity;
  }
  get audioStream() {
    return this.privAudioStream;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js
var TurnStatusResponsePayload = class {
  constructor(json) {
    this.privMessageStatusResponse = JSON.parse(json);
  }
  static fromJSON(json) {
    return new TurnStatusResponsePayload(json);
  }
  get interactionId() {
    return this.privMessageStatusResponse.interactionId;
  }
  get conversationId() {
    return this.privMessageStatusResponse.conversationId;
  }
  get statusCode() {
    switch (this.privMessageStatusResponse.statusCode) {
      case "Success":
        return 200;
      case "Failed":
        return 400;
      case "TimedOut":
        return 429;
      default:
        return this.privMessageStatusResponse.statusCode;
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js
var TurnStatusReceivedEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} turnStatus - The JSON-encoded turn status message.
   */
  constructor(turnStatus) {
    this.privTurnStatus = TurnStatusResponsePayload.fromJSON(turnStatus);
  }
  /**
   * Gets the interaction identifier associated with this turn status event.
   * @member TurnStatusReceivedEventArgs.prototype.interactionId
   * @function
   * @public
   * @returns {any} the received interaction id.
   */
  get interactionId() {
    return this.privTurnStatus.interactionId;
  }
  /**
   * Gets the conversation identifier associated with this turn status event.
   * @member TurnStatusReceivedEventArgs.prototype.conversationId
   * @function
   * @public
   * @returns {any} the received conversation id.
   */
  get conversationId() {
    return this.privTurnStatus.conversationId;
  }
  /**
   * Gets the received turn status code.
   * @member TurnStatusReceivedEventArgs.prototype.statusCode
   * @function
   * @public
   * @returns {number} the received turn status.
   */
  get statusCode() {
    return this.privTurnStatus.statusCode;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js
var ServicePropertyChannel;
(function(ServicePropertyChannel2) {
  ServicePropertyChannel2[ServicePropertyChannel2["UriQueryParameter"] = 0] = "UriQueryParameter";
})(ServicePropertyChannel || (ServicePropertyChannel = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js
var ProfanityOption;
(function(ProfanityOption2) {
  ProfanityOption2[ProfanityOption2["Masked"] = 0] = "Masked";
  ProfanityOption2[ProfanityOption2["Removed"] = 1] = "Removed";
  ProfanityOption2[ProfanityOption2["Raw"] = 2] = "Raw";
})(ProfanityOption || (ProfanityOption = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js
var __awaiter10 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var BaseAudioPlayer = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.
   */
  constructor(audioFormat) {
    this.audioContext = null;
    this.gainNode = null;
    this.autoUpdateBufferTimer = 0;
    if (audioFormat === void 0) {
      audioFormat = AudioStreamFormat.getDefaultInputFormat();
    }
    this.init(audioFormat);
  }
  /**
   * play Audio sample
   * @param newAudioData audio data to be played.
   */
  playAudioSample(newAudioData, cb, err) {
    try {
      this.ensureInitializedContext();
      const audioData = this.formatAudioData(newAudioData);
      const newSamplesData = new Float32Array(this.samples.length + audioData.length);
      newSamplesData.set(this.samples, 0);
      newSamplesData.set(audioData, this.samples.length);
      this.samples = newSamplesData;
      if (!!cb) {
        cb();
      }
    } catch (e) {
      if (!!err) {
        err(e);
      }
    }
  }
  /**
   * stops audio and clears the buffers
   */
  stopAudio(cb, err) {
    if (this.audioContext !== null) {
      this.samples = new Float32Array();
      clearInterval(this.autoUpdateBufferTimer);
      this.audioContext.close().then(() => {
        if (!!cb) {
          cb();
        }
      }, (error) => {
        if (!!err) {
          err(error);
        }
      });
      this.audioContext = null;
    }
  }
  init(audioFormat) {
    this.audioFormat = audioFormat;
    this.samples = new Float32Array();
  }
  ensureInitializedContext() {
    if (this.audioContext === null) {
      this.createAudioContext();
      const timerPeriod = 200;
      this.autoUpdateBufferTimer = setInterval(() => {
        this.updateAudioBuffer();
      }, timerPeriod);
    }
  }
  createAudioContext() {
    this.audioContext = AudioStreamFormatImpl.getAudioContext();
    this.gainNode = this.audioContext.createGain();
    this.gainNode.gain.value = 1;
    this.gainNode.connect(this.audioContext.destination);
    this.startTime = this.audioContext.currentTime;
  }
  formatAudioData(audioData) {
    switch (this.audioFormat.bitsPerSample) {
      case 8:
        return this.formatArrayBuffer(new Int8Array(audioData), 128);
      case 16:
        return this.formatArrayBuffer(new Int16Array(audioData), 32768);
      case 32:
        return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);
      default:
        throw new InvalidOperationError("Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time");
    }
  }
  formatArrayBuffer(audioData, maxValue) {
    const float32Data = new Float32Array(audioData.length);
    for (let i = 0; i < audioData.length; i++) {
      float32Data[i] = audioData[i] / maxValue;
    }
    return float32Data;
  }
  updateAudioBuffer() {
    if (this.samples.length === 0) {
      return;
    }
    const channelCount = this.audioFormat.channels;
    const bufferSource = this.audioContext.createBufferSource();
    const frameCount = this.samples.length / channelCount;
    const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);
    for (let channel = 0; channel < channelCount; channel++) {
      let channelOffset = channel;
      const audioData = audioBuffer.getChannelData(channel);
      for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {
        audioData[i] = this.samples[channelOffset];
      }
    }
    if (this.startTime < this.audioContext.currentTime) {
      this.startTime = this.audioContext.currentTime;
    }
    bufferSource.buffer = audioBuffer;
    bufferSource.connect(this.gainNode);
    bufferSource.start(this.startTime);
    this.startTime += audioBuffer.duration;
    this.samples = new Float32Array();
  }
  playAudio(audioData) {
    return __awaiter10(this, void 0, void 0, function* () {
      if (this.audioContext === null) {
        this.createAudioContext();
      }
      const source = this.audioContext.createBufferSource();
      const destination = this.audioContext.destination;
      yield this.audioContext.decodeAudioData(audioData, (newBuffer) => {
        source.buffer = newBuffer;
        source.connect(destination);
        source.start(0);
      });
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js
var ConnectionMessageEventArgs = class {
  constructor(message) {
    this.privConnectionMessage = message;
  }
  /**
   * Gets the <see cref="ConnectionMessage"/> associated with this <see cref="ConnectionMessageEventArgs"/>.
   */
  get message() {
    return this.privConnectionMessage;
  }
  /**
   * Returns a string that represents the connection message event.
   */
  toString() {
    return "Message: " + this.privConnectionMessage.toString();
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js
var VoiceProfile = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} profileId - profileId of this Voice Profile.
   * @param {VoiceProfileType} profileType - profileType of this Voice Profile.
   */
  constructor(profileId, profileType) {
    this.privId = profileId;
    this.privProfileType = profileType;
  }
  /**
   * profileId of this Voice Profile instance
   * @member VoiceProfile.prototype.profileId
   * @function
   * @public
   * @returns {string} profileId of this Voice Profile instance.
   */
  get profileId() {
    return this.privId;
  }
  /**
   * profileType of this Voice Profile instance
   * @member VoiceProfile.prototype.profileType
   * @function
   * @public
   * @returns {VoiceProfileType} profile type of this Voice Profile instance.
   */
  get profileType() {
    return this.privProfileType;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js
var VoiceProfileEnrollmentResult = class {
  constructor(reason, json, statusText) {
    this.privReason = reason;
    this.privProperties = new PropertyCollection();
    if (this.privReason !== ResultReason.Canceled) {
      if (!!json) {
        this.privDetails = JSON.parse(json);
        if (this.privDetails.enrollmentStatus.toLowerCase() === "enrolling") {
          this.privReason = ResultReason.EnrollingVoiceProfile;
        }
      }
    } else {
      this.privErrorDetails = statusText;
      this.privProperties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[CancellationErrorCode.ServiceError]);
    }
  }
  get reason() {
    return this.privReason;
  }
  get enrollmentsCount() {
    return this.privDetails.enrollmentsCount;
  }
  get enrollmentsLength() {
    return this.privDetails.enrollmentsLength;
  }
  get properties() {
    return this.privProperties;
  }
  get enrollmentResultDetails() {
    return this.privDetails;
  }
  get errorDetails() {
    return this.privErrorDetails;
  }
  static FromIdentificationProfileList(json) {
    const results = [];
    for (const item of json.value) {
      const reason = item.enrollmentStatus.toLowerCase() === "enrolling" ? ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === "enrolled" ? ResultReason.EnrolledVoiceProfile : ResultReason.Canceled;
      const result = new VoiceProfileEnrollmentResult(reason, null, null);
      result.privDetails = this.getIdentificationDetails(item);
      results.push(result);
    }
    return results;
  }
  static FromVerificationProfileList(json) {
    const results = [];
    for (const item of json.value) {
      const reason = item.enrollmentStatus.toLowerCase() === "enrolling" ? ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === "enrolled" ? ResultReason.EnrolledVoiceProfile : ResultReason.Canceled;
      const result = new VoiceProfileEnrollmentResult(reason, null, null);
      result.privDetails = this.getVerificationDetails(item);
      results.push(result);
    }
    return results;
  }
  static getIdentificationDetails(json) {
    return {
      audioLength: json.audioLength ? parseFloat(json.audioLength) : 0,
      audioSpeechLength: json.audioSpeechLength ? parseFloat(json.audioSpeechLength) : 0,
      enrollmentStatus: json.enrollmentStatus,
      enrollmentsCount: json.enrollmentsCount || 0,
      enrollmentsLength: json.enrollmentsLength ? parseFloat(json.enrollmentsLength) : 0,
      enrollmentsSpeechLength: json.enrollmentsSpeechLength ? parseFloat(json.enrollmentsSpeechLength) : 0,
      profileId: json.profileId || json.identificationProfileId,
      remainingEnrollmentsSpeechLength: json.remainingEnrollmentsSpeechLength ? parseFloat(json.remainingEnrollmentsSpeechLength) : 0
    };
  }
  static getVerificationDetails(json) {
    return {
      audioLength: json.audioLength ? parseFloat(json.audioLength) : 0,
      audioSpeechLength: json.audioSpeechLength ? parseFloat(json.audioSpeechLength) : 0,
      enrollmentStatus: json.enrollmentStatus,
      enrollmentsCount: json.enrollmentsCount,
      enrollmentsLength: json.enrollmentsLength ? parseFloat(json.enrollmentsLength) : 0,
      enrollmentsSpeechLength: json.enrollmentsSpeechLength ? parseFloat(json.enrollmentsSpeechLength) : 0,
      profileId: json.profileId || json.verificationProfileId,
      remainingEnrollmentsCount: json.remainingEnrollments || json.remainingEnrollmentsCount,
      remainingEnrollmentsSpeechLength: json.remainingEnrollmentsSpeechLength ? parseFloat(json.remainingEnrollmentsSpeechLength) : 0
    };
  }
};
var VoiceProfileEnrollmentCancellationDetails = class extends CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of VoiceProfileEnrollmentCancellationDetails object for the canceled VoiceProfileEnrollmentResult.
   * @member VoiceProfileEnrollmentCancellationDetails.fromResult
   * @function
   * @public
   * @param {VoiceProfileEnrollmentResult} result - The result that was canceled.
   * @returns {VoiceProfileEnrollmentCancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    const reason = CancellationReason.Error;
    let errorCode = CancellationErrorCode.NoError;
    if (!!result.properties) {
      errorCode = CancellationErrorCode[result.properties.getProperty(CancellationErrorCodePropertyName, CancellationErrorCode[CancellationErrorCode.NoError])];
    }
    return new VoiceProfileEnrollmentCancellationDetails(reason, result.errorDetails, errorCode);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js
var VoiceProfileResult = class {
  constructor(reason, statusText) {
    this.privReason = reason;
    this.privProperties = new PropertyCollection();
    if (reason === ResultReason.Canceled) {
      Contracts.throwIfNullOrUndefined(statusText, "statusText");
      this.privErrorDetails = statusText;
      this.privProperties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[CancellationErrorCode.ServiceError]);
    }
  }
  get reason() {
    return this.privReason;
  }
  get properties() {
    return this.privProperties;
  }
  get errorDetails() {
    return this.privErrorDetails;
  }
};
var VoiceProfileCancellationDetails = class extends CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.
   * @member VoiceProfileCancellationDetails.fromResult
   * @function
   * @public
   * @param {VoiceProfileResult} result - The result that was canceled.
   * @returns {VoiceProfileCancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    const reason = CancellationReason.Error;
    let errorCode = CancellationErrorCode.NoError;
    if (!!result.properties) {
      errorCode = CancellationErrorCode[result.properties.getProperty(CancellationErrorCodePropertyName, CancellationErrorCode[CancellationErrorCode.NoError])];
    }
    return new VoiceProfileCancellationDetails(reason, result.errorDetails, errorCode);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js
var VoiceProfilePhraseResult = class extends VoiceProfileResult {
  constructor(reason, statusText, type2, phraseArray) {
    super(reason, statusText);
    this.privPhrases = [];
    Contracts.throwIfNullOrUndefined(phraseArray, "phrase array");
    this.privType = type2;
    if (!!phraseArray && !!phraseArray[0]) {
      this.privPhrases = phraseArray;
    }
  }
  get phrases() {
    return this.privPhrases;
  }
  get type() {
    return this.privType;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js
var __awaiter11 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var VoiceProfileClient = class extends Recognizer {
  /**
   * VoiceProfileClient constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer (authentication key, region, &c)
   */
  constructor(speechConfig) {
    Contracts.throwIfNullOrUndefined(speechConfig, "speechConfig");
    const speechConfigImpl = speechConfig;
    Contracts.throwIfNull(speechConfigImpl, "speechConfig");
    super(AudioConfig.fromStreamInput(AudioInputStream.createPushStream()), speechConfigImpl.properties, new VoiceProfileConnectionFactory());
    this.privProperties = speechConfigImpl.properties.clone();
    this.privVoiceAdapter = this.privReco;
    this.privDisposedVoiceAdapter = false;
  }
  /**
   * The collection of properties and their values defined for this VoiceProfileClient.
   * @member VoiceProfileClient.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this VoiceProfileClient.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member VoiceProfileClient.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member VoiceProfileClient.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * Create a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.createProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfileType} profileType Type of Voice Profile to be created
   * @param {string} lang Language string (locale) for Voice Profile
   * @return {Promise<VoiceProfile>} - Promise of a VoiceProfile.
   */
  createProfileAsync(profileType, lang) {
    return __awaiter11(this, void 0, void 0, function* () {
      const profileIds = yield this.privVoiceAdapter.createProfile(profileType, lang);
      return new VoiceProfile(profileIds[0], profileType);
    });
  }
  /**
   * Get current information of a voice profile
   * @member VoiceProfileClient.prototype.retrieveEnrollmentResultAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to retrieve info for
   * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.
   */
  retrieveEnrollmentResultAsync(profile) {
    return __awaiter11(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.retrieveEnrollmentResult(profile);
    });
  }
  /**
   * Get all voice profiles on account with given voice profile type
   * @member VoiceProfileClient.prototype.getAllProfilesAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfileType} profileType profile type (identification/verification) for which to list profiles
   * @return {Promise<VoiceProfileEnrollmentResult[]>} - Promise of an array of VoiceProfileEnrollmentResults.
   */
  getAllProfilesAsync(profileType) {
    return __awaiter11(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.getAllProfiles(profileType);
    });
  }
  /**
   * Get valid authorization phrases for voice profile enrollment
   * @member VoiceProfileClient.prototype.getActivationPhrasesAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfileType} profileType Profile Type to get activation phrases for
   * @param {string} lang Language string (locale) for Voice Profile
   */
  getActivationPhrasesAsync(profileType, lang) {
    return __awaiter11(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.getActivationPhrases(profileType, lang);
    });
  }
  /**
   * Create a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.enrollProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to create enrollment for
   * @param {AudioConfig} audioConfig source info from which to create enrollment
   * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.
   */
  enrollProfileAsync(profile, audioConfig) {
    return __awaiter11(this, void 0, void 0, function* () {
      const configImpl = audioConfig;
      Contracts.throwIfNullOrUndefined(configImpl, "audioConfig");
      this.audioConfig = audioConfig;
      this.privVoiceAdapter.SpeakerAudioSource = configImpl;
      return this.privVoiceAdapter.enrollProfile(profile);
    });
  }
  /**
   * Delete a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.deleteProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to be deleted
   * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.
   */
  deleteProfileAsync(profile) {
    return __awaiter11(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.deleteProfile(profile);
    });
  }
  /**
   * Remove all enrollments for a speaker recognition voice profile
   * @member VoiceProfileClient.prototype.resetProfileAsync
   * @function
   * @public
   * @async
   * @param {VoiceProfile} profile Voice Profile to be reset
   * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.
   */
  resetProfileAsync(profile) {
    return __awaiter11(this, void 0, void 0, function* () {
      return this.privVoiceAdapter.resetProfile(profile);
    });
  }
  /**
   * Clean up object and close underlying connection
   * @member VoiceProfileClient.prototype.close
   * @function
   * @async
   * @public
   */
  close() {
    return __awaiter11(this, void 0, void 0, function* () {
      yield this.dispose(true);
    });
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioImpl = audioConfig;
    return new VoiceServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter11(this, void 0, void 0, function* () {
      if (this.privDisposedVoiceAdapter) {
        return;
      }
      this.privDisposedVoiceAdapter = true;
      if (disposing) {
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.properties);
  }
  getResult(result, successReason) {
    const response = new VoiceProfileResult(result.ok ? successReason : ResultReason.Canceled, result.statusText);
    return response;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js
var __awaiter12 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SpeakerRecognizer = class extends Recognizer {
  /**
   * Initializes an instance of the SpeakerRecognizer.
   * @constructor
   * @param {SpeechConfig} speechConfig - The set of configuration properties.
   * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer
   */
  constructor(speechConfig, audioConfig) {
    Contracts.throwIfNullOrUndefined(speechConfig, "speechConfig");
    const configImpl = speechConfig;
    Contracts.throwIfNullOrUndefined(configImpl, "speechConfig");
    super(audioConfig, configImpl.properties, new SpeakerRecognitionConnectionFactory());
    this.privAudioConfigImpl = audioConfig;
    Contracts.throwIfNull(this.privAudioConfigImpl, "audioConfig");
    this.privDisposedSpeakerRecognizer = false;
    this.privProperties = configImpl.properties;
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member SpeakerRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member SpeakerRecognizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * The collection of properties and their values defined for this SpeakerRecognizer.
   * @member SpeakerRecognizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeakerRecognizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Get recognition result for model using given audio
   * @member SpeakerRecognizer.prototype.recognizeOnceAsync
   * @function
   * @public
   * @async
   * @param {SpeakerIdentificationModel | SpeakerVerificationModel} model Model containing Voice Profiles to be identified
   * @param cb - Callback invoked once result is returned.
   * @param err - Callback invoked in case of an error.
   */
  recognizeOnceAsync(model) {
    return __awaiter12(this, void 0, void 0, function* () {
      Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);
      return this.recognizeSpeakerOnceAsyncImpl(model);
    });
  }
  /**
   * Included for compatibility
   * @member SpeakerRecognizer.prototype.close
   * @function
   * @public
   * @async
   */
  close() {
    return __awaiter12(this, void 0, void 0, function* () {
      Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);
      yield this.dispose(true);
    });
  }
  recognizeSpeakerOnceAsyncImpl(model) {
    return __awaiter12(this, void 0, void 0, function* () {
      Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);
      yield this.implRecognizerStop();
      const result = yield this.privReco.recognizeSpeaker(model);
      yield this.implRecognizerStop();
      return result;
    });
  }
  implRecognizerStop() {
    return __awaiter12(this, void 0, void 0, function* () {
      if (this.privReco) {
        yield this.privReco.stopRecognizing();
      }
      return;
    });
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.privProperties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioImpl = audioConfig;
    return new SpeakerServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);
  }
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter12(this, void 0, void 0, function* () {
      if (this.privDisposedSpeakerRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedSpeakerRecognizer = true;
        yield _super.dispose.call(this, disposing);
      }
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js
var SpeakerIdentificationModel = class {
  constructor(profiles) {
    this.privVoiceProfiles = [];
    this.privProfileIds = [];
    Contracts.throwIfNullOrUndefined(profiles, "VoiceProfiles");
    if (profiles.length === 0) {
      throw new Error("Empty Voice Profiles array");
    }
    for (const profile of profiles) {
      if (profile.profileType !== VoiceProfileType.TextIndependentIdentification) {
        throw new Error("Identification model can only be created from Identification profile: " + profile.profileId);
      }
      this.privVoiceProfiles.push(profile);
      this.privProfileIds.push(profile.profileId);
    }
  }
  static fromProfiles(profiles) {
    return new SpeakerIdentificationModel(profiles);
  }
  get voiceProfileIds() {
    return this.privProfileIds.join(",");
  }
  get profileIds() {
    return this.privProfileIds;
  }
  get scenario() {
    return "TextIndependentIdentification";
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js
var SpeakerVerificationModel = class {
  constructor(profile) {
    Contracts.throwIfNullOrUndefined(profile, "VoiceProfile");
    if (profile.profileType === VoiceProfileType.TextIndependentIdentification) {
      throw new Error("Verification model cannot be created from Identification profile");
    }
    this.privVoiceProfile = profile;
  }
  static fromProfile(profile) {
    return new SpeakerVerificationModel(profile);
  }
  get voiceProfile() {
    return this.privVoiceProfile;
  }
  get profileIds() {
    return [this.voiceProfile.profileId];
  }
  get scenario() {
    if (this.voiceProfile.profileType === VoiceProfileType.TextDependentVerification) {
      return "TextDependentVerification";
    } else {
      return "TextIndependentVerification";
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js
var LanguageIdMode;
(function(LanguageIdMode2) {
  LanguageIdMode2[LanguageIdMode2["AtStart"] = 0] = "AtStart";
  LanguageIdMode2[LanguageIdMode2["Continuous"] = 1] = "Continuous";
})(LanguageIdMode || (LanguageIdMode = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js
var AutoDetectSourceLanguageConfig = class {
  constructor() {
    this.privProperties = new PropertyCollection();
    this.privProperties.setProperty(PropertyId.SpeechServiceConnection_LanguageIdMode, "AtStart");
    this.privLanguageIdMode = LanguageIdMode.AtStart;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.fromOpenRange
   * @function
   * @public
   * Only [[SpeechSynthesizer]] supports source language auto detection from open range,
   * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.
   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.
   */
  static fromOpenRange() {
    const config = new AutoDetectSourceLanguageConfig();
    config.properties.setProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, AutoDetectSourceLanguagesOpenRangeOptionName);
    return config;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.fromLanguages
   * @function
   * @public
   * @param {string[]} languages Comma-separated string of languages (eg. "en-US,fr-FR") to populate properties of config.
   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.
   */
  static fromLanguages(languages) {
    Contracts.throwIfArrayEmptyOrWhitespace(languages, "languages");
    const config = new AutoDetectSourceLanguageConfig();
    config.properties.setProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());
    return config;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs
   * @function
   * @public
   * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.
   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.
   */
  static fromSourceLanguageConfigs(configs) {
    if (configs.length < 1) {
      throw new Error("Expected non-empty SourceLanguageConfig array.");
    }
    const autoConfig = new AutoDetectSourceLanguageConfig();
    const langs = [];
    configs.forEach((config) => {
      langs.push(config.language);
      if (config.endpointId !== void 0 && config.endpointId !== "") {
        const customProperty = config.language + PropertyId.SpeechServiceConnection_EndpointId.toString();
        autoConfig.properties.setProperty(customProperty, config.endpointId);
      }
    });
    autoConfig.properties.setProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());
    return autoConfig;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.prototype.properties
   * @function
   * @public
   * @return {PropertyCollection} Properties of the config.
   * @summary Gets an auto detected language config properties
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * @member AutoDetectSourceLanguageConfig.prototype.mode
   * @function
   * @public
   * @param {LanguageIdMode} mode LID mode desired.
   * @summary Sets LID operation to desired mode
   */
  set mode(mode) {
    if (mode === LanguageIdMode.Continuous) {
      this.privProperties.setProperty(PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "2");
      this.privProperties.setProperty(PropertyId.SpeechServiceConnection_LanguageIdMode, "Continuous");
    } else {
      this.privProperties.setProperty(PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "1");
      this.privProperties.setProperty(PropertyId.SpeechServiceConnection_LanguageIdMode, "AtStart");
    }
    this.privLanguageIdMode = mode;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js
var AutoDetectSourceLanguageResult = class {
  constructor(language, languageDetectionConfidence) {
    Contracts.throwIfNullOrUndefined(language, "language");
    Contracts.throwIfNullOrUndefined(languageDetectionConfidence, "languageDetectionConfidence");
    this.privLanguage = language;
    this.privLanguageDetectionConfidence = languageDetectionConfidence;
  }
  /**
   * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.
   * @member AutoDetectSourceLanguageResult.fromResult
   * @function
   * @public
   * @param {SpeechRecognitionResult} result - The recognition result.
   * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.
   */
  static fromResult(result) {
    return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);
  }
  get language() {
    return this.privLanguage;
  }
  get languageDetectionConfidence() {
    return this.privLanguageDetectionConfidence;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js
var SourceLanguageConfig = class {
  constructor(language, endpointId) {
    Contracts.throwIfNullOrUndefined(language, "language");
    this.privLanguage = language;
    this.privEndpointId = endpointId;
  }
  /**
   * @member SourceLanguageConfig.fromLanguage
   * @function
   * @public
   * @param {string} language language (eg. "en-US") value of config.
   * @param {string?} endpointId endpointId of model bound to given language of config.
   * @return {SourceLanguageConfig} Instance of SourceLanguageConfig
   * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.
   * Added in version 1.13.0.
   */
  static fromLanguage(language, endpointId) {
    return new SourceLanguageConfig(language, endpointId);
  }
  get language() {
    return this.privLanguage;
  }
  get endpointId() {
    return this.privEndpointId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js
var SpeakerRecognitionResultType;
(function(SpeakerRecognitionResultType2) {
  SpeakerRecognitionResultType2[SpeakerRecognitionResultType2["Verify"] = 0] = "Verify";
  SpeakerRecognitionResultType2[SpeakerRecognitionResultType2["Identify"] = 1] = "Identify";
})(SpeakerRecognitionResultType || (SpeakerRecognitionResultType = {}));
var SpeakerRecognitionResult = class {
  constructor(response, resultReason = ResultReason.RecognizedSpeaker, cancellationErrorCode = CancellationErrorCode.NoError, errorDetails = "") {
    this.privProperties = new PropertyCollection();
    const resultType = response.scenario === "TextIndependentIdentification" ? SpeakerRecognitionResultType.Identify : SpeakerRecognitionResultType.Verify;
    this.privReason = resultReason;
    if (this.privReason !== ResultReason.Canceled) {
      if (resultType === SpeakerRecognitionResultType.Identify) {
        this.privProfileId = response.identificationResult.identifiedProfile.profileId;
        this.privScore = response.identificationResult.identifiedProfile.score;
        this.privReason = ResultReason.RecognizedSpeakers;
      } else {
        this.privScore = response.verificationResult.score;
        if (response.verificationResult.recognitionResult.toLowerCase() !== "accept") {
          this.privReason = ResultReason.NoMatch;
        }
        if (response.verificationResult.profileId !== void 0 && response.verificationResult.profileId !== "") {
          this.privProfileId = response.verificationResult.profileId;
        }
      }
    } else {
      this.privErrorDetails = errorDetails;
      this.privProperties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[cancellationErrorCode]);
    }
    this.privProperties.setProperty(PropertyId.SpeechServiceResponse_JsonResult, JSON.stringify(response));
  }
  get properties() {
    return this.privProperties;
  }
  get reason() {
    return this.privReason;
  }
  get profileId() {
    return this.privProfileId;
  }
  get errorDetails() {
    return this.privErrorDetails;
  }
  get score() {
    return this.privScore;
  }
};
var SpeakerRecognitionCancellationDetails = class extends CancellationDetailsBase {
  constructor(reason, errorDetails, errorCode) {
    super(reason, errorDetails, errorCode);
  }
  /**
   * Creates an instance of SpeakerRecognitionCancellationDetails object for the canceled SpeakerRecognitionResult
   * @member SpeakerRecognitionCancellationDetails.fromResult
   * @function
   * @public
   * @param {SpeakerRecognitionResult} result - The result that was canceled.
   * @returns {SpeakerRecognitionCancellationDetails} The cancellation details object being created.
   */
  static fromResult(result) {
    const reason = CancellationReason.Error;
    let errorCode = CancellationErrorCode.NoError;
    if (!!result.properties) {
      errorCode = CancellationErrorCode[result.properties.getProperty(CancellationErrorCodePropertyName, CancellationErrorCode[CancellationErrorCode.NoError])];
    }
    return new SpeakerRecognitionCancellationDetails(reason, result.errorDetails, errorCode);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js
var __awaiter13 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var Conversation = class {
  constructor() {
    return;
  }
  /**
   * Create a conversation
   * @param speechConfig
   * @param cb
   * @param err
   */
  static createConversationAsync(speechConfig, arg2, arg3, arg4) {
    Contracts.throwIfNullOrUndefined(speechConfig, ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "config"));
    Contracts.throwIfNullOrUndefined(speechConfig.region, ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Region"));
    if (!speechConfig.subscriptionKey && !speechConfig.getProperty(PropertyId[PropertyId.SpeechServiceAuthorization_Token])) {
      Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Key"));
    }
    let conversationImpl;
    let cb;
    let err;
    if (typeof arg2 === "string") {
      conversationImpl = new ConversationImpl(speechConfig, arg2);
      marshalPromiseToCallbacks((() => __awaiter13(this, void 0, void 0, function* () {
      }))(), arg3, arg4);
    } else {
      conversationImpl = new ConversationImpl(speechConfig);
      cb = arg2;
      err = arg3;
      conversationImpl.createConversationAsync(() => {
        if (!!cb) {
          cb();
        }
      }, (error) => {
        if (!!err) {
          err(error);
        }
      });
    }
    return conversationImpl;
  }
};
var ConversationImpl = class extends Conversation {
  /**
   * Create a conversation impl
   * @param speechConfig
   * @param {string} id - optional conversationId
   */
  constructor(speechConfig, id) {
    super();
    this.privErrors = ConversationConnectionConfig.restErrors;
    this.onConnected = (e) => {
      var _a;
      this.privIsConnected = true;
      try {
        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStarted)) {
          this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);
        }
      } catch (e2) {
      }
    };
    this.onDisconnected = (e) => {
      var _a;
      try {
        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStopped)) {
          this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);
        }
      } catch (e2) {
      } finally {
        void this.close(false);
      }
    };
    this.onCanceled = (r, e) => {
      var _a;
      try {
        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.canceled)) {
          this.privConversationTranslator.canceled(this.privConversationTranslator, e);
        }
      } catch (e2) {
      }
    };
    this.onParticipantUpdateCommandReceived = (r, e) => {
      try {
        const updatedParticipant = this.privParticipants.getParticipant(e.id);
        if (updatedParticipant !== void 0) {
          switch (e.key) {
            case ConversationTranslatorCommandTypes.changeNickname:
              updatedParticipant.displayName = e.value;
              break;
            case ConversationTranslatorCommandTypes.setUseTTS:
              updatedParticipant.isUsingTts = e.value;
              break;
            case ConversationTranslatorCommandTypes.setProfanityFiltering:
              updatedParticipant.profanity = e.value;
              break;
            case ConversationTranslatorCommandTypes.setMute:
              updatedParticipant.isMuted = e.value;
              break;
            case ConversationTranslatorCommandTypes.setTranslateToLanguages:
              updatedParticipant.translateToLanguages = e.value;
              break;
          }
          this.privParticipants.addOrUpdateParticipant(updatedParticipant);
          if (!!this.privConversationTranslator) {
            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new ConversationParticipantsChangedEventArgs(ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));
          }
        }
      } catch (e2) {
      }
    };
    this.onLockRoomCommandReceived = () => {
    };
    this.onMuteAllCommandReceived = (r, e) => {
      try {
        this.privParticipants.participants.forEach((p) => p.isMuted = p.isHost ? false : e.isMuted);
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new ConversationParticipantsChangedEventArgs(ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));
        }
      } catch (e2) {
      }
    };
    this.onParticipantJoinCommandReceived = (r, e) => {
      try {
        const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);
        if (newParticipant !== void 0) {
          if (!!this.privConversationTranslator) {
            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new ConversationParticipantsChangedEventArgs(ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));
          }
        }
      } catch (e2) {
      }
    };
    this.onParticipantLeaveCommandReceived = (r, e) => {
      try {
        const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);
        if (ejectedParticipant !== void 0) {
          this.privParticipants.deleteParticipant(e.participant.id);
          if (!!this.privConversationTranslator) {
            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new ConversationParticipantsChangedEventArgs(ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));
          }
        }
      } catch (e2) {
      }
    };
    this.onTranslationReceived = (r, e) => {
      try {
        switch (e.command) {
          case ConversationTranslatorMessageTypes.final:
            if (!!this.privConversationTranslator) {
              this.privConversationTranslator.transcribed(this.privConversationTranslator, new ConversationTranslationEventArgs(e.payload, void 0, e.sessionId));
            }
            break;
          case ConversationTranslatorMessageTypes.partial:
            if (!!this.privConversationTranslator) {
              this.privConversationTranslator.transcribing(this.privConversationTranslator, new ConversationTranslationEventArgs(e.payload, void 0, e.sessionId));
            }
            break;
          case ConversationTranslatorMessageTypes.instantMessage:
            if (!!this.privConversationTranslator) {
              this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new ConversationTranslationEventArgs(e.payload, void 0, e.sessionId));
            }
            break;
        }
      } catch (e2) {
      }
    };
    this.onParticipantsListReceived = (r, e) => {
      var _a;
      try {
        if (e.sessionToken !== void 0 && e.sessionToken !== null) {
          this.privRoom.token = e.sessionToken;
        }
        this.privParticipants.participants = [...e.participants];
        if (this.privParticipants.me !== void 0) {
          this.privIsReady = true;
        }
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new ConversationParticipantsChangedEventArgs(ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));
        }
        if (this.me.isHost) {
          const nickname = (_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.properties.getProperty(PropertyId.ConversationTranslator_Name);
          if (nickname !== void 0 && nickname.length > 0 && nickname !== this.me.displayName) {
            this.changeNicknameAsync(nickname);
          }
        }
      } catch (e2) {
      }
    };
    this.onConversationExpiration = (r, e) => {
      try {
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);
        }
      } catch (e2) {
      }
    };
    this.privIsConnected = false;
    this.privIsDisposed = false;
    this.privConversationId = "";
    this.privProperties = new PropertyCollection();
    this.privManager = new ConversationManager();
    const language = speechConfig.getProperty(PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
    if (!language) {
      speechConfig.setProperty(PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage], ConversationConnectionConfig.defaultLanguageCode);
    }
    this.privLanguage = speechConfig.getProperty(PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
    if (!id) {
      if (speechConfig.targetLanguages.length === 0) {
        speechConfig.addTargetLanguage(this.privLanguage);
      }
      const profanity = speechConfig.getProperty(PropertyId[PropertyId.SpeechServiceResponse_ProfanityOption]);
      if (!profanity) {
        speechConfig.setProfanity(ProfanityOption.Masked);
      }
      let hostNickname = speechConfig.getProperty(PropertyId[PropertyId.ConversationTranslator_Name]);
      if (hostNickname === void 0 || hostNickname === null) {
        hostNickname = "Host";
      }
      Contracts.throwIfNullOrTooLong(hostNickname, "nickname", 50);
      Contracts.throwIfNullOrTooShort(hostNickname, "nickname", 2);
      speechConfig.setProperty(PropertyId[PropertyId.ConversationTranslator_Name], hostNickname);
    } else {
      this.privConversationId = id;
    }
    this.privConfig = speechConfig;
    const configImpl = speechConfig;
    Contracts.throwIfNull(configImpl, "speechConfig");
    this.privProperties = configImpl.properties.clone();
    this.privIsConnected = false;
    this.privParticipants = new InternalParticipants();
    this.privIsReady = false;
    this.privTextMessageMaxLength = 1e3;
  }
  // get the internal data about a conversation
  get room() {
    return this.privRoom;
  }
  // get the wrapper for connecting to the websockets
  get connection() {
    return this.privConversationRecognizer;
  }
  // get the config
  get config() {
    return this.privConfig;
  }
  // get the conversation Id
  get conversationId() {
    return this.privRoom ? this.privRoom.roomId : this.privConversationId;
  }
  // get the properties
  get properties() {
    return this.privProperties;
  }
  // get the speech language
  get speechRecognitionLanguage() {
    return this.privLanguage;
  }
  get isMutedByHost() {
    var _a, _b;
    return ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost) ? false : (_b = this.privParticipants.me) === null || _b === void 0 ? void 0 : _b.isMuted;
  }
  get isConnected() {
    return this.privIsConnected && this.privIsReady;
  }
  get participants() {
    return this.toParticipants(true);
  }
  get me() {
    return this.toParticipant(this.privParticipants.me);
  }
  get host() {
    return this.toParticipant(this.privParticipants.host);
  }
  get transcriberRecognizer() {
    return this.privTranscriberRecognizer;
  }
  get conversationInfo() {
    const convId = this.conversationId;
    const p = this.participants.map((part) => ({
      id: part.id,
      preferredLanguage: part.preferredLanguage,
      voice: part.voice
    }));
    const props = {};
    for (const key of ConversationConnectionConfig.transcriptionEventKeys) {
      const val = this.properties.getProperty(key, "");
      if (val !== "") {
        props[key] = val;
      }
    }
    const info = { id: convId, participants: p, conversationProperties: props };
    return info;
  }
  get canSend() {
    var _a;
    return this.privIsConnected && !((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isMuted);
  }
  get canSendAsHost() {
    var _a;
    return this.privIsConnected && ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost);
  }
  // get / set the speech auth token
  // eslint-disable-next-line @typescript-eslint/member-ordering
  get authorizationToken() {
    return this.privToken;
  }
  set authorizationToken(value) {
    Contracts.throwIfNullOrWhitespace(value, "authorizationToken");
    this.privToken = value;
  }
  set conversationTranslator(conversationTranslator) {
    this.privConversationTranslator = conversationTranslator;
  }
  /**
   * Create a new conversation as Host
   * @param cb
   * @param err
   */
  createConversationAsync(cb, err) {
    try {
      if (!!this.privConversationRecognizer) {
        this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
      }
      this.privManager.createOrJoin(this.privProperties, void 0, (room) => {
        if (!room) {
          this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);
        }
        this.privRoom = room;
        this.handleCallback(cb, err);
      }, (error) => {
        this.handleError(error, err);
      });
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Starts a new conversation as host.
   * @param cb
   * @param err
   */
  startConversationAsync(cb, err) {
    try {
      if (!!this.privConversationRecognizer) {
        this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
      }
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);
      this.privParticipants.meId = this.privRoom.participantId;
      this.privConversationRecognizer = ConversationRecognizerFactory.fromConfig(this, this.privConfig);
      this.privConversationRecognizer.connected = this.onConnected;
      this.privConversationRecognizer.disconnected = this.onDisconnected;
      this.privConversationRecognizer.canceled = this.onCanceled;
      this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;
      this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;
      this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;
      this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;
      this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;
      this.privConversationRecognizer.translationReceived = this.onTranslationReceived;
      this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;
      this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;
      this.privConversationRecognizer.connect(this.privRoom.token, () => {
        this.handleCallback(cb, err);
      }, (error) => {
        this.handleError(error, err);
      });
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Join a conversation as a participant.
   * @param { IParticipant } participant - participant to add
   * @param cb
   * @param err
   */
  addParticipantAsync(participant, cb, err) {
    Contracts.throwIfNullOrUndefined(participant, "Participant");
    marshalPromiseToCallbacks(this.addParticipantImplAsync(participant), cb, err);
  }
  /**
   * Join a conversation as a participant.
   * @param conversation
   * @param nickname
   * @param lang
   * @param cb
   * @param err
   */
  joinConversationAsync(conversationId, nickname, lang, cb, err) {
    try {
      Contracts.throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace("{arg}", "conversationId"));
      Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
      Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace("{arg}", "language"));
      this.privManager.createOrJoin(this.privProperties, conversationId, (room) => {
        Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);
        this.privRoom = room;
        this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;
        if (!!cb) {
          cb(room.cognitiveSpeechAuthToken);
        }
      }, (error) => {
        this.handleError(error, err);
      });
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Deletes a conversation
   * @param cb
   * @param err
   */
  deleteConversationAsync(cb, err) {
    marshalPromiseToCallbacks(this.deleteConversationImplAsync(), cb, err);
  }
  deleteConversationImplAsync() {
    return __awaiter13(this, void 0, void 0, function* () {
      Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);
      Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);
      yield this.privManager.leave(this.privProperties, this.privRoom.token);
      this.dispose();
    });
  }
  /**
   * Issues a request to close the client websockets
   * @param cb
   * @param err
   */
  endConversationAsync(cb, err) {
    marshalPromiseToCallbacks(this.endConversationImplAsync(), cb, err);
  }
  endConversationImplAsync() {
    return this.close(true);
  }
  /**
   * Issues a request to lock the conversation
   * @param cb
   * @param err
   */
  lockConversationAsync(cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "lock")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getLockCommand(true), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to mute the conversation
   * @param cb
   * @param err
   */
  muteAllParticipantsAsync(cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "mute")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to mute a participant in the conversation
   * @param userId
   * @param cb
   * @param err
   */
  muteParticipantAsync(userId, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (!this.me.isHost && this.me.id !== userId) {
        this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
      }
      const exists = this.privParticipants.getParticipantIndex(userId);
      if (exists === -1) {
        this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to remove a participant from the conversation
   * @param userId
   * @param cb
   * @param err
   */
  removeParticipantAsync(userId, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      if (!!this.privTranscriberRecognizer && userId.hasOwnProperty("id")) {
        marshalPromiseToCallbacks(this.removeParticipantImplAsync(userId), cb, err);
      } else {
        Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
        Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
        if (!this.canSendAsHost) {
          this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "remove")), err);
        }
        let participantId = "";
        if (typeof userId === "string") {
          participantId = userId;
        } else if (userId.hasOwnProperty("id")) {
          const participant = userId;
          participantId = participant.id;
        } else if (userId.hasOwnProperty("userId")) {
          const user = userId;
          participantId = user.userId;
        }
        Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
        const index = this.participants.findIndex((p) => p.id === participantId);
        if (index === -1) {
          this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
        }
        if (!!this.privConversationRecognizer) {
          this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), () => {
            this.handleCallback(cb, err);
          }, (error) => {
            this.handleError(error, err);
          });
        }
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to unlock the conversation
   * @param cb
   * @param err
   */
  unlockConversationAsync(cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unlock")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getLockCommand(false), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to unmute all participants in the conversation
   * @param cb
   * @param err
   */
  unmuteAllParticipantsAsync(cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSendAsHost) {
        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unmute all")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Issues a request to unmute a participant in the conversation
   * @param userId
   * @param cb
   * @param err
   */
  unmuteParticipantAsync(userId, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (!this.me.isHost && this.me.id !== userId) {
        this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
      }
      const exists = this.privParticipants.getParticipantIndex(userId);
      if (exists === -1) {
        this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Send a text message
   * @param message
   * @param cb
   * @param err
   */
  sendTextMessageAsync(message, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", "message"));
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (message.length > this.privTextMessageMaxLength) {
        this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "message length")), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Set translated to languages
   * @param {string[]} languages - languages to translate to
   * @param cb
   * @param err
   */
  setTranslatedLanguagesAsync(languages, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace("{arg}", "languages"));
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Change nickname
   * @param {string} nickname - new nickname for the room
   * @param cb
   * @param err
   */
  changeNicknameAsync(nickname, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
      Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
      Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
      if (!this.canSend) {
        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
      }
      if (!!this.privConversationRecognizer) {
        this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), () => {
          this.handleCallback(cb, err);
        }, (error) => {
          this.handleError(error, err);
        });
      }
    } catch (error) {
      this.handleError(error, err);
    }
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose() {
    if (this.isDisposed) {
      return;
    }
    this.privIsDisposed = true;
    if (!!this.config) {
      this.config.close();
    }
    this.privConfig = void 0;
    this.privLanguage = void 0;
    this.privProperties = void 0;
    this.privRoom = void 0;
    this.privToken = void 0;
    this.privManager = void 0;
    this.privIsConnected = false;
    this.privIsReady = false;
    this.privParticipants = void 0;
  }
  connectTranscriberRecognizer(recognizer) {
    return __awaiter13(this, void 0, void 0, function* () {
      if (!!this.privTranscriberRecognizer) {
        yield this.privTranscriberRecognizer.close();
      }
      yield recognizer.enforceAudioGating();
      this.privTranscriberRecognizer = recognizer;
      this.privTranscriberRecognizer.conversation = this;
    });
  }
  getKeepAlive() {
    const nickname = !!this.me ? this.me.displayName : "default_nickname";
    return JSON.stringify({
      id: "0",
      nickname,
      participantId: this.privRoom.participantId,
      roomId: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.keepAlive
    });
  }
  /* eslint-enable @typescript-eslint/typedef */
  addParticipantImplAsync(participant) {
    const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);
    if (newParticipant !== void 0) {
      if (!!this.privTranscriberRecognizer) {
        const conversationInfo = this.conversationInfo;
        conversationInfo.participants = [participant];
        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "join");
      }
    }
  }
  removeParticipantImplAsync(participant) {
    this.privParticipants.deleteParticipant(participant.id);
    const conversationInfo = this.conversationInfo;
    conversationInfo.participants = [participant];
    return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "leave");
  }
  close(dispose) {
    var _a;
    return __awaiter13(this, void 0, void 0, function* () {
      try {
        this.privIsConnected = false;
        yield (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.close();
        this.privConversationRecognizer = void 0;
        if (!!this.privConversationTranslator) {
          this.privConversationTranslator.dispose();
        }
      } catch (e) {
        throw e;
      }
      if (dispose) {
        this.dispose();
      }
    });
  }
  /** Helpers */
  handleCallback(cb, err) {
    if (!!cb) {
      try {
        cb();
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
      cb = void 0;
    }
  }
  handleError(error, err) {
    if (!!err) {
      if (error instanceof Error) {
        const typedError = error;
        err(typedError.name + ": " + typedError.message);
      } else {
        err(error);
      }
    }
  }
  /** Participant Helpers */
  toParticipants(includeHost) {
    const participants = this.privParticipants.participants.map((p) => this.toParticipant(p));
    if (!includeHost) {
      return participants.filter((p) => p.isHost === false);
    } else {
      return participants;
    }
  }
  toParticipant(p) {
    return new Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);
  }
  getMuteAllCommand(isMuted) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: ConversationTranslatorCommandTypes.setMuteAll,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.participantCommand,
      value: isMuted
    });
  }
  getMuteCommand(participantId, isMuted) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(participantId, "participantId");
    return JSON.stringify({
      command: ConversationTranslatorCommandTypes.setMute,
      // eslint-disable-next-line object-shorthand
      participantId,
      roomid: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.participantCommand,
      value: isMuted
    });
  }
  getLockCommand(isLocked) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: ConversationTranslatorCommandTypes.setLockState,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.participantCommand,
      value: isLocked
    });
  }
  getEjectCommand(participantId) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(participantId, "participantId");
    return JSON.stringify({
      command: ConversationTranslatorCommandTypes.ejectParticipant,
      // eslint-disable-next-line object-shorthand
      participantId,
      roomid: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.participantCommand
    });
  }
  getSetTranslateToLanguagesCommand(languages) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: ConversationTranslatorCommandTypes.setTranslateToLanguages,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.participantCommand,
      value: languages
    });
  }
  getChangeNicknameCommand(nickname) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(nickname, "nickname");
    Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    return JSON.stringify({
      command: ConversationTranslatorCommandTypes.changeNickname,
      nickname,
      participantId: this.privRoom.participantId,
      roomid: this.privRoom.roomId,
      type: ConversationTranslatorMessageTypes.participantCommand,
      value: nickname
    });
  }
  getMessageCommand(message) {
    Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
    Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
    Contracts.throwIfNullOrWhitespace(message, "message");
    return JSON.stringify({
      participantId: this.privRoom.participantId,
      roomId: this.privRoom.roomId,
      text: message,
      type: ConversationTranslatorMessageTypes.instantMessage
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js
var ConversationCommon = class {
  constructor(audioConfig) {
    this.privAudioConfig = audioConfig;
  }
  handleCallback(cb, err) {
    if (!!cb) {
      try {
        cb();
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
      cb = void 0;
    }
  }
  handleError(error, err) {
    if (!!err) {
      if (error instanceof Error) {
        const typedError = error;
        err(typedError.name + ": " + typedError.message);
      } else {
        err(error);
      }
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js
var ConversationExpirationEventArgs = class extends SessionEventArgs {
  constructor(expirationTime, sessionId) {
    super(sessionId);
    this.privExpirationTime = expirationTime;
  }
  /** How much longer until the conversation expires (in minutes). */
  get expirationTime() {
    return this.privExpirationTime;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js
var ConversationParticipantsChangedEventArgs = class extends SessionEventArgs {
  constructor(reason, participants, sessionId) {
    super(sessionId);
    this.privReason = reason;
    this.privParticipant = participants;
  }
  get reason() {
    return this.privReason;
  }
  get participants() {
    return this.privParticipant;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js
var ConversationTranslationCanceledEventArgs = class extends CancellationEventArgsBase {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js
var ConversationTranslationEventArgs = class extends RecognitionEventArgs {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {ConversationTranslationResult} result - The translation recognition result.
   * @param {number} offset - The offset.
   * @param {string} sessionId - The session id.
   */
  constructor(result, offset, sessionId) {
    super(offset, sessionId);
    this.privResult = result;
  }
  /**
   * Specifies the recognition result.
   * @returns {ConversationTranslationResult} the recognition result.
   */
  get result() {
    return this.privResult;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js
var ConversationTranslationResult = class extends TranslationRecognitionResult {
  constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {
    super(translations, resultId, reason, text, duration, offset, errorDetails, json, properties);
    this.privId = participantId;
    this.privOrigLang = originalLanguage;
  }
  /**
   * The unique identifier for the participant this result is for.
   */
  get participantId() {
    return this.privId;
  }
  /**
   * The original language this result was in.
   */
  get originalLang() {
    return this.privOrigLang;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/StringUtils.js
var StringUtils = class {
  /**
   * Formats a string by replacing the named {keys} in the string with the values contained in the replacement dictionary.
   * @param format The format string that contains the parts to replace surrounded by {}. For example: "wss://{region}.cts.speech.microsoft.com".
   * If your string needs to contain a { or } you can use the {{ and }} escape sequences respectively.
   * @param replacements The dictionary of replacements. If a replacement is not found, it is replaced with an empty string
   * @returns The formatted string. If you pass in a null or undefined format string, an empty string will be returned
   */
  static formatString(format, replacements) {
    if (!format) {
      return "";
    }
    if (!replacements) {
      return format;
    }
    let formatted = "";
    let key = "";
    const appendToFormatted = (str) => {
      formatted += str;
    };
    const appendToKey = (str) => {
      key += str;
    };
    let appendFunc = appendToFormatted;
    for (let i = 0; i < format.length; i++) {
      const c = format[i];
      const next = i + 1 < format.length ? format[i + 1] : "";
      switch (c) {
        case "{":
          if (next === "{") {
            appendFunc("{");
            i++;
          } else {
            appendFunc = appendToKey;
          }
          break;
        case "}":
          if (next === "}") {
            appendFunc("}");
            i++;
          } else {
            if (replacements.hasOwnProperty(key)) {
              formatted += replacements[key];
            }
            appendFunc = appendToFormatted;
            key = "";
          }
          break;
        default:
          appendFunc(c);
          break;
      }
    }
    return formatted;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js
var ConversationTranslatorConnectionFactory = class extends ConnectionFactoryBase {
  constructor(convGetter) {
    super();
    Contracts.throwIfNullOrUndefined(convGetter, "convGetter");
    this.privConvGetter = convGetter;
  }
  create(config, authInfo, connectionId) {
    const isVirtMicArrayEndpoint = config.parameters.getProperty("ConversationTranslator_MultiChannelAudio", "").toUpperCase() === "TRUE";
    const convInfo = this.privConvGetter().room;
    const region = convInfo.cognitiveSpeechRegion || config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region, "");
    const replacementValues = {
      hostSuffix: ConnectionFactoryBase.getHostSuffix(region),
      path: ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH,
      region: encodeURIComponent(region)
    };
    replacementValues[QueryParameterNames.Language] = encodeURIComponent(config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, ""));
    replacementValues[QueryParameterNames.CtsMeetingId] = encodeURIComponent(convInfo.roomId);
    replacementValues[QueryParameterNames.CtsDeviceId] = encodeURIComponent(convInfo.participantId);
    replacementValues[QueryParameterNames.CtsIsParticipant] = convInfo.isHost ? "" : "&" + QueryParameterNames.CtsIsParticipant;
    let endpointUrl = "";
    const queryParams = {};
    const headers = {};
    if (isVirtMicArrayEndpoint) {
      endpointUrl = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint);
      if (!endpointUrl) {
        const hostName = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, "transcribe.{region}.cts.speech{hostSuffix}");
        endpointUrl = "wss://" + hostName + "{path}";
      }
      endpointUrl = StringUtils.formatString(endpointUrl, replacementValues);
      const parsedUrl = new URL(endpointUrl);
      parsedUrl.searchParams.forEach((val, key) => {
        queryParams[key] = val;
      });
      const connFactory = new TranscriberConnectionFactory();
      connFactory.setQueryParams(queryParams, config, endpointUrl);
      queryParams[QueryParameterNames.CtsMeetingId] = replacementValues[QueryParameterNames.CtsMeetingId];
      queryParams[QueryParameterNames.CtsDeviceId] = replacementValues[QueryParameterNames.CtsDeviceId];
      if (!convInfo.isHost) {
        queryParams[QueryParameterNames.CtsIsParticipant] = "";
      }
      if (!(QueryParameterNames.Format in queryParams)) {
        queryParams[QueryParameterNames.Format] = "simple";
      }
      parsedUrl.searchParams.forEach((val, key) => {
        parsedUrl.searchParams.set(key, queryParams[key]);
        delete queryParams[key];
      });
      endpointUrl = parsedUrl.toString();
    } else {
      const connFactory = new TranslationConnectionFactory();
      endpointUrl = connFactory.getEndpointUrl(config, true);
      endpointUrl = StringUtils.formatString(endpointUrl, replacementValues);
      connFactory.setQueryParams(queryParams, config, endpointUrl);
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    headers[RestConfigBase.configParams.token] = convInfo.token;
    if (authInfo.token) {
      headers[authInfo.headerName] = authInfo.token;
    }
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "").toUpperCase() === "TRUE";
    return new WebsocketConnection(endpointUrl, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
};
ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH = "/speech/recognition/dynamicaudio";

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js
var __awaiter14 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SpeechState;
(function(SpeechState2) {
  SpeechState2[SpeechState2["Inactive"] = 0] = "Inactive";
  SpeechState2[SpeechState2["Connecting"] = 1] = "Connecting";
  SpeechState2[SpeechState2["Connected"] = 2] = "Connected";
})(SpeechState || (SpeechState = {}));
var ConversationTranslationRecognizer = class extends TranslationRecognizer {
  constructor(speechConfig, audioConfig, translator, convGetter) {
    super(speechConfig, audioConfig, new ConversationTranslatorConnectionFactory(convGetter));
    this.privSpeechState = SpeechState.Inactive;
    if (!!translator) {
      this.privTranslator = translator;
      this.sessionStarted = () => {
        this.privSpeechState = SpeechState.Connected;
      };
      this.sessionStopped = () => {
        this.privSpeechState = SpeechState.Inactive;
      };
      this.recognizing = (tr, e) => {
        if (!!this.privTranslator.recognizing) {
          this.privTranslator.recognizing(this.privTranslator, e);
        }
      };
      this.recognized = (tr, e) => __awaiter14(this, void 0, void 0, function* () {
        var _a;
        if ((_a = e.result) === null || _a === void 0 ? void 0 : _a.errorDetails) {
          yield this.cancelSpeech();
          this.fireCancelEvent(e.result.errorDetails);
        } else {
          if (!!this.privTranslator.recognized) {
            this.privTranslator.recognized(this.privTranslator, e);
          }
        }
        return;
      });
      this.canceled = () => __awaiter14(this, void 0, void 0, function* () {
        if (this.privSpeechState !== SpeechState.Inactive) {
          try {
            yield this.cancelSpeech();
          } catch (error) {
            this.privSpeechState = SpeechState.Inactive;
          }
        }
      });
    }
  }
  get state() {
    return this.privSpeechState;
  }
  set state(newState) {
    this.privSpeechState = newState;
  }
  onConnection() {
    this.privSpeechState = SpeechState.Connected;
  }
  onDisconnection() {
    return __awaiter14(this, void 0, void 0, function* () {
      this.privSpeechState = SpeechState.Inactive;
      yield this.cancelSpeech();
    });
  }
  /**
   * Fire a cancel event
   * @param error
   */
  fireCancelEvent(error) {
    try {
      if (!!this.privTranslator.canceled) {
        const cancelEvent = new ConversationTranslationCanceledEventArgs(CancellationReason.Error, error, CancellationErrorCode.RuntimeError);
        this.privTranslator.canceled(this.privTranslator, cancelEvent);
      }
    } catch (e) {
    }
  }
  cancelSpeech() {
    var _a;
    return __awaiter14(this, void 0, void 0, function* () {
      try {
        this.stopContinuousRecognitionAsync();
        yield (_a = this.privReco) === null || _a === void 0 ? void 0 : _a.disconnect();
        this.privSpeechState = SpeechState.Inactive;
      } catch (e) {
      }
    });
  }
};
var ConversationTranslator = class extends ConversationCommon {
  constructor(audioConfig) {
    super(audioConfig);
    this.privErrors = ConversationConnectionConfig.restErrors;
    this.privIsDisposed = false;
    this.privIsSpeaking = false;
    this.privPlaceholderKey = "abcdefghijklmnopqrstuvwxyz012345";
    this.privPlaceholderRegion = "westus";
    this.privProperties = new PropertyCollection();
  }
  get properties() {
    return this.privProperties;
  }
  get speechRecognitionLanguage() {
    return this.privSpeechRecognitionLanguage;
  }
  get participants() {
    var _a;
    return (_a = this.privConversation) === null || _a === void 0 ? void 0 : _a.participants;
  }
  get canSpeak() {
    if (!this.privConversation.isConnected || !this.privCTRecognizer) {
      return false;
    }
    if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {
      return false;
    }
    if (this.privConversation.isMutedByHost) {
      return false;
    }
    return true;
  }
  setServiceProperty(name, value) {
    const currentProperties = JSON.parse(this.privProperties.getProperty(ServicePropertiesPropertyName, "{}"));
    currentProperties[name] = value;
    this.privProperties.setProperty(ServicePropertiesPropertyName, JSON.stringify(currentProperties));
  }
  joinConversationAsync(conversation, nickname, param1, param2, param3) {
    try {
      if (typeof conversation === "string") {
        Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
        Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
        if (!!this.privConversation) {
          this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);
        }
        let lang = param1;
        if (lang === void 0 || lang === null || lang === "") {
          lang = ConversationConnectionConfig.defaultLanguageCode;
        }
        this.privSpeechTranslationConfig = SpeechTranslationConfig.fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);
        this.privSpeechTranslationConfig.setProfanity(ProfanityOption.Masked);
        this.privSpeechTranslationConfig.addTargetLanguage(lang);
        this.privSpeechTranslationConfig.setProperty(PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage], lang);
        this.privSpeechTranslationConfig.setProperty(PropertyId[PropertyId.ConversationTranslator_Name], nickname);
        const propertyIdsToCopy = [
          PropertyId.SpeechServiceConnection_Host,
          PropertyId.ConversationTranslator_Host,
          PropertyId.SpeechServiceConnection_Endpoint,
          PropertyId.SpeechServiceConnection_ProxyHostName,
          PropertyId.SpeechServiceConnection_ProxyPassword,
          PropertyId.SpeechServiceConnection_ProxyPort,
          PropertyId.SpeechServiceConnection_ProxyUserName,
          "ConversationTranslator_MultiChannelAudio",
          "ConversationTranslator_Region"
        ];
        for (const prop of propertyIdsToCopy) {
          const value = this.privProperties.getProperty(prop);
          if (value) {
            const key = typeof prop === "string" ? prop : PropertyId[prop];
            this.privSpeechTranslationConfig.setProperty(key, value);
          }
        }
        const currentProperties = JSON.parse(this.privProperties.getProperty(ServicePropertiesPropertyName, "{}"));
        for (const prop of Object.keys(currentProperties)) {
          this.privSpeechTranslationConfig.setServiceProperty(prop, currentProperties[prop], ServicePropertyChannel.UriQueryParameter);
        }
        this.privConversation = new ConversationImpl(this.privSpeechTranslationConfig);
        this.privConversation.conversationTranslator = this;
        this.privConversation.joinConversationAsync(conversation, nickname, lang, (result) => {
          if (!result) {
            this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);
          }
          this.privSpeechTranslationConfig.authorizationToken = result;
          this.privConversation.room.isHost = false;
          this.privConversation.startConversationAsync(() => {
            this.handleCallback(param2, param3);
          }, (error) => {
            this.handleError(error, param3);
          });
        }, (error) => {
          this.handleError(error, param3);
        });
      } else if (typeof conversation === "object") {
        Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
        Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
        this.privProperties.setProperty(PropertyId.ConversationTranslator_Name, nickname);
        this.privConversation = conversation;
        this.privConversation.conversationTranslator = this;
        this.privConversation.room.isHost = true;
        Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);
        Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
        this.privSpeechTranslationConfig = conversation.config;
        this.handleCallback(param1, param2);
      } else {
        this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "invalid conversation type")), param2);
      }
    } catch (error) {
      this.handleError(error, typeof param1 === "string" ? param3 : param2);
    }
  }
  /**
   * Leave the conversation
   * @param cb
   * @param err
   */
  leaveConversationAsync(cb, err) {
    marshalPromiseToCallbacks((() => __awaiter14(this, void 0, void 0, function* () {
      yield this.cancelSpeech();
      yield this.privConversation.endConversationImplAsync();
      yield this.privConversation.deleteConversationImplAsync();
      this.dispose();
    }))(), cb, err);
  }
  /**
   * Send a text message
   * @param message
   * @param cb
   * @param err
   */
  sendTextMessageAsync(message, cb, err) {
    try {
      Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
      Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", message));
      this.privConversation.sendTextMessageAsync(message, cb, err);
    } catch (error) {
      this.handleError(error, err);
    }
  }
  /**
   * Start speaking
   * @param cb
   * @param err
   */
  startTranscribingAsync(cb, err) {
    marshalPromiseToCallbacks((() => __awaiter14(this, void 0, void 0, function* () {
      try {
        Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
        Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
        if (this.privCTRecognizer === void 0) {
          yield this.connectTranslatorRecognizer();
        }
        Contracts.throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);
        if (!this.canSpeak) {
          this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
        }
        yield this.startContinuousRecognition();
        this.privIsSpeaking = true;
      } catch (error) {
        this.privIsSpeaking = false;
        yield this.cancelSpeech();
        throw error;
      }
    }))(), cb, err);
  }
  /**
   * Stop speaking
   * @param cb
   * @param err
   */
  stopTranscribingAsync(cb, err) {
    marshalPromiseToCallbacks((() => __awaiter14(this, void 0, void 0, function* () {
      try {
        if (!this.privIsSpeaking) {
          yield this.cancelSpeech();
          return;
        }
        this.privIsSpeaking = false;
        yield new Promise((resolve, reject) => {
          this.privCTRecognizer.stopContinuousRecognitionAsync(resolve, reject);
        });
      } catch (error) {
        yield this.cancelSpeech();
      }
    }))(), cb, err);
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose(reason, success, err) {
    marshalPromiseToCallbacks((() => __awaiter14(this, void 0, void 0, function* () {
      if (this.isDisposed && !this.privIsSpeaking) {
        return;
      }
      yield this.cancelSpeech();
      this.privIsDisposed = true;
      this.privSpeechTranslationConfig.close();
      this.privSpeechRecognitionLanguage = void 0;
      this.privProperties = void 0;
      this.privAudioConfig = void 0;
      this.privSpeechTranslationConfig = void 0;
      this.privConversation.dispose();
      this.privConversation = void 0;
    }))(), success, err);
  }
  /**
   * Cancel the speech websocket
   */
  cancelSpeech() {
    var _a;
    return __awaiter14(this, void 0, void 0, function* () {
      try {
        this.privIsSpeaking = false;
        yield (_a = this.privCTRecognizer) === null || _a === void 0 ? void 0 : _a.onDisconnection();
        this.privCTRecognizer = void 0;
      } catch (e) {
      }
    });
  }
  /**
   * Connect to the speech translation recognizer.
   * Currently there is no language validation performed before sending the SpeechLanguage code to the service.
   * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'
   * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'
   */
  connectTranslatorRecognizer() {
    return __awaiter14(this, void 0, void 0, function* () {
      try {
        if (this.privAudioConfig === void 0) {
          this.privAudioConfig = AudioConfig.fromDefaultMicrophoneInput();
        }
        if (this.privSpeechTranslationConfig.getProperty(PropertyId[PropertyId.SpeechServiceConnection_Key]) === this.privPlaceholderKey) {
          this.privSpeechTranslationConfig.setProperty(PropertyId[PropertyId.SpeechServiceConnection_Key], "");
        }
        const convGetter = () => this.privConversation;
        this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this, convGetter);
      } catch (error) {
        yield this.cancelSpeech();
        throw error;
      }
    });
  }
  /**
   * Handle the start speaking request
   */
  startContinuousRecognition() {
    return new Promise((resolve, reject) => {
      this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js
var __awaiter15 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var ConversationTranscriber = class {
  /**
   * ConversationTranscriber constructor.
   * @constructor
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
   */
  constructor(audioConfig) {
    this.privAudioConfig = audioConfig;
    this.privProperties = new PropertyCollection();
    this.privRecognizer = void 0;
    this.privDisposedRecognizer = false;
  }
  /**
   * Gets the spoken language of recognition.
   * @member ConversationTranscriber.prototype.speechRecognitionLanguage
   * @function
   * @public
   * @returns {string} The spoken language of recognition.
   */
  get speechRecognitionLanguage() {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  /**
   * The collection of properties and their values defined for this ConversationTranscriber.
   * @member ConversationTranscriber.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this ConversationTranscriber.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * @Internal
   * Internal data member to support fromRecognizer* pattern methods on other classes.
   * Do not use externally, object returned will change without warning or notice.
   */
  get internalData() {
    return this.privRecognizer.internalData;
  }
  /**
   * @Deprecated
   * @Obsolete
   * Please use the Connection.fromRecognizer pattern to obtain a connection object
   */
  get connection() {
    return Connection.fromRecognizer(this.privRecognizer);
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member ConversationTranscriber.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member ConversationTranscriber.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * @param {Conversation} conversation - conversation to be recognized
   */
  joinConversationAsync(conversation, cb, err) {
    const conversationImpl = conversation;
    Contracts.throwIfNullOrUndefined(conversationImpl, "Conversation");
    this.privRecognizer = new TranscriberRecognizer(conversation.config, this.privAudioConfig);
    Contracts.throwIfNullOrUndefined(this.privRecognizer, "Recognizer");
    this.privRecognizer.connectCallbacks(this);
    marshalPromiseToCallbacks(conversationImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);
  }
  /**
   * Starts conversation transcription, until stopTranscribingAsync() is called.
   * User must subscribe to events to receive transcription results.
   * @member ConversationTranscriber.prototype.startTranscribingAsync
   * @function
   * @public
   * @param cb - Callback invoked once the transcription has started.
   * @param err - Callback invoked in case of an error.
   */
  startTranscribingAsync(cb, err) {
    this.privRecognizer.startContinuousRecognitionAsync(cb, err);
  }
  /**
   * Starts conversation transcription, until stopTranscribingAsync() is called.
   * User must subscribe to events to receive transcription results.
   * @member ConversationTranscriber.prototype.stopTranscribingAsync
   * @function
   * @public
   * @param cb - Callback invoked once the transcription has started.
   * @param err - Callback invoked in case of an error.
   */
  stopTranscribingAsync(cb, err) {
    this.privRecognizer.stopContinuousRecognitionAsync(cb, err);
  }
  /**
   * Leave the current conversation. After this is called, you will no longer receive any events.
   */
  leaveConversationAsync(cb, err) {
    this.privRecognizer.disconnectCallbacks();
    marshalPromiseToCallbacks((() => __awaiter15(this, void 0, void 0, function* () {
      return;
    }))(), cb, err);
  }
  /**
   * closes all external resources held by an instance of this class.
   * @member ConversationTranscriber.prototype.close
   * @function
   * @public
   */
  close(cb, errorCb) {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);
  }
  /**
   * Disposes any resources held by the object.
   * @member ConversationTranscriber.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - true if disposing the object.
   */
  dispose(disposing) {
    return __awaiter15(this, void 0, void 0, function* () {
      if (this.privDisposedRecognizer) {
        return;
      }
      if (!!this.privRecognizer) {
        yield this.privRecognizer.close();
        this.privRecognizer = void 0;
      }
      if (disposing) {
        this.privDisposedRecognizer = true;
      }
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js
var User = class {
  constructor(userId) {
    this.privUserId = userId;
  }
  get userId() {
    return this.privUserId;
  }
};
var Participant = class {
  constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {
    this.privId = id;
    this.privAvatar = avatar;
    this.privDisplayName = displayName;
    this.privIsHost = isHost;
    this.privIsMuted = isMuted;
    this.privIsUsingTts = isUsingTts;
    this.privPreferredLanguage = preferredLanguage;
    this.privVoice = voice;
    this.privProperties = new PropertyCollection();
  }
  get avatar() {
    return this.privAvatar;
  }
  get displayName() {
    return this.privDisplayName;
  }
  get id() {
    return this.privId;
  }
  get preferredLanguage() {
    return this.privPreferredLanguage;
  }
  get isHost() {
    return this.privIsHost;
  }
  get isMuted() {
    return this.privIsMuted;
  }
  get isUsingTts() {
    return this.privIsUsingTts;
  }
  get voice() {
    return this.privVoice;
  }
  get properties() {
    return this.privProperties;
  }
  static From(id, language, voice) {
    return new Participant(id, "", id, false, false, false, language, voice);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js
var ParticipantChangedReason;
(function(ParticipantChangedReason2) {
  ParticipantChangedReason2[ParticipantChangedReason2["JoinedConversation"] = 0] = "JoinedConversation";
  ParticipantChangedReason2[ParticipantChangedReason2["LeftConversation"] = 1] = "LeftConversation";
  ParticipantChangedReason2[ParticipantChangedReason2["Updated"] = 2] = "Updated";
})(ParticipantChangedReason || (ParticipantChangedReason = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js
var __awaiter16 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SpeechSynthesizer = class {
  /**
   * SpeechSynthesizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.
   */
  constructor(speechConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    Contracts.throwIfNull(speechConfigImpl, "speechConfig");
    if (audioConfig !== null) {
      if (audioConfig === void 0) {
        this.audioConfig = typeof window === "undefined" ? void 0 : AudioConfig.fromDefaultSpeakerOutput();
      } else {
        this.audioConfig = audioConfig;
      }
    }
    this.privProperties = speechConfigImpl.properties.clone();
    this.privDisposed = false;
    this.privSynthesizing = false;
    this.privConnectionFactory = new SpeechSynthesisConnectionFactory();
    this.synthesisRequestQueue = new Queue();
    this.implCommonSynthesizeSetup();
  }
  /**
   * Gets the authorization token used to communicate with the service.
   * @member SpeechSynthesizer.prototype.authorizationToken
   * @function
   * @public
   * @returns {string} Authorization token.
   */
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  /**
   * Gets/Sets the authorization token used to communicate with the service.
   * @member SpeechSynthesizer.prototype.authorizationToken
   * @function
   * @public
   * @param {string} token - Authorization token.
   */
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  /**
   * The collection of properties and their values defined for this SpeechSynthesizer.
   * @member SpeechSynthesizer.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.
   */
  get properties() {
    return this.privProperties;
  }
  /**
   * Indicates if auto detect source language is enabled
   * @member SpeechSynthesizer.prototype.properties
   * @function
   * @public
   * @returns {boolean} if auto detect source language is enabled
   */
  get autoDetectSourceLanguage() {
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages) === AutoDetectSourceLanguagesOpenRangeOptionName;
  }
  /**
   * SpeechSynthesizer constructor.
   * @constructor
   * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer
   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer
   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer
   */
  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
    const speechConfigImpl = speechConfig;
    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
    return new SpeechSynthesizer(speechConfig, audioConfig);
  }
  buildSsml(text) {
    const languageToDefaultVoice = {
      ["af-ZA"]: "af-ZA-AdriNeural",
      ["am-ET"]: "am-ET-AmehaNeural",
      ["ar-AE"]: "ar-AE-FatimaNeural",
      ["ar-BH"]: "ar-BH-AliNeural",
      ["ar-DZ"]: "ar-DZ-AminaNeural",
      ["ar-EG"]: "ar-EG-SalmaNeural",
      ["ar-IQ"]: "ar-IQ-BasselNeural",
      ["ar-JO"]: "ar-JO-SanaNeural",
      ["ar-KW"]: "ar-KW-FahedNeural",
      ["ar-LY"]: "ar-LY-ImanNeural",
      ["ar-MA"]: "ar-MA-JamalNeural",
      ["ar-QA"]: "ar-QA-AmalNeural",
      ["ar-SA"]: "ar-SA-HamedNeural",
      ["ar-SY"]: "ar-SY-AmanyNeural",
      ["ar-TN"]: "ar-TN-HediNeural",
      ["ar-YE"]: "ar-YE-MaryamNeural",
      ["bg-BG"]: "bg-BG-BorislavNeural",
      ["bn-BD"]: "bn-BD-NabanitaNeural",
      ["bn-IN"]: "bn-IN-BashkarNeural",
      ["ca-ES"]: "ca-ES-JoanaNeural",
      ["cs-CZ"]: "cs-CZ-AntoninNeural",
      ["cy-GB"]: "cy-GB-AledNeural",
      ["da-DK"]: "da-DK-ChristelNeural",
      ["de-AT"]: "de-AT-IngridNeural",
      ["de-CH"]: "de-CH-JanNeural",
      ["de-DE"]: "de-DE-KatjaNeural",
      ["el-GR"]: "el-GR-AthinaNeural",
      ["en-AU"]: "en-AU-NatashaNeural",
      ["en-CA"]: "en-CA-ClaraNeural",
      ["en-GB"]: "en-GB-LibbyNeural",
      ["en-HK"]: "en-HK-SamNeural",
      ["en-IE"]: "en-IE-ConnorNeural",
      ["en-IN"]: "en-IN-NeerjaNeural",
      ["en-KE"]: "en-KE-AsiliaNeural",
      ["en-NG"]: "en-NG-AbeoNeural",
      ["en-NZ"]: "en-NZ-MitchellNeural",
      ["en-PH"]: "en-PH-JamesNeural",
      ["en-SG"]: "en-SG-LunaNeural",
      ["en-TZ"]: "en-TZ-ElimuNeural",
      ["en-US"]: "en-US-JennyNeural",
      ["en-ZA"]: "en-ZA-LeahNeural",
      ["es-AR"]: "es-AR-ElenaNeural",
      ["es-BO"]: "es-BO-MarceloNeural",
      ["es-CL"]: "es-CL-CatalinaNeural",
      ["es-CO"]: "es-CO-GonzaloNeural",
      ["es-CR"]: "es-CR-JuanNeural",
      ["es-CU"]: "es-CU-BelkysNeural",
      ["es-DO"]: "es-DO-EmilioNeural",
      ["es-EC"]: "es-EC-AndreaNeural",
      ["es-ES"]: "es-ES-AlvaroNeural",
      ["es-GQ"]: "es-GQ-JavierNeural",
      ["es-GT"]: "es-GT-AndresNeural",
      ["es-HN"]: "es-HN-CarlosNeural",
      ["es-MX"]: "es-MX-DaliaNeural",
      ["es-NI"]: "es-NI-FedericoNeural",
      ["es-PA"]: "es-PA-MargaritaNeural",
      ["es-PE"]: "es-PE-AlexNeural",
      ["es-PR"]: "es-PR-KarinaNeural",
      ["es-PY"]: "es-PY-MarioNeural",
      ["es-SV"]: "es-SV-LorenaNeural",
      ["es-US"]: "es-US-AlonsoNeural",
      ["es-UY"]: "es-UY-MateoNeural",
      ["es-VE"]: "es-VE-PaolaNeural",
      ["et-EE"]: "et-EE-AnuNeural",
      ["fa-IR"]: "fa-IR-DilaraNeural",
      ["fi-FI"]: "fi-FI-SelmaNeural",
      ["fil-PH"]: "fil-PH-AngeloNeural",
      ["fr-BE"]: "fr-BE-CharlineNeural",
      ["fr-CA"]: "fr-CA-SylvieNeural",
      ["fr-CH"]: "fr-CH-ArianeNeural",
      ["fr-FR"]: "fr-FR-DeniseNeural",
      ["ga-IE"]: "ga-IE-ColmNeural",
      ["gl-ES"]: "gl-ES-RoiNeural",
      ["gu-IN"]: "gu-IN-DhwaniNeural",
      ["he-IL"]: "he-IL-AvriNeural",
      ["hi-IN"]: "hi-IN-MadhurNeural",
      ["hr-HR"]: "hr-HR-GabrijelaNeural",
      ["hu-HU"]: "hu-HU-NoemiNeural",
      ["id-ID"]: "id-ID-ArdiNeural",
      ["is-IS"]: "is-IS-GudrunNeural",
      ["it-IT"]: "it-IT-IsabellaNeural",
      ["ja-JP"]: "ja-JP-NanamiNeural",
      ["jv-ID"]: "jv-ID-DimasNeural",
      ["kk-KZ"]: "kk-KZ-AigulNeural",
      ["km-KH"]: "km-KH-PisethNeural",
      ["kn-IN"]: "kn-IN-GaganNeural",
      ["ko-KR"]: "ko-KR-SunHiNeural",
      ["lo-LA"]: "lo-LA-ChanthavongNeural",
      ["lt-LT"]: "lt-LT-LeonasNeural",
      ["lv-LV"]: "lv-LV-EveritaNeural",
      ["mk-MK"]: "mk-MK-AleksandarNeural",
      ["ml-IN"]: "ml-IN-MidhunNeural",
      ["mr-IN"]: "mr-IN-AarohiNeural",
      ["ms-MY"]: "ms-MY-OsmanNeural",
      ["mt-MT"]: "mt-MT-GraceNeural",
      ["my-MM"]: "my-MM-NilarNeural",
      ["nb-NO"]: "nb-NO-PernilleNeural",
      ["nl-BE"]: "nl-BE-ArnaudNeural",
      ["nl-NL"]: "nl-NL-ColetteNeural",
      ["pl-PL"]: "pl-PL-AgnieszkaNeural",
      ["ps-AF"]: "ps-AF-GulNawazNeural",
      ["pt-BR"]: "pt-BR-FranciscaNeural",
      ["pt-PT"]: "pt-PT-DuarteNeural",
      ["ro-RO"]: "ro-RO-AlinaNeural",
      ["ru-RU"]: "ru-RU-SvetlanaNeural",
      ["si-LK"]: "si-LK-SameeraNeural",
      ["sk-SK"]: "sk-SK-LukasNeural",
      ["sl-SI"]: "sl-SI-PetraNeural",
      ["so-SO"]: "so-SO-MuuseNeural",
      ["sr-RS"]: "sr-RS-NicholasNeural",
      ["su-ID"]: "su-ID-JajangNeural",
      ["sv-SE"]: "sv-SE-SofieNeural",
      ["sw-KE"]: "sw-KE-RafikiNeural",
      ["sw-TZ"]: "sw-TZ-DaudiNeural",
      ["ta-IN"]: "ta-IN-PallaviNeural",
      ["ta-LK"]: "ta-LK-KumarNeural",
      ["ta-SG"]: "ta-SG-AnbuNeural",
      ["te-IN"]: "te-IN-MohanNeural",
      ["th-TH"]: "th-TH-PremwadeeNeural",
      ["tr-TR"]: "tr-TR-AhmetNeural",
      ["uk-UA"]: "uk-UA-OstapNeural",
      ["ur-IN"]: "ur-IN-GulNeural",
      ["ur-PK"]: "ur-PK-AsadNeural",
      ["uz-UZ"]: "uz-UZ-MadinaNeural",
      ["vi-VN"]: "vi-VN-HoaiMyNeural",
      ["zh-CN"]: "zh-CN-XiaoxiaoNeural",
      ["zh-HK"]: "zh-HK-HiuMaanNeural",
      ["zh-TW"]: "zh-TW-HsiaoChenNeural",
      ["zu-ZA"]: "zu-ZA-ThandoNeural"
    };
    let language = this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthLanguage, "en-US");
    let voice = this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthVoice, "");
    let ssml = SpeechSynthesizer.XMLEncode(text);
    if (this.autoDetectSourceLanguage) {
      language = "en-US";
    } else {
      voice = voice || languageToDefaultVoice[language];
    }
    if (voice) {
      ssml = `<voice name='${voice}'>${ssml}</voice>`;
    }
    ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;
    return ssml;
  }
  /**
   * Executes speech synthesis on plain text.
   * The task returns the synthesis result.
   * @member SpeechSynthesizer.prototype.speakTextAsync
   * @function
   * @public
   * @param text - Text to be synthesized.
   * @param cb - Callback that received the SpeechSynthesisResult.
   * @param err - Callback invoked in case of an error.
   * @param stream - AudioOutputStream to receive the synthesized audio.
   */
  speakTextAsync(text, cb, err, stream) {
    this.speakImpl(text, false, cb, err, stream);
  }
  /**
   * Executes speech synthesis on SSML.
   * The task returns the synthesis result.
   * @member SpeechSynthesizer.prototype.speakSsmlAsync
   * @function
   * @public
   * @param ssml - SSML to be synthesized.
   * @param cb - Callback that received the SpeechSynthesisResult.
   * @param err - Callback invoked in case of an error.
   * @param stream - AudioOutputStream to receive the synthesized audio.
   */
  speakSsmlAsync(ssml, cb, err, stream) {
    this.speakImpl(ssml, true, cb, err, stream);
  }
  /**
   * Get list of synthesis voices available.
   * The task returns the synthesis voice result.
   * @member SpeechSynthesizer.prototype.getVoicesAsync
   * @function
   * @async
   * @public
   * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.
   * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.
   */
  getVoicesAsync(locale = "") {
    return __awaiter16(this, void 0, void 0, function* () {
      return this.getVoices(locale);
    });
  }
  /**
   * Dispose of associated resources.
   * @member SpeechSynthesizer.prototype.close
   * @function
   * @public
   */
  close(cb, err) {
    Contracts.throwIfDisposed(this.privDisposed);
    marshalPromiseToCallbacks(this.dispose(true), cb, err);
  }
  /**
   * @Internal
   * Do not use externally, object returned will change without warning or notice.
   */
  get internalData() {
    return this.privAdapter;
  }
  /**
   * This method performs cleanup of resources.
   * The Boolean parameter disposing indicates whether the method is called
   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
   * Derived classes should override this method to dispose resource if needed.
   * @member SpeechSynthesizer.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - Flag to request disposal.
   */
  dispose(disposing) {
    return __awaiter16(this, void 0, void 0, function* () {
      if (this.privDisposed) {
        return;
      }
      if (disposing) {
        if (this.privAdapter) {
          yield this.privAdapter.dispose();
        }
      }
      this.privDisposed = true;
    });
  }
  //
  // ################################################################################################################
  // IMPLEMENTATION.
  // Move to independent class
  // ################################################################################################################
  //
  createSynthesizerConfig(speechConfig) {
    return new SynthesizerConfig(speechConfig, this.privProperties);
  }
  // Creates the synthesis adapter
  createSynthesisAdapter(authentication, connectionFactory, audioConfig, synthesizerConfig) {
    return new SynthesisAdapterBase(authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);
  }
  implCommonSynthesizeSetup() {
    let osPlatform = typeof window !== "undefined" ? "Browser" : "Node";
    let osName = "unknown";
    let osVersion = "unknown";
    if (typeof navigator !== "undefined") {
      osPlatform = osPlatform + "/" + navigator.platform;
      osName = navigator.userAgent;
      osVersion = navigator.appVersion;
    }
    const synthesizerConfig = this.createSynthesizerConfig(new SpeechServiceConfig(new Context(new OS(osPlatform, osName, osVersion))));
    const subscriptionKey = this.privProperties.getProperty(PropertyId.SpeechServiceConnection_Key, void 0);
    const authentication = subscriptionKey && subscriptionKey !== "" ? new CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new CognitiveTokenAuthentication(() => {
      const authorizationToken = this.privProperties.getProperty(PropertyId.SpeechServiceAuthorization_Token, void 0);
      return Promise.resolve(authorizationToken);
    }, () => {
      const authorizationToken = this.privProperties.getProperty(PropertyId.SpeechServiceAuthorization_Token, void 0);
      return Promise.resolve(authorizationToken);
    });
    this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, this.audioConfig, synthesizerConfig);
    this.privAdapter.audioOutputFormat = AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(SpeechSynthesisOutputFormat[this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, void 0)]);
    this.privRestAdapter = new SynthesisRestAdapter(synthesizerConfig, authentication);
  }
  speakImpl(text, IsSsml, cb, err, dataStream) {
    try {
      Contracts.throwIfDisposed(this.privDisposed);
      const requestId = createNoDashGuid();
      let audioDestination;
      if (dataStream instanceof PushAudioOutputStreamCallback) {
        audioDestination = new PushAudioOutputStreamImpl(dataStream);
      } else if (dataStream instanceof PullAudioOutputStream) {
        audioDestination = dataStream;
      } else if (dataStream !== void 0) {
        audioDestination = new AudioFileWriter(dataStream);
      } else {
        audioDestination = void 0;
      }
      this.synthesisRequestQueue.enqueue(new SynthesisRequest(requestId, text, IsSsml, (e) => {
        this.privSynthesizing = false;
        if (!!cb) {
          try {
            cb(e);
          } catch (e2) {
            if (!!err) {
              err(e2);
            }
          }
        }
        cb = void 0;
        this.adapterSpeak().catch(() => {
        });
      }, (e) => {
        if (!!err) {
          err(e);
        }
      }, audioDestination));
      this.adapterSpeak().catch(() => {
      });
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
      this.dispose(true).catch(() => {
      });
    }
  }
  getVoices(locale) {
    return __awaiter16(this, void 0, void 0, function* () {
      const requestId = createNoDashGuid();
      const response = yield this.privRestAdapter.getVoicesList(requestId);
      if (response.ok && Array.isArray(response.json)) {
        let json = response.json;
        if (!!locale && locale.length > 0) {
          json = json.filter((item) => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());
        }
        return new SynthesisVoicesResult(requestId, json, void 0);
      } else {
        return new SynthesisVoicesResult(requestId, void 0, `Error: ${response.status}: ${response.statusText}`);
      }
    });
  }
  adapterSpeak() {
    return __awaiter16(this, void 0, void 0, function* () {
      if (!this.privDisposed && !this.privSynthesizing) {
        this.privSynthesizing = true;
        const request = yield this.synthesisRequestQueue.dequeue();
        return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);
      }
    });
  }
  static XMLEncode(text) {
    return text.replace(/&/g, "&amp;").replace(/</g, "&lt;").replace(/>/g, "&gt;").replace(/"/g, "&quot;").replace(/'/g, "&apos;");
  }
};
var SynthesisRequest = class {
  constructor(requestId, text, isSSML, cb, err, dataStream) {
    this.requestId = requestId;
    this.text = text;
    this.isSSML = isSSML;
    this.cb = cb;
    this.err = err;
    this.dataStream = dataStream;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js
var SynthesisResult = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {string} errorDetails - Error details, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   */
  constructor(resultId, reason, errorDetails, properties) {
    this.privResultId = resultId;
    this.privReason = reason;
    this.privErrorDetails = errorDetails;
    this.privProperties = properties;
  }
  /**
   * Specifies the result identifier.
   * @member SynthesisResult.prototype.resultId
   * @function
   * @public
   * @returns {string} Specifies the result identifier.
   */
  get resultId() {
    return this.privResultId;
  }
  /**
   * Specifies status of the result.
   * @member SynthesisResult.prototype.reason
   * @function
   * @public
   * @returns {ResultReason} Specifies status of the result.
   */
  get reason() {
    return this.privReason;
  }
  /**
   * In case of an unsuccessful synthesis, provides details of the occurred error.
   * @member SynthesisResult.prototype.errorDetails
   * @function
   * @public
   * @returns {string} a brief description of an error.
   */
  get errorDetails() {
    return this.privErrorDetails;
  }
  /**
   * The set of properties exposed in the result.
   * @member SynthesisResult.prototype.properties
   * @function
   * @public
   * @returns {PropertyCollection} The set of properties exposed in the result.
   */
  get properties() {
    return this.privProperties;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js
var SpeechSynthesisResult = class extends SynthesisResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {string} resultId - The result id.
   * @param {ResultReason} reason - The reason.
   * @param {ArrayBuffer} audioData - The synthesized audio binary.
   * @param {string} errorDetails - Error details, if provided.
   * @param {PropertyCollection} properties - Additional properties, if provided.
   * @param {number} audioDuration - The audio duration.
   */
  constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {
    super(resultId, reason, errorDetails, properties);
    this.privAudioData = audioData;
    this.privAudioDuration = audioDuration;
  }
  /**
   * The synthesized audio data
   * @member SpeechSynthesisResult.prototype.audioData
   * @function
   * @public
   * @returns {ArrayBuffer} The synthesized audio data.
   */
  get audioData() {
    return this.privAudioData;
  }
  /**
   * The time duration of synthesized audio, in ticks (100 nanoseconds).
   * @member SpeechSynthesisResult.prototype.audioDuration
   * @function
   * @public
   * @returns {number} The time duration of synthesized audio.
   */
  get audioDuration() {
    return this.privAudioDuration;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js
var SpeechSynthesisEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {SpeechSynthesisResult} result - The speech synthesis result.
   */
  constructor(result) {
    this.privResult = result;
  }
  /**
   * Specifies the synthesis result.
   * @member SpeechSynthesisEventArgs.prototype.result
   * @function
   * @public
   * @returns {SpeechSynthesisResult} the synthesis result.
   */
  get result() {
    return this.privResult;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js
var SpeechSynthesisWordBoundaryEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} audioOffset - The audio offset.
   * @param {number} duration - The audio duration.
   * @param {string} text - The text.
   * @param {number} wordLength - The length of the word.
   * @param {number} textOffset - The text offset.
   * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type
   */
  constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {
    this.privAudioOffset = audioOffset;
    this.privDuration = duration;
    this.privText = text;
    this.privWordLength = wordLength;
    this.privTextOffset = textOffset;
    this.privBoundaryType = boundaryType;
  }
  /**
   * Specifies the audio offset.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset
   * @function
   * @public
   * @returns {number} the audio offset.
   */
  get audioOffset() {
    return this.privAudioOffset;
  }
  /**
   * Specifies the duration, in ticks (100 nanoseconds).
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration
   * @function
   * @public
   * @returns {number} Duration in 100 nanosecond increments.
   */
  get duration() {
    return this.privDuration;
  }
  /**
   * Specifies the text of the word boundary event.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text
   * @function
   * @public
   * @returns {string} the text.
   */
  get text() {
    return this.privText;
  }
  /**
   * Specifies the word length
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength
   * @function
   * @public
   * @returns {number} the word length
   */
  get wordLength() {
    return this.privWordLength;
  }
  /**
   * Specifies the text offset.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset
   * @function
   * @public
   * @returns {number} the text offset.
   */
  get textOffset() {
    return this.privTextOffset;
  }
  /**
   * Specifies the boundary type.
   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType
   * @function
   * @public
   * @returns {SpeechSynthesisBoundaryType} the boundary type.
   */
  get boundaryType() {
    return this.privBoundaryType;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js
var SpeechSynthesisBookmarkEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} audioOffset - The audio offset.
   * @param {string} text - The bookmark text.
   */
  constructor(audioOffset, text) {
    this.privAudioOffset = audioOffset;
    this.privText = text;
  }
  /**
   * Specifies the audio offset.
   * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset
   * @function
   * @public
   * @returns {number} the audio offset.
   */
  get audioOffset() {
    return this.privAudioOffset;
  }
  /**
   * Specifies the bookmark.
   * @member SpeechSynthesisBookmarkEventArgs.prototype.text
   * @function
   * @public
   * @returns {string} the bookmark text.
   */
  get text() {
    return this.privText;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js
var SpeechSynthesisVisemeEventArgs = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param {number} audioOffset - The audio offset.
   * @param {number} visemeId - The viseme ID.
   * @param {string} animation - The animation, could be in svg or other format.
   */
  constructor(audioOffset, visemeId, animation) {
    this.privAudioOffset = audioOffset;
    this.privVisemeId = visemeId;
    this.privAnimation = animation;
  }
  /**
   * Specifies the audio offset.
   * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset
   * @function
   * @public
   * @returns {number} the audio offset.
   */
  get audioOffset() {
    return this.privAudioOffset;
  }
  /**
   * Specifies the viseme ID.
   * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId
   * @function
   * @public
   * @returns {number} the viseme ID.
   */
  get visemeId() {
    return this.privVisemeId;
  }
  /**
   * Specifies the animation.
   * @member SpeechSynthesisVisemeEventArgs.prototype.animation
   * @function
   * @public
   * @returns {string} the animation, could be in svg or other format.
   */
  get animation() {
    return this.privAnimation;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js
var SpeechSynthesisBoundaryType;
(function(SpeechSynthesisBoundaryType2) {
  SpeechSynthesisBoundaryType2["Word"] = "WordBoundary";
  SpeechSynthesisBoundaryType2["Punctuation"] = "PunctuationBoundary";
  SpeechSynthesisBoundaryType2["Sentence"] = "SentenceBoundary";
})(SpeechSynthesisBoundaryType || (SpeechSynthesisBoundaryType = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js
var SynthesisVoicesResult = class extends SynthesisResult {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param requestId - result id for request.
   * @param json - json payload from endpoint.
   */
  constructor(requestId, json, errorDetails) {
    if (Array.isArray(json)) {
      super(requestId, ResultReason.VoicesListRetrieved, void 0, new PropertyCollection());
      this.privVoices = [];
      for (const item of json) {
        this.privVoices.push(new VoiceInfo(item));
      }
    } else {
      super(requestId, ResultReason.Canceled, errorDetails ? errorDetails : "Error information unavailable", new PropertyCollection());
    }
  }
  /**
   * The list of voices
   * @member SynthesisVoicesResult.prototype.voices
   * @function
   * @public
   * @returns {VoiceInfo[]} List of synthesized voices.
   */
  get voices() {
    return this.privVoices;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js
var SynthesisVoiceGender;
(function(SynthesisVoiceGender2) {
  SynthesisVoiceGender2[SynthesisVoiceGender2["Unknown"] = 0] = "Unknown";
  SynthesisVoiceGender2[SynthesisVoiceGender2["Female"] = 1] = "Female";
  SynthesisVoiceGender2[SynthesisVoiceGender2["Male"] = 2] = "Male";
})(SynthesisVoiceGender || (SynthesisVoiceGender = {}));
var SynthesisVoiceType;
(function(SynthesisVoiceType2) {
  SynthesisVoiceType2[SynthesisVoiceType2["OnlineNeural"] = 1] = "OnlineNeural";
  SynthesisVoiceType2[SynthesisVoiceType2["OnlineStandard"] = 2] = "OnlineStandard";
  SynthesisVoiceType2[SynthesisVoiceType2["OfflineNeural"] = 3] = "OfflineNeural";
  SynthesisVoiceType2[SynthesisVoiceType2["OfflineStandard"] = 4] = "OfflineStandard";
})(SynthesisVoiceType || (SynthesisVoiceType = {}));
var VoiceInfo = class {
  constructor(json) {
    this.privStyleList = [];
    this.privVoicePath = "";
    if (!!json) {
      this.privName = json.Name;
      this.privLocale = json.Locale;
      this.privShortName = json.ShortName;
      this.privLocalName = json.LocalName;
      this.privVoiceType = json.VoiceType.endsWith("Standard") ? SynthesisVoiceType.OnlineStandard : SynthesisVoiceType.OnlineNeural;
      this.privGender = json.Gender === "Male" ? SynthesisVoiceGender.Male : json.Gender === "Female" ? SynthesisVoiceGender.Female : SynthesisVoiceGender.Unknown;
      if (!!json.StyleList && Array.isArray(json.StyleList)) {
        for (const style of json.StyleList) {
          this.privStyleList.push(style);
        }
      }
    }
  }
  get name() {
    return this.privName;
  }
  get locale() {
    return this.privLocale;
  }
  get shortName() {
    return this.privShortName;
  }
  get localName() {
    return this.privLocalName;
  }
  get gender() {
    return this.privGender;
  }
  get voiceType() {
    return this.privVoiceType;
  }
  get styleList() {
    return this.privStyleList;
  }
  get voicePath() {
    return this.privVoicePath;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js
var __awaiter17 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var MediaDurationPlaceholderSeconds = 60 * 30;
var AudioFormatToMimeType = {
  [AudioFormatTag.PCM]: "audio/wav",
  [AudioFormatTag.MuLaw]: "audio/x-wav",
  [AudioFormatTag.MP3]: "audio/mpeg",
  [AudioFormatTag.OGG_OPUS]: "audio/ogg",
  [AudioFormatTag.WEBM_OPUS]: "audio/webm; codecs=opus",
  [AudioFormatTag.ALaw]: "audio/x-wav",
  [AudioFormatTag.FLAC]: "audio/flac"
};
var SpeakerAudioDestination = class {
  constructor(audioDestinationId) {
    this.privPlaybackStarted = false;
    this.privAppendingToBuffer = false;
    this.privMediaSourceOpened = false;
    this.privBytesReceived = 0;
    this.privId = audioDestinationId ? audioDestinationId : createNoDashGuid();
    this.privIsPaused = false;
    this.privIsClosed = false;
  }
  id() {
    return this.privId;
  }
  write(buffer, cb, err) {
    if (this.privAudioBuffer !== void 0) {
      this.privAudioBuffer.push(buffer);
      this.updateSourceBuffer().then(() => {
        if (!!cb) {
          cb();
        }
      }, (error) => {
        if (!!err) {
          err(error);
        }
      });
    } else if (this.privAudioOutputStream !== void 0) {
      this.privAudioOutputStream.write(buffer);
      this.privBytesReceived += buffer.byteLength;
    }
  }
  close(cb, err) {
    this.privIsClosed = true;
    if (this.privSourceBuffer !== void 0) {
      this.handleSourceBufferUpdateEnd().then(() => {
        if (!!cb) {
          cb();
        }
      }, (error) => {
        if (!!err) {
          err(error);
        }
      });
    } else if (this.privAudioOutputStream !== void 0 && typeof window !== "undefined") {
      if ((this.privFormat.formatTag === AudioFormatTag.PCM || this.privFormat.formatTag === AudioFormatTag.MuLaw || this.privFormat.formatTag === AudioFormatTag.ALaw) && this.privFormat.hasHeader === false) {
        console.warn("Play back is not supported for raw PCM, mulaw or alaw format without header.");
        if (!!this.onAudioEnd) {
          this.onAudioEnd(this);
        }
      } else {
        let receivedAudio = new ArrayBuffer(this.privBytesReceived);
        this.privAudioOutputStream.read(receivedAudio).then(() => {
          receivedAudio = SynthesisAdapterBase.addHeader(receivedAudio, this.privFormat);
          const audioBlob = new Blob([receivedAudio], { type: AudioFormatToMimeType[this.privFormat.formatTag] });
          this.privAudio.src = window.URL.createObjectURL(audioBlob);
          this.notifyPlayback().then(() => {
            if (!!cb) {
              cb();
            }
          }, (error) => {
            if (!!err) {
              err(error);
            }
          });
        }, (error) => {
          if (!!err) {
            err(error);
          }
        });
      }
    } else {
      if (!!this.onAudioEnd) {
        this.onAudioEnd(this);
      }
    }
  }
  set format(format) {
    if (typeof AudioContext !== "undefined" || typeof window !== "undefined" && typeof window.webkitAudioContext !== "undefined") {
      this.privFormat = format;
      const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];
      if (mimeType === void 0) {
        console.warn(`Unknown mimeType for format ${AudioFormatTag[this.privFormat.formatTag]}; playback is not supported.`);
      } else if (typeof MediaSource !== "undefined" && MediaSource.isTypeSupported(mimeType)) {
        this.privAudio = new Audio();
        this.privAudioBuffer = [];
        this.privMediaSource = new MediaSource();
        this.privAudio.src = URL.createObjectURL(this.privMediaSource);
        this.privAudio.load();
        this.privMediaSource.onsourceopen = () => {
          this.privMediaSourceOpened = true;
          this.privMediaSource.duration = MediaDurationPlaceholderSeconds;
          this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);
          this.privSourceBuffer.onupdate = () => {
            this.updateSourceBuffer().catch((reason) => {
              Events.instance.onEvent(new BackgroundEvent(reason));
            });
          };
          this.privSourceBuffer.onupdateend = () => {
            this.handleSourceBufferUpdateEnd().catch((reason) => {
              Events.instance.onEvent(new BackgroundEvent(reason));
            });
          };
          this.privSourceBuffer.onupdatestart = () => {
            this.privAppendingToBuffer = false;
          };
        };
        this.updateSourceBuffer().catch((reason) => {
          Events.instance.onEvent(new BackgroundEvent(reason));
        });
      } else {
        console.warn(`Format ${AudioFormatTag[this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);
        this.privAudioOutputStream = new PullAudioOutputStreamImpl();
        this.privAudioOutputStream.format = this.privFormat;
        this.privAudio = new Audio();
      }
    }
  }
  get volume() {
    var _a, _b;
    return (_b = (_a = this.privAudio) === null || _a === void 0 ? void 0 : _a.volume) !== null && _b !== void 0 ? _b : -1;
  }
  set volume(volume) {
    if (!!this.privAudio) {
      this.privAudio.volume = volume;
    }
  }
  mute() {
    if (!!this.privAudio) {
      this.privAudio.muted = true;
    }
  }
  unmute() {
    if (!!this.privAudio) {
      this.privAudio.muted = false;
    }
  }
  get isClosed() {
    return this.privIsClosed;
  }
  get currentTime() {
    if (this.privAudio !== void 0) {
      return this.privAudio.currentTime;
    }
    return -1;
  }
  pause() {
    if (!this.privIsPaused && this.privAudio !== void 0) {
      this.privAudio.pause();
      this.privIsPaused = true;
    }
  }
  resume(cb, err) {
    if (this.privIsPaused && this.privAudio !== void 0) {
      this.privAudio.play().then(() => {
        if (!!cb) {
          cb();
        }
      }, (error) => {
        if (!!err) {
          err(error);
        }
      });
      this.privIsPaused = false;
    }
  }
  get internalAudio() {
    return this.privAudio;
  }
  updateSourceBuffer() {
    return __awaiter17(this, void 0, void 0, function* () {
      if (this.privAudioBuffer !== void 0 && this.privAudioBuffer.length > 0 && this.sourceBufferAvailable()) {
        this.privAppendingToBuffer = true;
        const binary = this.privAudioBuffer.shift();
        try {
          this.privSourceBuffer.appendBuffer(binary);
        } catch (error) {
          this.privAudioBuffer.unshift(binary);
          console.log("buffer filled, pausing addition of binaries until space is made");
          return;
        }
        yield this.notifyPlayback();
      } else if (this.canEndStream()) {
        yield this.handleSourceBufferUpdateEnd();
      }
    });
  }
  handleSourceBufferUpdateEnd() {
    return __awaiter17(this, void 0, void 0, function* () {
      if (this.canEndStream() && this.sourceBufferAvailable()) {
        this.privMediaSource.endOfStream();
        yield this.notifyPlayback();
      }
    });
  }
  notifyPlayback() {
    return __awaiter17(this, void 0, void 0, function* () {
      if (!this.privPlaybackStarted && this.privAudio !== void 0) {
        this.privPlaybackStarted = true;
        if (!!this.onAudioStart) {
          this.onAudioStart(this);
        }
        this.privAudio.onended = () => {
          if (!!this.onAudioEnd) {
            this.onAudioEnd(this);
          }
        };
        if (!this.privIsPaused) {
          yield this.privAudio.play();
        }
      }
    });
  }
  canEndStream() {
    return this.isClosed && this.privSourceBuffer !== void 0 && this.privAudioBuffer.length === 0 && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === "open";
  }
  sourceBufferAvailable() {
    return this.privSourceBuffer !== void 0 && !this.privSourceBuffer.updating;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js
var ConversationTranscriptionCanceledEventArgs = class extends CancellationEventArgsBase {
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js
var PronunciationAssessmentGradingSystem;
(function(PronunciationAssessmentGradingSystem2) {
  PronunciationAssessmentGradingSystem2[PronunciationAssessmentGradingSystem2["FivePoint"] = 1] = "FivePoint";
  PronunciationAssessmentGradingSystem2[PronunciationAssessmentGradingSystem2["HundredMark"] = 2] = "HundredMark";
})(PronunciationAssessmentGradingSystem || (PronunciationAssessmentGradingSystem = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js
var PronunciationAssessmentGranularity;
(function(PronunciationAssessmentGranularity2) {
  PronunciationAssessmentGranularity2[PronunciationAssessmentGranularity2["Phoneme"] = 1] = "Phoneme";
  PronunciationAssessmentGranularity2[PronunciationAssessmentGranularity2["Word"] = 2] = "Word";
  PronunciationAssessmentGranularity2[PronunciationAssessmentGranularity2["FullText"] = 3] = "FullText";
})(PronunciationAssessmentGranularity || (PronunciationAssessmentGranularity = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js
var PronunciationAssessmentConfig = class {
  /**
   * PronunciationAssessmentConfig constructor.
   * @constructor
   * @param {string} referenceText
   * @param gradingSystem
   * @param granularity
   * @param enableMiscue
   */
  constructor(referenceText, gradingSystem = PronunciationAssessmentGradingSystem.FivePoint, granularity = PronunciationAssessmentGranularity.Phoneme, enableMiscue = false) {
    Contracts.throwIfNullOrUndefined(referenceText, "referenceText");
    this.privProperties = new PropertyCollection();
    this.privProperties.setProperty(PropertyId.PronunciationAssessment_ReferenceText, referenceText);
    this.privProperties.setProperty(PropertyId.PronunciationAssessment_GradingSystem, PronunciationAssessmentGradingSystem[gradingSystem]);
    this.privProperties.setProperty(PropertyId.PronunciationAssessment_Granularity, PronunciationAssessmentGranularity[granularity]);
    this.privProperties.setProperty(PropertyId.PronunciationAssessment_EnableMiscue, String(enableMiscue));
  }
  /**
   * @member PronunciationAssessmentConfig.fromJSON
   * @function
   * @public
   * @param {string} json The json string containing the pronunciation assessment parameters.
   * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
   * @summary Creates an instance of the PronunciationAssessmentConfig from json.
   */
  static fromJSON(json) {
    Contracts.throwIfNullOrUndefined(json, "json");
    const config = new PronunciationAssessmentConfig("");
    config.privProperties = new PropertyCollection();
    config.properties.setProperty(PropertyId.PronunciationAssessment_Json, json);
    return config;
  }
  toJSON() {
    this.updateJson();
    return this.privProperties.getProperty(PropertyId.PronunciationAssessment_Params);
  }
  applyTo(recognizer) {
    this.updateJson();
    const recoBase = recognizer.internalData;
    recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(PropertyId.PronunciationAssessment_Params));
  }
  /**
   * Gets the reference text.
   * @member PronunciationAssessmentConfig.prototype.referenceText
   * @function
   * @public
   * @returns {string} Reference text.
   */
  get referenceText() {
    return this.properties.getProperty(PropertyId.PronunciationAssessment_ReferenceText);
  }
  /**
   * Gets/Sets the reference text.
   * @member PronunciationAssessmentConfig.prototype.referenceText
   * @function
   * @public
   * @param {string} referenceText - Reference text.
   */
  set referenceText(referenceText) {
    Contracts.throwIfNullOrWhitespace(referenceText, "referenceText");
    this.properties.setProperty(PropertyId.PronunciationAssessment_ReferenceText, referenceText);
  }
  /**
   * Sets the phoneme alphabet.
   * The valid values are "SAPI" (default) and "IPA".
   * Added in version 1.20.0
   * @member PronunciationAssessmentConfig.prototype.phonemeAlphabet
   * @function
   * @public
   * @param {string} phonemeAlphabet - Phoneme alphabet.
   */
  set phonemeAlphabet(phonemeAlphabet) {
    Contracts.throwIfNullOrWhitespace(phonemeAlphabet, "phonemeAlphabet");
    this.privPhonemeAlphabet = phonemeAlphabet;
  }
  /**
   * Sets the boolean enableMiscue property.
   * Added in version 1.26.0
   * @member PronunciationAssessmentConfig.prototype.enableMiscue
   * @function
   * @public
   * @param {boolean} enableMiscue - enable miscue.
   */
  set enableMiscue(enableMiscue) {
    const enableMiscueString = enableMiscue ? "true" : "false";
    this.properties.setProperty(PropertyId.PronunciationAssessment_EnableMiscue, enableMiscueString);
  }
  /**
   * Gets the boolean enableMiscue property.
   * Added in version 1.26.0
   * @member PronunciationAssessmentConfig.prototype.enableMiscue
   * @function
   * @public
   * @return {boolean} enableMiscue - enable miscue.
   */
  get enableMiscue() {
    const enableMiscueString = this.properties.getProperty(PropertyId.PronunciationAssessment_EnableMiscue, "false");
    return enableMiscueString.toLowerCase() === "true";
  }
  /**
   * Sets the nbest phoneme count
   * Added in version 1.20.0
   * @member PronunciationAssessmentConfig.prototype.nbestPhonemeCount
   * @function
   * @public
   * @param {number} nbestPhonemeCount - NBest phoneme count.
   */
  set nbestPhonemeCount(nbestPhonemeCount) {
    this.privNBestPhonemeCount = nbestPhonemeCount;
  }
  /**
   * @member PronunciationAssessmentConfig.prototype.properties
   * @function
   * @public
   * @return {PropertyCollection} Properties of the config.
   * @summary Gets a pronunciation assessment config properties
   */
  get properties() {
    return this.privProperties;
  }
  updateJson() {
    const jsonString = this.privProperties.getProperty(PropertyId.PronunciationAssessment_Json, "{}");
    const paramsJson = JSON.parse(jsonString);
    const referenceText = this.privProperties.getProperty(PropertyId.PronunciationAssessment_ReferenceText);
    if (referenceText) {
      paramsJson.referenceText = referenceText;
    }
    const gradingSystem = this.privProperties.getProperty(PropertyId.PronunciationAssessment_GradingSystem);
    if (gradingSystem) {
      paramsJson.gradingSystem = gradingSystem;
    }
    const granularity = this.privProperties.getProperty(PropertyId.PronunciationAssessment_Granularity);
    if (granularity) {
      paramsJson.granularity = granularity;
    }
    if (this.privPhonemeAlphabet) {
      paramsJson.phonemeAlphabet = this.privPhonemeAlphabet;
    }
    if (this.privNBestPhonemeCount) {
      paramsJson.nbestPhonemeCount = this.privNBestPhonemeCount;
    }
    paramsJson.dimension = "Comprehensive";
    paramsJson.enableMiscue = this.enableMiscue;
    this.privProperties.setProperty(PropertyId.PronunciationAssessment_Params, JSON.stringify(paramsJson));
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js
var PronunciationAssessmentResult = class {
  constructor(jsonString) {
    const j = JSON.parse(jsonString);
    Contracts.throwIfNullOrUndefined(j.NBest[0], "NBest");
    this.privPronJson = j.NBest[0];
  }
  /**
   * @member PronunciationAssessmentResult.fromResult
   * @function
   * @public
   * @param {RecognitionResult} result The recognition result.
   * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
   * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.
   */
  static fromResult(result) {
    Contracts.throwIfNullOrUndefined(result, "result");
    const json = result.properties.getProperty(PropertyId.SpeechServiceResponse_JsonResult);
    Contracts.throwIfNullOrUndefined(json, "json");
    return new PronunciationAssessmentResult(json);
  }
  /**
   * Gets the detail result of pronunciation assessment.
   * @member PronunciationAssessmentConfig.prototype.detailResult
   * @function
   * @public
   * @returns {DetailResult} detail result.
   */
  get detailResult() {
    return this.privPronJson;
  }
  /**
   * The score indicating the pronunciation accuracy of the given speech, which indicates
   * how closely the phonemes match a native speaker's pronunciation.
   * @member PronunciationAssessmentResult.prototype.accuracyScore
   * @function
   * @public
   * @returns {number} Accuracy score.
   */
  get accuracyScore() {
    return this.detailResult.PronunciationAssessment.AccuracyScore;
  }
  /**
   * The overall score indicating the pronunciation quality of the given speech.
   * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.
   * @member PronunciationAssessmentResult.prototype.pronunciationScore
   * @function
   * @public
   * @returns {number} Pronunciation score.
   */
  get pronunciationScore() {
    return this.detailResult.PronunciationAssessment.PronScore;
  }
  /**
   * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.
   * @member PronunciationAssessmentResult.prototype.completenessScore
   * @function
   * @public
   * @returns {number} Completeness score.
   */
  get completenessScore() {
    return this.detailResult.PronunciationAssessment.CompletenessScore;
  }
  /**
   * The score indicating the fluency of the given speech.
   * @member PronunciationAssessmentResult.prototype.fluencyScore
   * @function
   * @public
   * @returns {number} Fluency score.
   */
  get fluencyScore() {
    return this.detailResult.PronunciationAssessment.FluencyScore;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js
var Diagnostics = class {
  static SetLoggingLevel(logLevel) {
    this.privListener = new ConsoleLoggingListener(logLevel);
    Events.instance.attachConsoleListener(this.privListener);
  }
  static StartConsoleOutput() {
    if (!!this.privListener) {
      this.privListener.enableConsoleOutput = true;
    }
  }
  static StopConsoleOutput() {
    if (!!this.privListener) {
      this.privListener.enableConsoleOutput = false;
    }
  }
  static SetLogOutputPath(path) {
    if (typeof window === "undefined") {
      if (!!this.privListener) {
        this.privListener.logPath = path;
      }
    } else {
      throw new Error("File system logging not available in browser.");
    }
  }
};
Diagnostics.privListener = void 0;

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js
var IntentConnectionFactory = class extends ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint);
    if (!endpoint) {
      const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_IntentRegion);
      const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
      const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, "wss://" + region + ".sr.speech" + hostSuffix);
      endpoint = host + "/speech/recognition/interactive/cognitiveservices/v1";
    }
    const queryParams = {
      format: "simple",
      language: config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage)
    };
    this.setCommonUrlParams(config, queryParams, endpoint);
    const headers = {};
    if (authInfo.token !== void 0 && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  getSpeechRegionFromIntentRegion(intentRegion) {
    switch (intentRegion) {
      case "West US":
      case "US West":
      case "westus":
        return "uswest";
      case "West US 2":
      case "US West 2":
      case "westus2":
        return "uswest2";
      case "South Central US":
      case "US South Central":
      case "southcentralus":
        return "ussouthcentral";
      case "West Central US":
      case "US West Central":
      case "westcentralus":
        return "uswestcentral";
      case "East US":
      case "US East":
      case "eastus":
        return "useast";
      case "East US 2":
      case "US East 2":
      case "eastus2":
        return "useast2";
      case "West Europe":
      case "Europe West":
      case "westeurope":
        return "europewest";
      case "North Europe":
      case "Europe North":
      case "northeurope":
        return "europenorth";
      case "Brazil South":
      case "South Brazil":
      case "southbrazil":
        return "brazilsouth";
      case "Australia East":
      case "East Australia":
      case "eastaustralia":
        return "australiaeast";
      case "Southeast Asia":
      case "Asia Southeast":
      case "southeastasia":
        return "asiasoutheast";
      case "East Asia":
      case "Asia East":
      case "eastasia":
        return "asiaeast";
      default:
        return intentRegion;
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConnectionFactory.js
var SpeakerRecognitionConnectionFactoryBase = class extends ConnectionFactoryBase {
  create(config, authInfo, endpointPath, connectionId) {
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint);
    if (!endpoint) {
      const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region);
      const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
      const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, `wss://${region}.spr-frontend.speech${hostSuffix}`);
      const scenario = config.parameters.getProperty(PropertyId.SpeechServiceConnection_SpeakerIdMode, "TextIndependentIdentification");
      endpoint = `${host}/speaker/ws/${this.scenarioToPath(scenario)}/${endpointPath}`;
    }
    const queryParams = {
      format: "simple",
      language: config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage)
    };
    this.setCommonUrlParams(config, queryParams, endpoint);
    const headers = {};
    if (authInfo.token !== void 0 && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    headers[HeaderNames.SpIDAuthKey] = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Key);
    config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  scenarioToPath(mode) {
    switch (mode) {
      case "TextIndependentVerification":
      case "2":
        return "verification/text-independent";
      case "TextDependentVerification":
      case "1":
        return "verification/text-dependent";
      default:
        return "identification/text-independent";
    }
  }
};
var SpeakerRecognitionConnectionFactory = class extends SpeakerRecognitionConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    return super.create(config, authInfo, "recognition", connectionId);
  }
};
var VoiceProfileConnectionFactory = class extends SpeakerRecognitionConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    return super.create(config, authInfo, "profile", connectionId);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js
var SpeechRecognitionEvent = class extends PlatformEvent {
  constructor(eventName, requestId, sessionId, eventType = EventType.Info) {
    super(eventName, eventType);
    this.privRequestId = requestId;
    this.privSessionId = sessionId;
  }
  get requestId() {
    return this.privRequestId;
  }
  get sessionId() {
    return this.privSessionId;
  }
};
var RecognitionTriggeredEvent = class extends SpeechRecognitionEvent {
  constructor(requestId, sessionId, audioSourceId, audioNodeId) {
    super("RecognitionTriggeredEvent", requestId, sessionId);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
};
var ListeningStartedEvent = class extends SpeechRecognitionEvent {
  constructor(requestId, sessionId, audioSourceId, audioNodeId) {
    super("ListeningStartedEvent", requestId, sessionId);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
};
var ConnectingToServiceEvent = class extends SpeechRecognitionEvent {
  constructor(requestId, authFetchEventid, sessionId) {
    super("ConnectingToServiceEvent", requestId, sessionId);
    this.privAuthFetchEventid = authFetchEventid;
  }
  get authFetchEventid() {
    return this.privAuthFetchEventid;
  }
};
var RecognitionStartedEvent = class extends SpeechRecognitionEvent {
  constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {
    super("RecognitionStartedEvent", requestId, sessionId);
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
    this.privAuthFetchEventId = authFetchEventId;
  }
  get audioSourceId() {
    return this.privAudioSourceId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
};
var RecognitionCompletionStatus;
(function(RecognitionCompletionStatus2) {
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["Success"] = 0] = "Success";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["AudioSourceError"] = 1] = "AudioSourceError";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["AudioSourceTimeout"] = 2] = "AudioSourceTimeout";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["AuthTokenFetchError"] = 3] = "AuthTokenFetchError";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["AuthTokenFetchTimeout"] = 4] = "AuthTokenFetchTimeout";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["UnAuthorized"] = 5] = "UnAuthorized";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["ConnectTimeout"] = 6] = "ConnectTimeout";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["ConnectError"] = 7] = "ConnectError";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["ClientRecognitionActivityTimeout"] = 8] = "ClientRecognitionActivityTimeout";
  RecognitionCompletionStatus2[RecognitionCompletionStatus2["UnknownError"] = 9] = "UnknownError";
})(RecognitionCompletionStatus || (RecognitionCompletionStatus = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js
var SpeechConnectionMessage = class extends ConnectionMessage {
  constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {
    if (!path) {
      throw new ArgumentNullError("path");
    }
    if (!requestId) {
      throw new ArgumentNullError("requestId");
    }
    const headers = {};
    headers[HeaderNames.Path] = path;
    headers[HeaderNames.RequestId] = requestId;
    headers[HeaderNames.RequestTimestamp] = (/* @__PURE__ */ new Date()).toISOString();
    if (contentType) {
      headers[HeaderNames.ContentType] = contentType;
    }
    if (streamId) {
      headers[HeaderNames.RequestStreamId] = streamId;
    }
    if (additionalHeaders) {
      for (const headerName in additionalHeaders) {
        if (headerName) {
          headers[headerName] = additionalHeaders[headerName];
        }
      }
    }
    if (id) {
      super(messageType, body, headers, id);
    } else {
      super(messageType, body, headers);
    }
    this.privPath = path;
    this.privRequestId = requestId;
    this.privContentType = contentType;
    this.privStreamId = streamId;
    this.privAdditionalHeaders = additionalHeaders;
  }
  get path() {
    return this.privPath;
  }
  get requestId() {
    return this.privRequestId;
  }
  get contentType() {
    return this.privContentType;
  }
  get streamId() {
    return this.privStreamId;
  }
  get additionalHeaders() {
    return this.privAdditionalHeaders;
  }
  static fromConnectionMessage(message) {
    let path = null;
    let requestId = null;
    let contentType = null;
    let streamId = null;
    const additionalHeaders = {};
    if (message.headers) {
      for (const headerName in message.headers) {
        if (headerName) {
          if (headerName.toLowerCase() === HeaderNames.Path.toLowerCase()) {
            path = message.headers[headerName];
          } else if (headerName.toLowerCase() === HeaderNames.RequestId.toLowerCase()) {
            requestId = message.headers[headerName];
          } else if (headerName.toLowerCase() === HeaderNames.ContentType.toLowerCase()) {
            contentType = message.headers[headerName];
          } else if (headerName.toLowerCase() === HeaderNames.RequestStreamId.toLowerCase()) {
            streamId = message.headers[headerName];
          } else {
            additionalHeaders[headerName] = message.headers[headerName];
          }
        }
      }
    }
    return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js
var __awaiter18 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var ServiceRecognizerBase = class {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    this.privConnectionConfigurationPromise = void 0;
    this.privConnectionPromise = void 0;
    this.privSetTimeout = setTimeout;
    this.privIsLiveAudio = false;
    this.recognizeOverride = void 0;
    this.recognizeSpeaker = void 0;
    this.disconnectOverride = void 0;
    this.receiveMessageOverride = void 0;
    this.sendPrePayloadJSONOverride = void 0;
    this.postConnectImplOverride = void 0;
    this.configConnectionOverride = void 0;
    this.handleSpeechPhraseMessage = void 0;
    this.handleSpeechHypothesisMessage = void 0;
    if (!authentication) {
      throw new ArgumentNullError("authentication");
    }
    if (!connectionFactory) {
      throw new ArgumentNullError("connectionFactory");
    }
    if (!audioSource) {
      throw new ArgumentNullError("audioSource");
    }
    if (!recognizerConfig) {
      throw new ArgumentNullError("recognizerConfig");
    }
    this.privMustReportEndOfStream = false;
    this.privAuthentication = authentication;
    this.privConnectionFactory = connectionFactory;
    this.privAudioSource = audioSource;
    this.privRecognizerConfig = recognizerConfig;
    this.privIsDisposed = false;
    this.privRecognizer = recognizer;
    this.privRequestSession = new RequestSession(this.privAudioSource.id());
    this.privConnectionEvents = new EventSource();
    this.privServiceEvents = new EventSource();
    this.privDynamicGrammar = new DynamicGrammarBuilder();
    this.privSpeechContext = new SpeechContext(this.privDynamicGrammar);
    this.privAgentConfig = new AgentConfig();
    if (typeof Blob !== "undefined" && typeof Worker !== "undefined") {
      this.privSetTimeout = Timeout.setTimeout;
    }
    this.connectionEvents.attach((connectionEvent) => {
      if (connectionEvent.name === "ConnectionClosedEvent") {
        const connectionClosedEvent = connectionEvent;
        if (connectionClosedEvent.statusCode === 1003 || connectionClosedEvent.statusCode === 1007 || connectionClosedEvent.statusCode === 1002 || connectionClosedEvent.statusCode === 4e3 || this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {
          void this.cancelRecognitionLocal(CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? CancellationErrorCode.BadRequestParameters : CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);
        }
      }
    });
  }
  get audioSource() {
    return this.privAudioSource;
  }
  get speechContext() {
    return this.privSpeechContext;
  }
  get dynamicGrammar() {
    return this.privDynamicGrammar;
  }
  get agentConfig() {
    return this.privAgentConfig;
  }
  set conversationTranslatorToken(token) {
    this.privRecognizerConfig.parameters.setProperty(PropertyId.ConversationTranslator_Token, token);
  }
  set voiceProfileType(type2) {
    this.privRecognizerConfig.parameters.setProperty(PropertyId.SpeechServiceConnection_SpeakerIdMode, type2);
  }
  set authentication(auth) {
    this.privAuthentication = this.authentication;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose(reason) {
    return __awaiter18(this, void 0, void 0, function* () {
      this.privIsDisposed = true;
      if (this.privConnectionConfigurationPromise !== void 0) {
        try {
          const connection = yield this.privConnectionConfigurationPromise;
          yield connection.dispose(reason);
        } catch (error) {
          return;
        }
      }
    });
  }
  get connectionEvents() {
    return this.privConnectionEvents;
  }
  get serviceEvents() {
    return this.privServiceEvents;
  }
  get recognitionMode() {
    return this.privRecognizerConfig.recognitionMode;
  }
  recognize(recoMode, successCallback, errorCallBack) {
    return __awaiter18(this, void 0, void 0, function* () {
      if (this.recognizeOverride !== void 0) {
        yield this.recognizeOverride(recoMode, successCallback, errorCallBack);
        return;
      }
      this.privConnectionConfigurationPromise = void 0;
      this.privRecognizerConfig.recognitionMode = recoMode;
      this.setSpeechSegmentationTimeout();
      this.privSuccessCallback = successCallback;
      this.privErrorCallback = errorCallBack;
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);
      const conPromise = this.connectImpl();
      let audioNode;
      try {
        const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);
        const format = yield this.audioSource.format;
        const deviceInfo = yield this.audioSource.deviceInfo;
        this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === type.Microphones;
        audioNode = new ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);
        yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
      } catch (error) {
        yield this.privRequestSession.onStopRecognizing();
        throw error;
      }
      try {
        yield conPromise;
      } catch (error) {
        yield this.cancelRecognitionLocal(CancellationReason.Error, CancellationErrorCode.ConnectionFailure, error);
        return;
      }
      const sessionStartEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      void this.receiveMessage();
      const audioSendPromise = this.sendAudio(audioNode);
      audioSendPromise.catch((error) => __awaiter18(this, void 0, void 0, function* () {
        yield this.cancelRecognitionLocal(CancellationReason.Error, CancellationErrorCode.RuntimeError, error);
      }));
      return;
    });
  }
  stopRecognizing() {
    return __awaiter18(this, void 0, void 0, function* () {
      if (this.privRequestSession.isRecognizing) {
        try {
          yield this.audioSource.turnOff();
          yield this.sendFinalAudio();
          yield this.privRequestSession.onStopRecognizing();
          yield this.privRequestSession.turnCompletionPromise;
        } finally {
          yield this.privRequestSession.dispose();
        }
      }
      return;
    });
  }
  connect() {
    return __awaiter18(this, void 0, void 0, function* () {
      yield this.connectImpl();
      return Promise.resolve();
    });
  }
  connectAsync(cb, err) {
    this.connectImpl().then(() => {
      try {
        if (!!cb) {
          cb();
        }
      } catch (e) {
        if (!!err) {
          err(e);
        }
      }
    }, (reason) => {
      try {
        if (!!err) {
          err(reason);
        }
      } catch (error) {
      }
    });
  }
  disconnect() {
    return __awaiter18(this, void 0, void 0, function* () {
      yield this.cancelRecognitionLocal(CancellationReason.Error, CancellationErrorCode.NoError, "Disconnecting");
      if (this.disconnectOverride !== void 0) {
        yield this.disconnectOverride();
      }
      if (this.privConnectionPromise !== void 0) {
        try {
          yield (yield this.privConnectionPromise).dispose();
        } catch (error) {
        }
      }
      this.privConnectionPromise = void 0;
    });
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  sendMessage(message) {
    return;
  }
  sendNetworkMessage(path, payload) {
    return __awaiter18(this, void 0, void 0, function* () {
      const type2 = typeof payload === "string" ? MessageType.Text : MessageType.Binary;
      const contentType = typeof payload === "string" ? "application/json" : "";
      const connection = yield this.fetchConnection();
      return connection.send(new SpeechConnectionMessage(type2, path, this.privRequestSession.requestId, contentType, payload));
    });
  }
  set activityTemplate(messagePayload) {
    this.privActivityTemplate = messagePayload;
  }
  get activityTemplate() {
    return this.privActivityTemplate;
  }
  sendTelemetryData() {
    return __awaiter18(this, void 0, void 0, function* () {
      const telemetryData = this.privRequestSession.getTelemetry();
      if (ServiceRecognizerBase.telemetryDataEnabled !== true || this.privIsDisposed || null === telemetryData) {
        return;
      }
      if (!!ServiceRecognizerBase.telemetryData) {
        try {
          ServiceRecognizerBase.telemetryData(telemetryData);
        } catch (_a) {
        }
      }
      const connection = yield this.fetchConnection();
      yield connection.send(new SpeechConnectionMessage(MessageType.Text, "telemetry", this.privRequestSession.requestId, "application/json", telemetryData));
    });
  }
  // Cancels recognition.
  cancelRecognitionLocal(cancellationReason, errorCode, error) {
    return __awaiter18(this, void 0, void 0, function* () {
      if (!!this.privRequestSession.isRecognizing) {
        yield this.privRequestSession.onStopRecognizing();
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);
      }
    });
  }
  receiveMessage() {
    return __awaiter18(this, void 0, void 0, function* () {
      try {
        if (this.privIsDisposed) {
          return;
        }
        let connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (this.receiveMessageOverride !== void 0) {
          return this.receiveMessageOverride();
        }
        if (!message) {
          if (!this.privRequestSession.isRecognizing) {
            return;
          } else {
            return this.receiveMessage();
          }
        }
        this.privServiceHasSentMessage = true;
        const connectionMessage = SpeechConnectionMessage.fromConnectionMessage(message);
        if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {
          switch (connectionMessage.path.toLowerCase()) {
            case "turn.start":
              this.privMustReportEndOfStream = true;
              this.privRequestSession.onServiceTurnStartResponse();
              break;
            case "speech.startdetected":
              const speechStartDetected = SpeechDetected.fromJSON(connectionMessage.textBody);
              const speechStartEventArgs = new RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);
              if (!!this.privRecognizer.speechStartDetected) {
                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
              }
              break;
            case "speech.enddetected":
              let json;
              if (connectionMessage.textBody.length > 0) {
                json = connectionMessage.textBody;
              } else {
                json = "{ Offset: 0 }";
              }
              const speechStopDetected = SpeechDetected.fromJSON(json);
              const speechStopEventArgs = new RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
              if (!!this.privRecognizer.speechEndDetected) {
                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
              }
              break;
            case "turn.end":
              yield this.sendTelemetryData();
              if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {
                this.privMustReportEndOfStream = false;
                yield this.cancelRecognitionLocal(CancellationReason.EndOfStream, CancellationErrorCode.NoError, void 0);
              }
              const sessionStopEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);
              yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);
              if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                if (!!this.privRecognizer.sessionStopped) {
                  this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                }
                return;
              } else {
                connection = yield this.fetchConnection();
                yield this.sendPrePayloadJSON(connection);
              }
              break;
            default:
              if (!(yield this.processTypeSpecificMessages(connectionMessage))) {
                if (!!this.privServiceEvents) {
                  this.serviceEvents.onEvent(new ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                }
              }
          }
        }
        return this.receiveMessage();
      } catch (error) {
        return null;
      }
    });
  }
  setSpeechSegmentationTimeout() {
    return;
  }
  sendSpeechContext(connection, generateNewRequestId) {
    const speechContextJson = this.speechContext.toJSON();
    if (generateNewRequestId) {
      this.privRequestSession.onSpeechContext();
    }
    if (speechContextJson) {
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speech.context", this.privRequestSession.requestId, "application/json", speechContextJson));
    }
    return;
  }
  noOp() {
    return;
  }
  // Encapsulated for derived service recognizers that need to send additional JSON
  sendPrePayloadJSON(connection, generateNewRequestId = true) {
    return __awaiter18(this, void 0, void 0, function* () {
      if (this.sendPrePayloadJSONOverride !== void 0) {
        return this.sendPrePayloadJSONOverride(connection);
      }
      yield this.sendSpeechContext(connection, generateNewRequestId);
      yield this.sendWaveHeader(connection);
      return;
    });
  }
  sendWaveHeader(connection) {
    return __awaiter18(this, void 0, void 0, function* () {
      const format = yield this.audioSource.format;
      return connection.send(new SpeechConnectionMessage(MessageType.Binary, "audio", this.privRequestSession.requestId, "audio/x-wav", format.header));
    });
  }
  // Establishes a websocket connection to the end point.
  connectImpl() {
    if (this.privConnectionPromise !== void 0) {
      return this.privConnectionPromise.then((connection) => {
        if (connection.state() === ConnectionState.Disconnected) {
          this.privConnectionId = null;
          this.privConnectionPromise = void 0;
          this.privServiceHasSentMessage = false;
          return this.connectImpl();
        }
        return this.privConnectionPromise;
      }, () => {
        this.privConnectionId = null;
        this.privConnectionPromise = void 0;
        this.privServiceHasSentMessage = false;
        return this.connectImpl();
      });
    }
    this.privConnectionPromise = this.retryableConnect();
    this.privConnectionPromise.catch(() => {
    });
    if (this.postConnectImplOverride !== void 0) {
      return this.postConnectImplOverride(this.privConnectionPromise);
    }
    return this.privConnectionPromise;
  }
  sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {
    requestSession.onSpeechContext();
    if (ServiceRecognizerBase.telemetryDataEnabled !== true) {
      const withTelemetry = JSON.parse(SpeechServiceConfigJson);
      const replacement = {
        context: {
          system: withTelemetry.context.system
        }
      };
      SpeechServiceConfigJson = JSON.stringify(replacement);
    }
    if (this.privRecognizerConfig.parameters.getProperty("f0f5debc-f8c9-4892-ac4b-90a7ab359fd2", "false").toLowerCase() === "true") {
      const json = JSON.parse(SpeechServiceConfigJson);
      json.context.DisableReferenceChannel = "True";
      json.context.MicSpec = "1_0_0";
      SpeechServiceConfigJson = JSON.stringify(json);
    }
    if (SpeechServiceConfigJson) {
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speech.config", requestSession.requestId, "application/json", SpeechServiceConfigJson));
    }
    return;
  }
  fetchConnection() {
    return __awaiter18(this, void 0, void 0, function* () {
      if (this.privConnectionConfigurationPromise !== void 0) {
        return this.privConnectionConfigurationPromise.then((connection) => {
          if (connection.state() === ConnectionState.Disconnected) {
            this.privConnectionId = null;
            this.privConnectionConfigurationPromise = void 0;
            this.privServiceHasSentMessage = false;
            return this.fetchConnection();
          }
          return this.privConnectionConfigurationPromise;
        }, () => {
          this.privConnectionId = null;
          this.privConnectionConfigurationPromise = void 0;
          this.privServiceHasSentMessage = false;
          return this.fetchConnection();
        });
      }
      this.privConnectionConfigurationPromise = this.configureConnection();
      return yield this.privConnectionConfigurationPromise;
    });
  }
  sendAudio(audioStreamNode) {
    return __awaiter18(this, void 0, void 0, function* () {
      const audioFormat = yield this.audioSource.format;
      let nextSendTime = Date.now();
      const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty("SPEECH-TransmitLengthBeforThrottleMs", "5000");
      const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1e3 * parseInt(fastLaneSizeMs, 10);
      const startRecogNumber = this.privRequestSession.recogNumber;
      const readAndUploadCycle = () => __awaiter18(this, void 0, void 0, function* () {
        if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {
          const connection = yield this.fetchConnection();
          const audioStreamChunk = yield audioStreamNode.read();
          if (this.privRequestSession.isSpeechEnded) {
            return;
          }
          let payload;
          let sendDelay;
          if (!audioStreamChunk || audioStreamChunk.isEnd) {
            payload = null;
            sendDelay = 0;
          } else {
            payload = audioStreamChunk.buffer;
            this.privRequestSession.onAudioSent(payload.byteLength);
            if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {
              sendDelay = 0;
            } else {
              sendDelay = Math.max(0, nextSendTime - Date.now());
            }
          }
          if (0 !== sendDelay) {
            yield this.delay(sendDelay);
          }
          if (payload !== null) {
            nextSendTime = Date.now() + payload.byteLength * 1e3 / (audioFormat.avgBytesPerSec * 2);
          }
          if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {
            connection.send(new SpeechConnectionMessage(MessageType.Binary, "audio", this.privRequestSession.requestId, null, payload)).catch(() => {
              this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => {
              });
            });
            if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {
              return readAndUploadCycle();
            } else {
              if (!this.privIsLiveAudio) {
                this.privRequestSession.onSpeechEnded();
              }
            }
          }
        }
      });
      return readAndUploadCycle();
    });
  }
  retryableConnect() {
    return __awaiter18(this, void 0, void 0, function* () {
      let isUnAuthorized = false;
      this.privAuthFetchEventId = createNoDashGuid();
      const sessionId = this.privRequestSession.sessionId;
      this.privConnectionId = sessionId !== void 0 ? sessionId : createNoDashGuid();
      this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);
      let lastStatusCode = 0;
      let lastReason = "";
      while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {
        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
        const auth = yield authPromise;
        yield this.privRequestSession.onAuthCompleted(false);
        const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);
        this.privRequestSession.listenForServiceTelemetry(connection.events);
        connection.events.attach((event) => {
          this.connectionEvents.onEvent(event);
        });
        const response = yield connection.open();
        if (response.statusCode === 200) {
          yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);
          return Promise.resolve(connection);
        } else if (response.statusCode === 1006) {
          isUnAuthorized = true;
        }
        lastStatusCode = response.statusCode;
        lastReason = response.reason;
        this.privRequestSession.onRetryConnection();
      }
      yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);
      return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);
    });
  }
  delay(delayMs) {
    return new Promise((resolve) => this.privSetTimeout(resolve, delayMs));
  }
  writeBufferToConsole(buffer) {
    let out = "Buffer Size: ";
    if (null === buffer) {
      out += "null";
    } else {
      const readView = new Uint8Array(buffer);
      out += `${buffer.byteLength}\r
`;
      for (let i = 0; i < buffer.byteLength; i++) {
        out += readView[i].toString(16).padStart(2, "0") + " ";
        if ((i + 1) % 16 === 0) {
          console.info(out);
          out = "";
        }
      }
    }
    console.info(out);
  }
  sendFinalAudio() {
    return __awaiter18(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      yield connection.send(new SpeechConnectionMessage(MessageType.Binary, "audio", this.privRequestSession.requestId, null, null));
      return;
    });
  }
  // Takes an established websocket connection to the endpoint and sends speech configuration information.
  configureConnection() {
    return __awaiter18(this, void 0, void 0, function* () {
      const connection = yield this.connectImpl();
      if (this.configConnectionOverride !== void 0) {
        return this.configConnectionOverride(connection);
      }
      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
      yield this.sendPrePayloadJSON(connection, false);
      return connection;
    });
  }
};
ServiceRecognizerBase.telemetryDataEnabled = true;

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConversationServiceRecognizer.js
var __awaiter19 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var ConversationServiceRecognizer = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.handleSpeechPhraseMessage = (textBody) => __awaiter19(this, void 0, void 0, function* () {
      return this.handleSpeechPhrase(textBody);
    });
    this.handleSpeechHypothesisMessage = (textBody) => this.handleSpeechHypothesis(textBody);
  }
  processTypeSpecificMessages(connectionMessage) {
    return;
  }
  handleRecognizedCallback(result, offset, sessionId) {
    return;
  }
  handleRecognizingCallback(result, duration, sessionId) {
    return;
  }
  processSpeechMessages(connectionMessage) {
    return __awaiter19(this, void 0, void 0, function* () {
      let processed = false;
      switch (connectionMessage.path.toLowerCase()) {
        case "speech.hypothesis":
        case "speech.fragment":
          if (!!this.handleSpeechHypothesisMessage) {
            this.handleSpeechHypothesisMessage(connectionMessage.textBody);
          }
          processed = true;
          break;
        case "speech.phrase":
          if (!!this.handleSpeechPhraseMessage) {
            yield this.handleSpeechPhraseMessage(connectionMessage.textBody);
          }
          processed = true;
          break;
        default:
          break;
      }
      return processed;
    });
  }
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
  }
  handleSpeechPhrase(textBody) {
    return __awaiter19(this, void 0, void 0, function* () {
      const simple = SimpleSpeechPhrase.fromJSON(textBody);
      const resultReason = EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
      let result;
      const resultProps = new PropertyCollection();
      resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, textBody);
      const simpleOffset = simple.Offset + this.privRequestSession.currentTurnAudioOffset;
      let offset = simpleOffset;
      this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
      if (ResultReason.Canceled === resultReason) {
        const cancelReason = EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
        const cancellationErrorCode = EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
      } else {
        if (!(this.privRequestSession.isSpeechEnded && resultReason === ResultReason.NoMatch && simple.RecognitionStatus !== RecognitionStatus.InitialSilenceTimeout)) {
          if (this.privRecognizerConfig.parameters.getProperty(OutputFormatPropertyName) === OutputFormat[OutputFormat.Simple]) {
            result = new SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simpleOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, void 0, textBody, resultProps);
          } else {
            const detailed = DetailedSpeechPhrase.fromJSON(textBody);
            const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
            const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
            result = new SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, void 0, offsetCorrectedJson, resultProps);
            offset = result.offset;
          }
          this.handleRecognizedCallback(result, offset, this.privRequestSession.sessionId);
        }
      }
    });
  }
  handleSpeechHypothesis(textBody) {
    const hypothesis = SpeechHypothesis.fromJSON(textBody);
    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
    const resultProps = new PropertyCollection();
    resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, textBody);
    const result = new SpeechRecognitionResult(this.privRequestSession.requestId, ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, void 0, textBody, resultProps);
    this.privRequestSession.onHypothesis(offset);
    this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js
var RecognitionMode;
(function(RecognitionMode2) {
  RecognitionMode2[RecognitionMode2["Interactive"] = 0] = "Interactive";
  RecognitionMode2[RecognitionMode2["Conversation"] = 1] = "Conversation";
  RecognitionMode2[RecognitionMode2["Dictation"] = 2] = "Dictation";
})(RecognitionMode || (RecognitionMode = {}));
var SpeechResultFormat;
(function(SpeechResultFormat2) {
  SpeechResultFormat2[SpeechResultFormat2["Simple"] = 0] = "Simple";
  SpeechResultFormat2[SpeechResultFormat2["Detailed"] = 1] = "Detailed";
})(SpeechResultFormat || (SpeechResultFormat = {}));
var RecognizerConfig = class {
  constructor(speechServiceConfig, parameters) {
    this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));
    this.privParameters = parameters;
    this.privMaxRetryCount = parseInt(parameters.getProperty("SPEECH-Error-MaxRetryCount", "4"), 10);
    this.privLanguageIdMode = parameters.getProperty(PropertyId.SpeechServiceConnection_LanguageIdMode, void 0);
  }
  get parameters() {
    return this.privParameters;
  }
  get recognitionMode() {
    return this.privRecognitionMode;
  }
  set recognitionMode(value) {
    this.privRecognitionMode = value;
    this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8e3 : 25e3;
    this.privSpeechServiceConfig.Recognition = RecognitionMode[value];
  }
  get SpeechServiceConfig() {
    return this.privSpeechServiceConfig;
  }
  get recognitionActivityTimeout() {
    return this.privRecognitionActivityTimeout;
  }
  get isContinuousRecognition() {
    return this.privRecognitionMode !== RecognitionMode.Interactive;
  }
  get languageIdMode() {
    return this.privLanguageIdMode;
  }
  get autoDetectSourceLanguages() {
    return this.parameters.getProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, void 0);
  }
  get recognitionEndpointVersion() {
    return this.parameters.getProperty(PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, void 0);
  }
  get sourceLanguageModels() {
    const models = [];
    let modelsExist = false;
    if (this.autoDetectSourceLanguages !== void 0) {
      for (const language of this.autoDetectSourceLanguages.split(",")) {
        const customProperty = language + PropertyId.SpeechServiceConnection_EndpointId.toString();
        const modelId = this.parameters.getProperty(customProperty, void 0);
        if (modelId !== void 0) {
          models.push({ language, endpoint: modelId });
          modelsExist = true;
        } else {
          models.push({ language, endpoint: "" });
        }
      }
    }
    return modelsExist ? models : void 0;
  }
  get maxRetryCount() {
    return this.privMaxRetryCount;
  }
};
var SpeechServiceConfig = class {
  constructor(context) {
    this.context = context;
  }
  serialize() {
    return JSON.stringify(this, (key, value) => {
      if (value && typeof value === "object") {
        const replacement = {};
        for (const k in value) {
          if (Object.hasOwnProperty.call(value, k)) {
            replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];
          }
        }
        return replacement;
      }
      return value;
    });
  }
  get Context() {
    return this.context;
  }
  get Recognition() {
    return this.recognition;
  }
  set Recognition(value) {
    this.recognition = value.toLowerCase();
  }
};
var Context = class {
  constructor(os) {
    this.system = new System();
    this.os = os;
  }
};
var System = class {
  constructor() {
    const SPEECHSDK_CLIENTSDK_VERSION = "1.28.0";
    this.name = "SpeechSDK";
    this.version = SPEECHSDK_CLIENTSDK_VERSION;
    this.build = "JavaScript";
    this.lang = "JavaScript";
  }
};
var OS = class {
  constructor(platform, name, version) {
    this.platform = platform;
    this.name = name;
    this.version = version;
  }
};
var connectivity;
(function(connectivity2) {
  connectivity2["Bluetooth"] = "Bluetooth";
  connectivity2["Wired"] = "Wired";
  connectivity2["WiFi"] = "WiFi";
  connectivity2["Cellular"] = "Cellular";
  connectivity2["InBuilt"] = "InBuilt";
  connectivity2["Unknown"] = "Unknown";
})(connectivity || (connectivity = {}));
var type;
(function(type2) {
  type2["Phone"] = "Phone";
  type2["Speaker"] = "Speaker";
  type2["Car"] = "Car";
  type2["Headset"] = "Headset";
  type2["Thermostat"] = "Thermostat";
  type2["Microphones"] = "Microphones";
  type2["Deskphone"] = "Deskphone";
  type2["RemoteControl"] = "RemoteControl";
  type2["Unknown"] = "Unknown";
  type2["File"] = "File";
  type2["Stream"] = "Stream";
})(type || (type = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js
var CRLF = "\r\n";
var WebsocketMessageFormatter = class {
  toConnectionMessage(message) {
    const deferral = new Deferred();
    try {
      if (message.messageType === MessageType.Text) {
        const textMessage = message.textContent;
        let headers = {};
        let body = null;
        if (textMessage) {
          const headerBodySplit = textMessage.split("\r\n\r\n");
          if (headerBodySplit && headerBodySplit.length > 0) {
            headers = this.parseHeaders(headerBodySplit[0]);
            if (headerBodySplit.length > 1) {
              body = headerBodySplit[1];
            }
          }
        }
        deferral.resolve(new ConnectionMessage(message.messageType, body, headers, message.id));
      } else if (message.messageType === MessageType.Binary) {
        const binaryMessage = message.binaryContent;
        let headers = {};
        let body = null;
        if (!binaryMessage || binaryMessage.byteLength < 2) {
          throw new Error("Invalid binary message format. Header length missing.");
        }
        const dataView = new DataView(binaryMessage);
        const headerLength = dataView.getInt16(0);
        if (binaryMessage.byteLength < headerLength + 2) {
          throw new Error("Invalid binary message format. Header content missing.");
        }
        let headersString = "";
        for (let i = 0; i < headerLength; i++) {
          headersString += String.fromCharCode(dataView.getInt8(i + 2));
        }
        headers = this.parseHeaders(headersString);
        if (binaryMessage.byteLength > headerLength + 2) {
          body = binaryMessage.slice(2 + headerLength);
        }
        deferral.resolve(new ConnectionMessage(message.messageType, body, headers, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. Error: ${e}`);
    }
    return deferral.promise;
  }
  fromConnectionMessage(message) {
    const deferral = new Deferred();
    try {
      if (message.messageType === MessageType.Text) {
        const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : ""}`;
        deferral.resolve(new RawWebsocketMessage(MessageType.Text, payload, message.id));
      } else if (message.messageType === MessageType.Binary) {
        const headersString = this.makeHeaders(message);
        const content = message.binaryBody;
        const headerBuffer = this.stringToArrayBuffer(headersString);
        const headerInt8Array = new Int8Array(headerBuffer);
        const headerLength = headerInt8Array.byteLength;
        const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));
        payloadInt8Array[0] = headerLength >> 8 & 255;
        payloadInt8Array[1] = headerLength & 255;
        payloadInt8Array.set(headerInt8Array, 2);
        if (content) {
          const bodyInt8Array = new Int8Array(content);
          payloadInt8Array.set(bodyInt8Array, 2 + headerLength);
        }
        const payload = payloadInt8Array.buffer;
        deferral.resolve(new RawWebsocketMessage(MessageType.Binary, payload, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. ${e}`);
    }
    return deferral.promise;
  }
  makeHeaders(message) {
    let headersString = "";
    if (message.headers) {
      for (const header in message.headers) {
        if (header) {
          headersString += `${header}: ${message.headers[header]}${CRLF}`;
        }
      }
    }
    return headersString;
  }
  parseHeaders(headersString) {
    const headers = {};
    if (headersString) {
      const headerMatches = headersString.match(/[^\r\n]+/g);
      if (headers) {
        for (const header of headerMatches) {
          if (header) {
            const separatorIndex = header.indexOf(":");
            const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;
            const headerValue = separatorIndex > 0 && header.length > separatorIndex + 1 ? header.substr(separatorIndex + 1).trim() : "";
            headers[headerName] = headerValue;
          }
        }
      }
    }
    return headers;
  }
  stringToArrayBuffer(str) {
    const buffer = new ArrayBuffer(str.length);
    const view = new DataView(buffer);
    for (let i = 0; i < str.length; i++) {
      view.setUint8(i, str.charCodeAt(i));
    }
    return buffer;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js
var SpeechConnectionFactory = class extends ConnectionFactoryBase {
  constructor() {
    super(...arguments);
    this.interactiveRelativeUri = "/speech/recognition/interactive/cognitiveservices/v1";
    this.conversationRelativeUri = "/speech/recognition/conversation/cognitiveservices/v1";
    this.dictationRelativeUri = "/speech/recognition/dictation/cognitiveservices/v1";
    this.universalUri = "/speech/universal/v";
  }
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, void 0);
    const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region, void 0);
    const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
    const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, "wss://" + region + ".stt.speech" + hostSuffix);
    const queryParams = {};
    const endpointId = config.parameters.getProperty(PropertyId.SpeechServiceConnection_EndpointId, void 0);
    const language = config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, void 0);
    if (endpointId) {
      if (!endpoint || endpoint.search(QueryParameterNames.CustomSpeechDeploymentId) === -1) {
        queryParams[QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
      }
    } else if (language) {
      if (!endpoint || endpoint.search(QueryParameterNames.Language) === -1) {
        queryParams[QueryParameterNames.Language] = language;
      }
    }
    if (!endpoint || endpoint.search(QueryParameterNames.Format) === -1) {
      queryParams[QueryParameterNames.Format] = config.parameters.getProperty(OutputFormatPropertyName, OutputFormat[OutputFormat.Simple]).toLowerCase();
    }
    if (config.autoDetectSourceLanguages !== void 0) {
      queryParams[QueryParameterNames.EnableLanguageId] = "true";
    }
    this.setCommonUrlParams(config, queryParams, endpoint);
    if (!endpoint) {
      switch (config.recognitionMode) {
        case RecognitionMode.Conversation:
          if (config.parameters.getProperty(ForceDictationPropertyName, "false") === "true") {
            endpoint = host + this.dictationRelativeUri;
          } else {
            if (config.recognitionEndpointVersion !== void 0 && parseInt(config.recognitionEndpointVersion, 10) > 1) {
              endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;
            } else {
              endpoint = host + this.conversationRelativeUri;
            }
          }
          break;
        case RecognitionMode.Dictation:
          endpoint = host + this.dictationRelativeUri;
          break;
        default:
          if (config.recognitionEndpointVersion !== void 0 && parseInt(config.recognitionEndpointVersion, 10) > 1) {
            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;
          } else {
            endpoint = host + this.interactiveRelativeUri;
          }
          break;
      }
    }
    const headers = {};
    if (authInfo.token !== void 0 && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    const webSocketConnection = new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
    const uri = webSocketConnection.uri;
    config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, uri);
    return webSocketConnection;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js
var TranscriberConnectionFactory = class extends ConnectionFactoryBase {
  constructor() {
    super(...arguments);
    this.multiaudioRelativeUri = "/speech/recognition/multiaudio";
  }
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, void 0);
    const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region, "centralus");
    const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
    const hostDefault = "wss://transcribe." + region + ".cts.speech" + hostSuffix + this.multiaudioRelativeUri;
    const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, hostDefault);
    const queryParams = {};
    this.setQueryParams(queryParams, config, endpoint);
    if (!endpoint) {
      endpoint = host;
    }
    const headers = {};
    if (authInfo.token !== void 0 && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  setQueryParams(queryParams, config, endpointUrl) {
    const endpointId = config.parameters.getProperty(PropertyId.SpeechServiceConnection_EndpointId, void 0);
    const language = config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, void 0);
    if (endpointId && !(QueryParameterNames.CustomSpeechDeploymentId in queryParams)) {
      queryParams[QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
    }
    if (language && !(QueryParameterNames.Language in queryParams)) {
      queryParams[QueryParameterNames.Language] = language;
    }
    const wordLevelTimings = config.parameters.getProperty(PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "false").toLowerCase() === "true";
    const detailed = config.parameters.getProperty(OutputFormatPropertyName, OutputFormat[OutputFormat.Simple]) !== OutputFormat[OutputFormat.Simple];
    if (wordLevelTimings || detailed) {
      queryParams[QueryParameterNames.Format] = OutputFormat[OutputFormat.Detailed].toLowerCase();
    }
    this.setCommonUrlParams(config, queryParams, endpointUrl);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js
var TranslationConnectionFactory = class extends ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    const endpoint = this.getEndpointUrl(config);
    const queryParams = {};
    this.setQueryParams(queryParams, config, endpoint);
    const headers = {};
    if (authInfo.token !== void 0 && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
  getEndpointUrl(config, returnRegionPlaceholder) {
    const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region);
    const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
    let endpointUrl = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, void 0);
    if (!endpointUrl) {
      const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, "wss://{region}.s2s.speech" + hostSuffix);
      endpointUrl = host + "/speech/translation/cognitiveservices/v1";
    }
    if (returnRegionPlaceholder === true) {
      return endpointUrl;
    }
    return StringUtils.formatString(endpointUrl, { region });
  }
  setQueryParams(queryParams, config, endpointUrl) {
    queryParams.from = config.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
    queryParams.to = config.parameters.getProperty(PropertyId.SpeechServiceConnection_TranslationToLanguages);
    this.setCommonUrlParams(config, queryParams, endpointUrl);
    this.setUrlParameter(PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult, QueryParameterNames.StableTranslation, config, queryParams, endpointUrl);
    const translationVoice = config.parameters.getProperty(PropertyId.SpeechServiceConnection_TranslationVoice, void 0);
    if (translationVoice !== void 0) {
      queryParams.voice = translationVoice;
      queryParams.features = "texttospeech";
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js
var SpeechSynthesisConnectionFactory = class {
  constructor() {
    this.synthesisUri = "/cognitiveservices/websocket/v1";
  }
  create(config, authInfo, connectionId) {
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, void 0);
    const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region, void 0);
    const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
    const endpointId = config.parameters.getProperty(PropertyId.SpeechServiceConnection_EndpointId, void 0);
    const hostPrefix = endpointId === void 0 ? "tts" : "voice";
    const host = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, "wss://" + region + "." + hostPrefix + ".speech" + hostSuffix);
    const queryParams = {};
    if (!endpoint) {
      endpoint = host + this.synthesisUri;
    }
    const headers = {};
    if (authInfo.token !== void 0 && authInfo.token !== "") {
      headers[authInfo.headerName] = authInfo.token;
    }
    headers[HeaderNames.ConnectionId] = connectionId;
    if (endpointId !== void 0) {
      headers[QueryParameterNames.CustomVoiceDeploymentId] = endpointId;
    }
    config.parameters.setProperty(PropertyId.SpeechServiceConnection_Url, endpoint);
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, headers, new WebsocketMessageFormatter(), ProxyInfo.fromParameters(config.parameters), enableCompression, connectionId);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js
var EnumTranslation = class {
  static implTranslateRecognitionResult(recognitionStatus) {
    let reason = ResultReason.Canceled;
    switch (recognitionStatus) {
      case RecognitionStatus.Success:
        reason = ResultReason.RecognizedSpeech;
        break;
      case RecognitionStatus.NoMatch:
      case RecognitionStatus.InitialSilenceTimeout:
      case RecognitionStatus.BabbleTimeout:
      case RecognitionStatus.EndOfDictation:
        reason = ResultReason.NoMatch;
        break;
      case RecognitionStatus.Error:
      case RecognitionStatus.BadRequest:
      case RecognitionStatus.Forbidden:
      default:
        reason = ResultReason.Canceled;
        break;
    }
    return reason;
  }
  static implTranslateCancelResult(recognitionStatus) {
    let reason = CancellationReason.EndOfStream;
    switch (recognitionStatus) {
      case RecognitionStatus.Success:
      case RecognitionStatus.EndOfDictation:
      case RecognitionStatus.NoMatch:
        reason = CancellationReason.EndOfStream;
        break;
      case RecognitionStatus.InitialSilenceTimeout:
      case RecognitionStatus.BabbleTimeout:
      case RecognitionStatus.Error:
      case RecognitionStatus.BadRequest:
      case RecognitionStatus.Forbidden:
      default:
        reason = CancellationReason.Error;
        break;
    }
    return reason;
  }
  static implTranslateCancelErrorCode(recognitionStatus) {
    let reason = CancellationErrorCode.NoError;
    switch (recognitionStatus) {
      case RecognitionStatus.Error:
        reason = CancellationErrorCode.ServiceError;
        break;
      case RecognitionStatus.TooManyRequests:
        reason = CancellationErrorCode.TooManyRequests;
        break;
      case RecognitionStatus.BadRequest:
        reason = CancellationErrorCode.BadRequestParameters;
        break;
      case RecognitionStatus.Forbidden:
        reason = CancellationErrorCode.Forbidden;
        break;
      default:
        reason = CancellationErrorCode.NoError;
        break;
    }
    return reason;
  }
  static implTranslateErrorDetails(cancellationErrorCode) {
    let errorDetails = "The speech service encountered an internal error and could not continue.";
    switch (cancellationErrorCode) {
      case CancellationErrorCode.Forbidden:
        errorDetails = "The recognizer is using a free subscription that ran out of quota.";
        break;
      case CancellationErrorCode.BadRequestParameters:
        errorDetails = "Invalid parameter or unsupported audio format in the request.";
        break;
      case CancellationErrorCode.TooManyRequests:
        errorDetails = "The number of parallel requests exceeded the number of allowed concurrent transcriptions.";
        break;
      default:
        break;
    }
    return errorDetails;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js
var SynthesisStatus;
(function(SynthesisStatus2) {
  SynthesisStatus2[SynthesisStatus2["Success"] = 0] = "Success";
  SynthesisStatus2[SynthesisStatus2["SynthesisEnd"] = 1] = "SynthesisEnd";
  SynthesisStatus2[SynthesisStatus2["Error"] = 2] = "Error";
})(SynthesisStatus || (SynthesisStatus = {}));
var RecognitionStatus;
(function(RecognitionStatus2) {
  RecognitionStatus2[RecognitionStatus2["Success"] = 0] = "Success";
  RecognitionStatus2[RecognitionStatus2["NoMatch"] = 1] = "NoMatch";
  RecognitionStatus2[RecognitionStatus2["InitialSilenceTimeout"] = 2] = "InitialSilenceTimeout";
  RecognitionStatus2[RecognitionStatus2["BabbleTimeout"] = 3] = "BabbleTimeout";
  RecognitionStatus2[RecognitionStatus2["Error"] = 4] = "Error";
  RecognitionStatus2[RecognitionStatus2["EndOfDictation"] = 5] = "EndOfDictation";
  RecognitionStatus2[RecognitionStatus2["TooManyRequests"] = 6] = "TooManyRequests";
  RecognitionStatus2[RecognitionStatus2["BadRequest"] = 7] = "BadRequest";
  RecognitionStatus2[RecognitionStatus2["Forbidden"] = 8] = "Forbidden";
})(RecognitionStatus || (RecognitionStatus = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js
var TranslationSynthesisEnd = class {
  constructor(json) {
    this.privSynthesisEnd = JSON.parse(json);
    if (!!this.privSynthesisEnd.SynthesisStatus) {
      this.privSynthesisEnd.SynthesisStatus = SynthesisStatus[this.privSynthesisEnd.SynthesisStatus];
    }
    if (!!this.privSynthesisEnd.Status) {
      this.privSynthesisEnd.SynthesisStatus = SynthesisStatus[this.privSynthesisEnd.Status];
    }
  }
  static fromJSON(json) {
    return new TranslationSynthesisEnd(json);
  }
  get SynthesisStatus() {
    return this.privSynthesisEnd.SynthesisStatus;
  }
  get FailureReason() {
    return this.privSynthesisEnd.FailureReason;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js
var TranslationHypothesis = class {
  constructor(json) {
    this.privTranslationHypothesis = JSON.parse(json);
    this.privTranslationHypothesis.Translation.TranslationStatus = TranslationStatus[this.privTranslationHypothesis.Translation.TranslationStatus];
  }
  static fromJSON(json) {
    return new TranslationHypothesis(json);
  }
  get Duration() {
    return this.privTranslationHypothesis.Duration;
  }
  get Offset() {
    return this.privTranslationHypothesis.Offset;
  }
  get Text() {
    return this.privTranslationHypothesis.Text;
  }
  get Translation() {
    return this.privTranslationHypothesis.Translation;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js
var TranslationPhrase = class {
  constructor(phrase) {
    this.privTranslationPhrase = phrase;
    this.privTranslationPhrase.RecognitionStatus = RecognitionStatus[this.privTranslationPhrase.RecognitionStatus];
    if (this.privTranslationPhrase.Translation !== void 0) {
      this.privTranslationPhrase.Translation.TranslationStatus = TranslationStatus[this.privTranslationPhrase.Translation.TranslationStatus];
    }
  }
  static fromJSON(json) {
    return new TranslationPhrase(JSON.parse(json));
  }
  static fromTranslationResponse(translationResponse) {
    Contracts.throwIfNullOrUndefined(translationResponse, "translationResponse");
    const phrase = translationResponse.SpeechPhrase;
    translationResponse.SpeechPhrase = void 0;
    phrase.Translation = translationResponse;
    phrase.Text = phrase.DisplayText;
    return new TranslationPhrase(phrase);
  }
  get RecognitionStatus() {
    return this.privTranslationPhrase.RecognitionStatus;
  }
  get Offset() {
    return this.privTranslationPhrase.Offset;
  }
  get Duration() {
    return this.privTranslationPhrase.Duration;
  }
  get Text() {
    return this.privTranslationPhrase.Text;
  }
  get Translation() {
    return this.privTranslationPhrase.Translation;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js
var __awaiter20 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var TranslationServiceRecognizer = class extends ConversationServiceRecognizer {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);
    this.privTranslationRecognizer = translationRecognizer;
    this.connectionEvents.attach((connectionEvent) => {
      if (connectionEvent.name === "ConnectionEstablishedEvent") {
        this.privTranslationRecognizer.onConnection();
      } else if (connectionEvent.name === "ConnectionClosedEvent") {
        void this.privTranslationRecognizer.onDisconnection();
      }
    });
  }
  processTypeSpecificMessages(connectionMessage) {
    return __awaiter20(this, void 0, void 0, function* () {
      const resultProps = new PropertyCollection();
      let processed = yield this.processSpeechMessages(connectionMessage);
      if (processed) {
        return true;
      }
      const handleTranslationPhrase = (translatedPhrase) => __awaiter20(this, void 0, void 0, function* () {
        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset + translatedPhrase.Duration);
        if (translatedPhrase.RecognitionStatus === RecognitionStatus.Success) {
          const result = this.fireEventForResult(translatedPhrase, resultProps);
          if (!!this.privTranslationRecognizer.recognized) {
            try {
              this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);
            } catch (error) {
            }
          }
          if (!!this.privSuccessCallback) {
            try {
              this.privSuccessCallback(result.result);
            } catch (e) {
              if (!!this.privErrorCallback) {
                this.privErrorCallback(e);
              }
            }
            this.privSuccessCallback = void 0;
            this.privErrorCallback = void 0;
          }
        } else {
          const reason = EnumTranslation.implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);
          const result = new TranslationRecognitionResult(void 0, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset, void 0, connectionMessage.textBody, resultProps);
          if (reason === ResultReason.Canceled) {
            const cancelReason = EnumTranslation.implTranslateCancelResult(translatedPhrase.RecognitionStatus);
            const cancellationErrorCode = EnumTranslation.implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);
            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
          } else {
            if (!(this.privRequestSession.isSpeechEnded && reason === ResultReason.NoMatch && translatedPhrase.RecognitionStatus !== RecognitionStatus.InitialSilenceTimeout)) {
              const ev = new TranslationRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
              if (!!this.privTranslationRecognizer.recognized) {
                try {
                  this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
                } catch (error) {
                }
              }
            }
            if (!!this.privSuccessCallback) {
              try {
                this.privSuccessCallback(result);
              } catch (e) {
                if (!!this.privErrorCallback) {
                  this.privErrorCallback(e);
                }
              }
              this.privSuccessCallback = void 0;
              this.privErrorCallback = void 0;
            }
          }
          processed = true;
        }
      });
      if (connectionMessage.messageType === MessageType.Text) {
        resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
      }
      switch (connectionMessage.path.toLowerCase()) {
        case "translation.hypothesis":
          const result = this.fireEventForResult(TranslationHypothesis.fromJSON(connectionMessage.textBody), resultProps);
          this.privRequestSession.onHypothesis(this.privRequestSession.currentTurnAudioOffset + result.offset);
          if (!!this.privTranslationRecognizer.recognizing) {
            try {
              this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);
            } catch (error) {
            }
          }
          processed = true;
          break;
        case "translation.response":
          const phrase = JSON.parse(connectionMessage.textBody);
          if (!!phrase.SpeechPhrase) {
            yield handleTranslationPhrase(TranslationPhrase.fromTranslationResponse(phrase));
          }
          break;
        case "translation.phrase":
          yield handleTranslationPhrase(TranslationPhrase.fromJSON(connectionMessage.textBody));
          break;
        case "translation.synthesis":
          this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);
          processed = true;
          break;
        case "audio.end":
        case "translation.synthesis.end":
          const synthEnd = TranslationSynthesisEnd.fromJSON(connectionMessage.textBody);
          switch (synthEnd.SynthesisStatus) {
            case SynthesisStatus.Error:
              if (!!this.privTranslationRecognizer.synthesizing) {
                const result2 = new TranslationSynthesisResult(ResultReason.Canceled, void 0);
                const retEvent = new TranslationSynthesisEventArgs(result2, this.privRequestSession.sessionId);
                try {
                  this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
                } catch (error) {
                }
              }
              if (!!this.privTranslationRecognizer.canceled) {
                const canceledResult = new TranslationRecognitionCanceledEventArgs(this.privRequestSession.sessionId, CancellationReason.Error, synthEnd.FailureReason, CancellationErrorCode.ServiceError, null);
                try {
                  this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);
                } catch (error) {
                }
              }
              break;
            case SynthesisStatus.Success:
              this.sendSynthesisAudio(void 0, this.privRequestSession.sessionId);
              break;
            default:
              break;
          }
          processed = true;
          break;
        default:
          break;
      }
      return processed;
    });
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    if (!!this.privTranslationRecognizer.canceled) {
      const cancelEvent = new TranslationRecognitionCanceledEventArgs(sessionId, cancellationReason, error, errorCode, void 0);
      try {
        this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);
      } catch (_a) {
      }
    }
    if (!!this.privSuccessCallback) {
      const result = new TranslationRecognitionResult(
        void 0,
        // Translations
        requestId,
        ResultReason.Canceled,
        void 0,
        // Text
        void 0,
        // Druation
        void 0,
        // Offset
        error,
        void 0,
        // Json
        properties
      );
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = void 0;
      } catch (_b) {
      }
    }
  }
  handleRecognizingCallback(result, duration, sessionId) {
    try {
      const ev = new TranslationRecognitionEventArgs(TranslationRecognitionResult.fromSpeechRecognitionResult(result), duration, sessionId);
      this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, ev);
    } catch (error) {
    }
  }
  handleRecognizedCallback(result, offset, sessionId) {
    try {
      const ev = new TranslationRecognitionEventArgs(TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);
      this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
    } catch (error) {
    }
  }
  fireEventForResult(serviceResult, properties) {
    let translations;
    if (void 0 !== serviceResult.Translation.Translations) {
      translations = new Translations();
      for (const translation of serviceResult.Translation.Translations) {
        translations.set(translation.Language, translation.Text || translation.DisplayText);
      }
    }
    let resultReason;
    if (serviceResult instanceof TranslationPhrase) {
      if (!!serviceResult.Translation && serviceResult.Translation.TranslationStatus === TranslationStatus.Success) {
        resultReason = ResultReason.TranslatedSpeech;
      } else {
        resultReason = ResultReason.RecognizedSpeech;
      }
    } else {
      resultReason = ResultReason.TranslatingSpeech;
    }
    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;
    const result = new TranslationRecognitionResult(translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, offset, serviceResult.Translation.FailureReason, JSON.stringify(serviceResult), properties);
    const ev = new TranslationRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);
    return ev;
  }
  sendSynthesisAudio(audio, sessionId) {
    const reason = void 0 === audio ? ResultReason.SynthesizingAudioCompleted : ResultReason.SynthesizingAudio;
    const result = new TranslationSynthesisResult(reason, audio);
    const retEvent = new TranslationSynthesisEventArgs(result, sessionId);
    if (!!this.privTranslationRecognizer.synthesizing) {
      try {
        this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
      } catch (error) {
      }
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js
var SpeechDetected = class {
  constructor(json) {
    this.privSpeechStartDetected = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SpeechDetected(json);
  }
  get Offset() {
    return this.privSpeechStartDetected.Offset;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js
var SpeechHypothesis = class {
  constructor(json) {
    this.privSpeechHypothesis = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SpeechHypothesis(json);
  }
  get Text() {
    return this.privSpeechHypothesis.Text;
  }
  get Offset() {
    return this.privSpeechHypothesis.Offset;
  }
  get Duration() {
    return this.privSpeechHypothesis.Duration;
  }
  get Language() {
    return this.privSpeechHypothesis.PrimaryLanguage === void 0 ? void 0 : this.privSpeechHypothesis.PrimaryLanguage.Language;
  }
  get LanguageDetectionConfidence() {
    return this.privSpeechHypothesis.PrimaryLanguage === void 0 ? void 0 : this.privSpeechHypothesis.PrimaryLanguage.Confidence;
  }
  get SpeakerId() {
    return this.privSpeechHypothesis.SpeakerId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js
var SpeechKeyword = class {
  constructor(json) {
    this.privSpeechKeyword = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SpeechKeyword(json);
  }
  get Status() {
    return this.privSpeechKeyword.Status;
  }
  get Text() {
    return this.privSpeechKeyword.Text;
  }
  get Offset() {
    return this.privSpeechKeyword.Offset;
  }
  get Duration() {
    return this.privSpeechKeyword.Duration;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js
var __awaiter21 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SpeechServiceRecognizer = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);
    this.privSpeechRecognizer = speechRecognizer;
    const phraseDetection = {};
    if (recognizerConfig.autoDetectSourceLanguages !== void 0) {
      const sourceLanguages = recognizerConfig.autoDetectSourceLanguages.split(",");
      let speechContextLidMode;
      if (recognizerConfig.languageIdMode === "Continuous") {
        speechContextLidMode = "DetectContinuous";
      } else {
        speechContextLidMode = "DetectAtAudioStart";
      }
      this.privSpeechContext.setSection("languageId", {
        Priority: "PrioritizeLatency",
        languages: sourceLanguages,
        mode: speechContextLidMode,
        onSuccess: { action: "Recognize" },
        onUnknown: { action: "None" }
      });
      this.privSpeechContext.setSection("phraseOutput", {
        interimResults: {
          resultType: "Auto"
        },
        phraseResults: {
          resultType: "Always"
        }
      });
      const customModels = recognizerConfig.sourceLanguageModels;
      if (customModels !== void 0) {
        phraseDetection.customModels = customModels;
        phraseDetection.onInterim = { action: "None" };
        phraseDetection.onSuccess = { action: "None" };
      }
    }
    const isEmpty = (obj) => {
      for (const x in obj) {
        return false;
      }
      return true;
    };
    if (!isEmpty(phraseDetection)) {
      this.privSpeechContext.setSection("phraseDetection", phraseDetection);
    }
  }
  setSpeechSegmentationTimeout() {
    const speechSegmentationTimeout = this.privRecognizerConfig.parameters.getProperty(PropertyId.Speech_SegmentationSilenceTimeoutMs, void 0);
    if (speechSegmentationTimeout !== void 0) {
      const mode = this.recognitionMode === RecognitionMode.Conversation ? "CONVERSATION" : this.recognitionMode === RecognitionMode.Dictation ? "DICTATION" : "INTERACTIVE";
      const segmentationSilenceTimeoutMs = parseInt(speechSegmentationTimeout, 10);
      const phraseDetection = this.privSpeechContext.getSection("phraseDetection");
      phraseDetection.mode = mode;
      phraseDetection[mode] = {
        segmentation: {
          mode: "Custom",
          segmentationSilenceTimeoutMs
        }
      };
      this.privSpeechContext.setSection("phraseDetection", phraseDetection);
    }
  }
  processTypeSpecificMessages(connectionMessage) {
    return __awaiter21(this, void 0, void 0, function* () {
      let result;
      const resultProps = new PropertyCollection();
      resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
      let processed = false;
      switch (connectionMessage.path.toLowerCase()) {
        case "speech.hypothesis":
        case "speech.fragment":
          const hypothesis = SpeechHypothesis.fromJSON(connectionMessage.textBody);
          const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
          result = new SpeechRecognitionResult(
            this.privRequestSession.requestId,
            ResultReason.RecognizingSpeech,
            hypothesis.Text,
            hypothesis.Duration,
            offset,
            hypothesis.Language,
            hypothesis.LanguageDetectionConfidence,
            void 0,
            // Speaker Id
            void 0,
            connectionMessage.textBody,
            resultProps
          );
          this.privRequestSession.onHypothesis(offset);
          const ev = new SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);
          if (!!this.privSpeechRecognizer.recognizing) {
            try {
              this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);
            } catch (error) {
            }
          }
          processed = true;
          break;
        case "speech.phrase":
          const simple = SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);
          const resultReason = EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
          this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);
          if (ResultReason.Canceled === resultReason) {
            const cancelReason = EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
            const cancellationErrorCode = EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
          } else {
            if (!(this.privRequestSession.isSpeechEnded && resultReason === ResultReason.NoMatch && simple.RecognitionStatus !== RecognitionStatus.InitialSilenceTimeout)) {
              if (this.privRecognizerConfig.parameters.getProperty(OutputFormatPropertyName) === OutputFormat[OutputFormat.Simple]) {
                result = new SpeechRecognitionResult(
                  this.privRequestSession.requestId,
                  resultReason,
                  simple.DisplayText,
                  simple.Duration,
                  simple.Offset + this.privRequestSession.currentTurnAudioOffset,
                  simple.Language,
                  simple.LanguageDetectionConfidence,
                  void 0,
                  // Speaker Id
                  void 0,
                  connectionMessage.textBody,
                  resultProps
                );
              } else {
                const detailed = DetailedSpeechPhrase.fromJSON(connectionMessage.textBody);
                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;
                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);
                result = new SpeechRecognitionResult(
                  this.privRequestSession.requestId,
                  resultReason,
                  detailed.RecognitionStatus === RecognitionStatus.Success ? detailed.NBest[0].Display : void 0,
                  detailed.Duration,
                  totalOffset,
                  detailed.Language,
                  detailed.LanguageDetectionConfidence,
                  void 0,
                  // Speaker Id
                  void 0,
                  offsetCorrectedJson,
                  resultProps
                );
              }
              const event = new SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
              if (!!this.privSpeechRecognizer.recognized) {
                try {
                  this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);
                } catch (error) {
                }
              }
            }
            if (!!this.privSuccessCallback) {
              try {
                this.privSuccessCallback(result);
              } catch (e) {
                if (!!this.privErrorCallback) {
                  this.privErrorCallback(e);
                }
              }
              this.privSuccessCallback = void 0;
              this.privErrorCallback = void 0;
            }
          }
          processed = true;
          break;
        default:
          break;
      }
      return processed;
    });
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    if (!!this.privSpeechRecognizer.canceled) {
      const cancelEvent = new SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, void 0, sessionId);
      try {
        this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);
      } catch (_a) {
      }
    }
    if (!!this.privSuccessCallback) {
      const result = new SpeechRecognitionResult(
        requestId,
        ResultReason.Canceled,
        void 0,
        // Text
        void 0,
        // Duration
        void 0,
        // Offset
        void 0,
        // Language
        void 0,
        // Language Detection Confidence
        void 0,
        // Speaker Id
        error,
        void 0,
        // Json
        properties
      );
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = void 0;
      } catch (_b) {
      }
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js
var __awaiter22 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var TranscriptionServiceRecognizer = class extends ConversationServiceRecognizer {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);
    this.privTranscriberRecognizer = transcriber;
    this.sendPrePayloadJSONOverride = (connection) => this.sendTranscriptionStartJSON(connection);
    if (this.privRecognizerConfig.parameters.getProperty(PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps) === "true") {
      this.privSpeechContext.setWordLevelTimings();
    }
  }
  sendSpeechEventAsync(info, command) {
    return __awaiter22(this, void 0, void 0, function* () {
      if (!!this.privRequestSession.isRecognizing) {
        const connection = yield this.fetchConnection();
        yield this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));
      }
    });
  }
  processTypeSpecificMessages(connectionMessage) {
    return this.processSpeechMessages(connectionMessage);
  }
  handleRecognizedCallback(result, offset, sessionId) {
    try {
      const event = new SpeechRecognitionEventArgs(result, offset, sessionId);
      this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);
      if (!!this.privSuccessCallback) {
        try {
          this.privSuccessCallback(result);
        } catch (e) {
          if (!!this.privErrorCallback) {
            this.privErrorCallback(e);
          }
        }
        this.privSuccessCallback = void 0;
        this.privErrorCallback = void 0;
      }
    } catch (error) {
    }
  }
  handleRecognizingCallback(result, duration, sessionId) {
    try {
      const ev = new SpeechRecognitionEventArgs(result, duration, sessionId);
      this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);
    } catch (error) {
    }
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    if (!!this.privTranscriberRecognizer.canceled) {
      const cancelEvent = new ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, void 0, sessionId);
      try {
        this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);
      } catch (_a) {
      }
    }
    if (!!this.privSuccessCallback) {
      const result = new SpeechRecognitionResult(
        requestId,
        ResultReason.Canceled,
        void 0,
        // Text
        void 0,
        // Duration
        void 0,
        // Offset
        void 0,
        // Language
        void 0,
        // Language Detection Confidence
        void 0,
        // Speaker Id
        error,
        void 0,
        // Json
        properties
      );
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = void 0;
      } catch (_b) {
      }
    }
  }
  // Encapsulated for derived service recognizers that need to send additional JSON
  sendTranscriptionStartJSON(connection) {
    return __awaiter22(this, void 0, void 0, function* () {
      yield this.sendSpeechContext(connection, true);
      const info = this.privTranscriberRecognizer.getConversationInfo();
      const payload = this.createSpeechEventPayload(info, "start");
      yield this.sendSpeechEvent(connection, payload);
      yield this.sendWaveHeader(connection);
      return;
    });
  }
  sendSpeechEvent(connection, payload) {
    const speechEventJson = JSON.stringify(payload);
    if (speechEventJson) {
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speech.event", this.privRequestSession.requestId, "application/json", speechEventJson));
    }
    return;
  }
  createSpeechEventPayload(info, command) {
    const eventDict = { id: "meeting", name: command, meeting: info.conversationProperties };
    eventDict.meeting.id = info.id;
    eventDict.meeting.attendees = info.participants;
    eventDict.meeting.record = info.conversationProperties.audiorecording === "on" ? "true" : "false";
    return eventDict;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js
var DetailedSpeechPhrase = class {
  constructor(json) {
    this.privDetailedSpeechPhrase = JSON.parse(json);
    this.privDetailedSpeechPhrase.RecognitionStatus = RecognitionStatus[this.privDetailedSpeechPhrase.RecognitionStatus];
  }
  static fromJSON(json) {
    return new DetailedSpeechPhrase(json);
  }
  getJsonWithCorrectedOffsets(baseOffset) {
    if (!!this.privDetailedSpeechPhrase.NBest) {
      let firstWordOffset;
      for (const phrase of this.privDetailedSpeechPhrase.NBest) {
        if (!!phrase.Words && !!phrase.Words[0]) {
          firstWordOffset = phrase.Words[0].Offset;
          break;
        }
      }
      if (!!firstWordOffset && firstWordOffset < baseOffset) {
        const offset = baseOffset - firstWordOffset;
        for (const details of this.privDetailedSpeechPhrase.NBest) {
          if (!!details.Words) {
            for (const word of details.Words) {
              word.Offset += offset;
            }
          }
          if (!!details.DisplayWords) {
            for (const word of details.DisplayWords) {
              word.Offset += offset;
            }
          }
        }
      }
    }
    return JSON.stringify(this.privDetailedSpeechPhrase);
  }
  get RecognitionStatus() {
    return this.privDetailedSpeechPhrase.RecognitionStatus;
  }
  get NBest() {
    return this.privDetailedSpeechPhrase.NBest;
  }
  get Duration() {
    return this.privDetailedSpeechPhrase.Duration;
  }
  get Offset() {
    return this.privDetailedSpeechPhrase.Offset;
  }
  get Language() {
    return this.privDetailedSpeechPhrase.PrimaryLanguage === void 0 ? void 0 : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;
  }
  get LanguageDetectionConfidence() {
    return this.privDetailedSpeechPhrase.PrimaryLanguage === void 0 ? void 0 : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;
  }
  get Text() {
    if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {
      return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;
    }
    return this.privDetailedSpeechPhrase.DisplayText;
  }
  get SpeakerId() {
    return this.privDetailedSpeechPhrase.SpeakerId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js
var SimpleSpeechPhrase = class {
  constructor(json) {
    this.privSimpleSpeechPhrase = JSON.parse(json);
    this.privSimpleSpeechPhrase.RecognitionStatus = RecognitionStatus[this.privSimpleSpeechPhrase.RecognitionStatus];
  }
  static fromJSON(json) {
    return new SimpleSpeechPhrase(json);
  }
  get RecognitionStatus() {
    return this.privSimpleSpeechPhrase.RecognitionStatus;
  }
  get DisplayText() {
    return this.privSimpleSpeechPhrase.DisplayText;
  }
  get Offset() {
    return this.privSimpleSpeechPhrase.Offset;
  }
  get Duration() {
    return this.privSimpleSpeechPhrase.Duration;
  }
  get Language() {
    return this.privSimpleSpeechPhrase.PrimaryLanguage === void 0 ? void 0 : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;
  }
  get LanguageDetectionConfidence() {
    return this.privSimpleSpeechPhrase.PrimaryLanguage === void 0 ? void 0 : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;
  }
  get SpeakerId() {
    return this.privSimpleSpeechPhrase.SpeakerId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js
var AddedLmIntent = class {
  /**
   * Creates and initializes an instance of this class.
   * @constructor
   * @param modelImpl - The model.
   * @param intentName - The intent name.
   */
  constructor(modelImpl, intentName) {
    this.modelImpl = modelImpl;
    this.intentName = intentName;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js
var IntentServiceRecognizer = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.privIntentRecognizer = recognizer;
    this.privIntentDataSent = false;
  }
  setIntents(addedIntents, umbrellaIntent) {
    this.privAddedLmIntents = addedIntents;
    this.privUmbrellaIntent = umbrellaIntent;
    this.privIntentDataSent = true;
  }
  processTypeSpecificMessages(connectionMessage) {
    let result;
    let ev;
    let processed = false;
    const resultProps = new PropertyCollection();
    if (connectionMessage.messageType === MessageType.Text) {
      resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    switch (connectionMessage.path.toLowerCase()) {
      case "speech.hypothesis":
        const speechHypothesis = SpeechHypothesis.fromJSON(connectionMessage.textBody);
        result = new IntentRecognitionResult(void 0, this.privRequestSession.requestId, ResultReason.RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, void 0, connectionMessage.textBody, resultProps);
        this.privRequestSession.onHypothesis(result.offset);
        ev = new IntentRecognitionEventArgs(result, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
        if (!!this.privIntentRecognizer.recognizing) {
          try {
            this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);
          } catch (error) {
          }
        }
        processed = true;
        break;
      case "speech.phrase":
        const simple = SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);
        result = new IntentRecognitionResult(void 0, this.privRequestSession.requestId, EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, void 0, connectionMessage.textBody, resultProps);
        ev = new IntentRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
        const sendEvent = () => {
          if (!!this.privIntentRecognizer.recognized) {
            try {
              this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);
            } catch (error) {
            }
          }
          if (!!this.privSuccessCallback) {
            try {
              this.privSuccessCallback(result);
            } catch (e) {
              if (!!this.privErrorCallback) {
                this.privErrorCallback(e);
              }
            }
            this.privSuccessCallback = void 0;
            this.privErrorCallback = void 0;
          }
        };
        if (false === this.privIntentDataSent || ResultReason.NoMatch === ev.result.reason) {
          this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);
          sendEvent();
        } else {
          this.privPendingIntentArgs = ev;
        }
        processed = true;
        break;
      case "response":
        ev = this.privPendingIntentArgs;
        this.privPendingIntentArgs = void 0;
        if (void 0 === ev) {
          if ("" === connectionMessage.textBody) {
            return;
          }
          ev = new IntentRecognitionEventArgs(new IntentRecognitionResult(), 0, this.privRequestSession.sessionId);
        }
        const intentResponse = IntentResponse.fromJSON(connectionMessage.textBody);
        if (null !== intentResponse && !!intentResponse.topScoringIntent && !!intentResponse.topScoringIntent.intent) {
          let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];
          if (this.privUmbrellaIntent !== void 0) {
            addedIntent = this.privUmbrellaIntent;
          }
          if (!!addedIntent) {
            const intentId = addedIntent === void 0 || addedIntent.intentName === void 0 ? intentResponse.topScoringIntent.intent : addedIntent.intentName;
            let reason = ev.result.reason;
            if (void 0 !== intentId) {
              reason = ResultReason.RecognizedIntent;
            }
            const properties = void 0 !== ev.result.properties ? ev.result.properties : new PropertyCollection();
            properties.setProperty(PropertyId.LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);
            ev = new IntentRecognitionEventArgs(new IntentRecognitionResult(intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, void 0, void 0, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);
          }
        }
        this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);
        if (!!this.privIntentRecognizer.recognized) {
          try {
            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);
          } catch (error) {
          }
        }
        if (!!this.privSuccessCallback) {
          try {
            this.privSuccessCallback(ev.result);
          } catch (e) {
            if (!!this.privErrorCallback) {
              this.privErrorCallback(e);
            }
          }
          this.privSuccessCallback = void 0;
          this.privErrorCallback = void 0;
        }
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    if (!!this.privIntentRecognizer.canceled) {
      const cancelEvent = new IntentRecognitionCanceledEventArgs(cancellationReason, error, errorCode, void 0, void 0, sessionId);
      try {
        this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);
      } catch (_a) {
      }
    }
    if (!!this.privSuccessCallback) {
      const result = new IntentRecognitionResult(
        void 0,
        // Intent Id
        requestId,
        ResultReason.Canceled,
        void 0,
        // Text
        void 0,
        // Duration
        void 0,
        // Offset
        void 0,
        // Language
        void 0,
        // LanguageDetectionConfidence
        error,
        void 0,
        // Json
        properties
      );
      try {
        this.privSuccessCallback(result);
        this.privSuccessCallback = void 0;
      } catch (_b) {
      }
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js
var IntentResponse = class {
  constructor(json) {
    if (json === "") {
      this.privIntentResponse = {};
    } else {
      this.privIntentResponse = JSON.parse(json);
    }
  }
  static fromJSON(json) {
    return new IntentResponse(json);
  }
  get query() {
    return this.privIntentResponse.query;
  }
  get topScoringIntent() {
    return this.privIntentResponse.topScoringIntent;
  }
  get entities() {
    return this.privIntentResponse.entities;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js
var ServiceTelemetryListener = class {
  constructor(requestId, audioSourceId, audioNodeId) {
    this.privIsDisposed = false;
    this.privListeningTriggerMetric = null;
    this.privMicMetric = null;
    this.privConnectionEstablishMetric = null;
    this.privRequestId = requestId;
    this.privAudioSourceId = audioSourceId;
    this.privAudioNodeId = audioNodeId;
    this.privReceivedMessages = {};
    this.privPhraseLatencies = [];
    this.privHypothesisLatencies = [];
  }
  phraseReceived(audioReceivedTime) {
    if (audioReceivedTime > 0) {
      this.privPhraseLatencies.push(Date.now() - audioReceivedTime);
    }
  }
  hypothesisReceived(audioReceivedTime) {
    if (audioReceivedTime > 0) {
      this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);
    }
  }
  onEvent(e) {
    if (this.privIsDisposed) {
      return;
    }
    if (e instanceof RecognitionTriggeredEvent && e.requestId === this.privRequestId) {
      this.privListeningTriggerMetric = {
        End: e.eventTime,
        Name: "ListeningTrigger",
        Start: e.eventTime
      };
    }
    if (e instanceof AudioStreamNodeAttachingEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      this.privMicStartTime = e.eventTime;
    }
    if (e instanceof AudioStreamNodeAttachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      this.privMicStartTime = e.eventTime;
    }
    if (e instanceof AudioSourceErrorEvent && e.audioSourceId === this.privAudioSourceId) {
      if (!this.privMicMetric) {
        this.privMicMetric = {
          End: e.eventTime,
          Error: e.error,
          Name: "Microphone",
          Start: this.privMicStartTime
        };
      }
    }
    if (e instanceof AudioStreamNodeErrorEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      if (!this.privMicMetric) {
        this.privMicMetric = {
          End: e.eventTime,
          Error: e.error,
          Name: "Microphone",
          Start: this.privMicStartTime
        };
      }
    }
    if (e instanceof AudioStreamNodeDetachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
      if (!this.privMicMetric) {
        this.privMicMetric = {
          End: e.eventTime,
          Name: "Microphone",
          Start: this.privMicStartTime
        };
      }
    }
    if (e instanceof ConnectingToServiceEvent && e.requestId === this.privRequestId) {
      this.privConnectionId = e.sessionId;
    }
    if (e instanceof ConnectionStartEvent && e.connectionId === this.privConnectionId) {
      this.privConnectionStartTime = e.eventTime;
    }
    if (e instanceof ConnectionEstablishedEvent && e.connectionId === this.privConnectionId) {
      if (!this.privConnectionEstablishMetric) {
        this.privConnectionEstablishMetric = {
          End: e.eventTime,
          Id: this.privConnectionId,
          Name: "Connection",
          Start: this.privConnectionStartTime
        };
      }
    }
    if (e instanceof ConnectionEstablishErrorEvent && e.connectionId === this.privConnectionId) {
      if (!this.privConnectionEstablishMetric) {
        this.privConnectionEstablishMetric = {
          End: e.eventTime,
          Error: this.getConnectionError(e.statusCode),
          Id: this.privConnectionId,
          Name: "Connection",
          Start: this.privConnectionStartTime
        };
      }
    }
    if (e instanceof ConnectionMessageReceivedEvent && e.connectionId === this.privConnectionId) {
      if (e.message && e.message.headers && e.message.headers.path) {
        if (!this.privReceivedMessages[e.message.headers.path]) {
          this.privReceivedMessages[e.message.headers.path] = new Array();
        }
        const maxMessagesToSend = 50;
        if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {
          this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);
        }
      }
    }
  }
  getTelemetry() {
    const metrics = new Array();
    if (this.privListeningTriggerMetric) {
      metrics.push(this.privListeningTriggerMetric);
    }
    if (this.privMicMetric) {
      metrics.push(this.privMicMetric);
    }
    if (this.privConnectionEstablishMetric) {
      metrics.push(this.privConnectionEstablishMetric);
    }
    if (this.privPhraseLatencies.length > 0) {
      metrics.push({
        PhraseLatencyMs: this.privPhraseLatencies
      });
    }
    if (this.privHypothesisLatencies.length > 0) {
      metrics.push({
        FirstHypothesisLatencyMs: this.privHypothesisLatencies
      });
    }
    const telemetry = {
      Metrics: metrics,
      ReceivedMessages: this.privReceivedMessages
    };
    const json = JSON.stringify(telemetry);
    this.privReceivedMessages = {};
    this.privListeningTriggerMetric = null;
    this.privMicMetric = null;
    this.privConnectionEstablishMetric = null;
    this.privPhraseLatencies = [];
    this.privHypothesisLatencies = [];
    return json;
  }
  // Determines if there are any telemetry events to send to the service.
  get hasTelemetry() {
    return Object.keys(this.privReceivedMessages).length !== 0 || this.privListeningTriggerMetric !== null || this.privMicMetric !== null || this.privConnectionEstablishMetric !== null || this.privPhraseLatencies.length !== 0 || this.privHypothesisLatencies.length !== 0;
  }
  dispose() {
    this.privIsDisposed = true;
  }
  getConnectionError(statusCode) {
    switch (statusCode) {
      case 400:
      case 1002:
      case 1003:
      case 1005:
      case 1007:
      case 1008:
      case 1009:
        return "BadRequest";
      case 401:
        return "Unauthorized";
      case 403:
        return "Forbidden";
      case 503:
      case 1001:
        return "ServerUnavailable";
      case 500:
      case 1011:
        return "ServerError";
      case 408:
      case 504:
        return "Timeout";
      default:
        return "statuscode:" + statusCode.toString();
    }
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js
var __awaiter23 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var RequestSession = class {
  constructor(audioSourceId) {
    this.privIsDisposed = false;
    this.privDetachables = new Array();
    this.privIsAudioNodeDetached = false;
    this.privIsRecognizing = false;
    this.privIsSpeechEnded = false;
    this.privTurnStartAudioOffset = 0;
    this.privLastRecoOffset = 0;
    this.privHypothesisReceived = false;
    this.privBytesSent = 0;
    this.privRecogNumber = 0;
    this.privInTurn = false;
    this.privConnectionAttempts = 0;
    this.privAudioSourceId = audioSourceId;
    this.privRequestId = createNoDashGuid();
    this.privAudioNodeId = createNoDashGuid();
    this.privTurnDeferral = new Deferred();
    this.privTurnDeferral.resolve();
  }
  get sessionId() {
    return this.privSessionId;
  }
  get requestId() {
    return this.privRequestId;
  }
  get audioNodeId() {
    return this.privAudioNodeId;
  }
  get turnCompletionPromise() {
    return this.privTurnDeferral.promise;
  }
  get isSpeechEnded() {
    return this.privIsSpeechEnded;
  }
  get isRecognizing() {
    return this.privIsRecognizing;
  }
  get currentTurnAudioOffset() {
    return this.privTurnStartAudioOffset;
  }
  get recogNumber() {
    return this.privRecogNumber;
  }
  get numConnectionAttempts() {
    return this.privConnectionAttempts;
  }
  // The number of bytes sent for the current connection.
  // Counter is reset to 0 each time a connection is established.
  get bytesSent() {
    return this.privBytesSent;
  }
  listenForServiceTelemetry(eventSource) {
    if (!!this.privServiceTelemetryListener) {
      this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));
    }
  }
  startNewRecognition() {
    this.privIsSpeechEnded = false;
    this.privIsRecognizing = true;
    this.privTurnStartAudioOffset = 0;
    this.privLastRecoOffset = 0;
    this.privRecogNumber++;
    this.privServiceTelemetryListener = new ServiceTelemetryListener(this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);
    this.onEvent(new RecognitionTriggeredEvent(this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
  }
  onAudioSourceAttachCompleted(audioNode, isError) {
    return __awaiter23(this, void 0, void 0, function* () {
      this.privAudioNode = audioNode;
      this.privIsAudioNodeDetached = false;
      if (isError) {
        yield this.onComplete();
      } else {
        this.onEvent(new ListeningStartedEvent(this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
      }
    });
  }
  onPreConnectionStart(authFetchEventId, connectionId) {
    this.privAuthFetchEventId = authFetchEventId;
    this.privSessionId = connectionId;
    this.onEvent(new ConnectingToServiceEvent(this.privRequestId, this.privAuthFetchEventId, this.privSessionId));
  }
  onAuthCompleted(isError) {
    return __awaiter23(this, void 0, void 0, function* () {
      if (isError) {
        yield this.onComplete();
      }
    });
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  onConnectionEstablishCompleted(statusCode, reason) {
    return __awaiter23(this, void 0, void 0, function* () {
      if (statusCode === 200) {
        this.onEvent(new RecognitionStartedEvent(this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));
        if (!!this.privAudioNode) {
          this.privAudioNode.replay();
        }
        this.privTurnStartAudioOffset = this.privLastRecoOffset;
        this.privBytesSent = 0;
        return;
      } else if (statusCode === 403) {
        yield this.onComplete();
      }
    });
  }
  onServiceTurnEndResponse(continuousRecognition) {
    return __awaiter23(this, void 0, void 0, function* () {
      this.privTurnDeferral.resolve();
      if (!continuousRecognition || this.isSpeechEnded) {
        yield this.onComplete();
        this.privInTurn = false;
      } else {
        this.privTurnStartAudioOffset = this.privLastRecoOffset;
        this.privAudioNode.replay();
      }
    });
  }
  onSpeechContext() {
    this.privRequestId = createNoDashGuid();
  }
  onServiceTurnStartResponse() {
    if (!!this.privTurnDeferral && !!this.privInTurn) {
      this.privTurnDeferral.reject("Another turn started before current completed.");
      this.privTurnDeferral.promise.then().catch(() => {
      });
    }
    this.privInTurn = true;
    this.privTurnDeferral = new Deferred();
  }
  onHypothesis(offset) {
    if (!this.privHypothesisReceived) {
      this.privHypothesisReceived = true;
      this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));
    }
  }
  onPhraseRecognized(offset) {
    this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));
    this.onServiceRecognized(offset);
  }
  onServiceRecognized(offset) {
    this.privLastRecoOffset = offset;
    this.privHypothesisReceived = false;
    this.privAudioNode.shrinkBuffers(offset);
    this.privConnectionAttempts = 0;
  }
  onAudioSent(bytesSent) {
    this.privBytesSent += bytesSent;
  }
  onRetryConnection() {
    this.privConnectionAttempts++;
  }
  dispose() {
    return __awaiter23(this, void 0, void 0, function* () {
      if (!this.privIsDisposed) {
        this.privIsDisposed = true;
        for (const detachable of this.privDetachables) {
          yield detachable.detach();
        }
        if (!!this.privServiceTelemetryListener) {
          this.privServiceTelemetryListener.dispose();
        }
        this.privIsRecognizing = false;
      }
    });
  }
  getTelemetry() {
    if (this.privServiceTelemetryListener.hasTelemetry) {
      return this.privServiceTelemetryListener.getTelemetry();
    } else {
      return null;
    }
  }
  onStopRecognizing() {
    return __awaiter23(this, void 0, void 0, function* () {
      yield this.onComplete();
    });
  }
  // Should be called with the audioNode for this session has indicated that it is out of speech.
  onSpeechEnded() {
    this.privIsSpeechEnded = true;
  }
  onEvent(event) {
    if (!!this.privServiceTelemetryListener) {
      this.privServiceTelemetryListener.onEvent(event);
    }
    Events.instance.onEvent(event);
  }
  onComplete() {
    return __awaiter23(this, void 0, void 0, function* () {
      if (!!this.privIsRecognizing) {
        this.privIsRecognizing = false;
        yield this.detachAudioNode();
      }
    });
  }
  detachAudioNode() {
    return __awaiter23(this, void 0, void 0, function* () {
      if (!this.privIsAudioNodeDetached) {
        this.privIsAudioNodeDetached = true;
        if (this.privAudioNode) {
          yield this.privAudioNode.detach();
        }
      }
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js
var SpeechContext = class {
  constructor(dynamicGrammar) {
    this.privContext = {};
    this.privDynamicGrammar = dynamicGrammar;
  }
  /**
   * Gets a section of the speech.context object.
   * @param sectionName Name of the section to get.
   * @return string or Context JSON serializable object that represents the value.
   */
  getSection(sectionName) {
    return this.privContext[sectionName] || {};
  }
  /**
   * Adds a section to the speech.context object.
   * @param sectionName Name of the section to add.
   * @param value JSON serializable object that represents the value.
   */
  setSection(sectionName, value) {
    this.privContext[sectionName] = value;
  }
  /**
   * @Internal
   * This is only used by pronunciation assessment config.
   * Do not use externally, object returned will change without warning or notice.
   */
  setPronunciationAssessmentParams(params) {
    if (this.privContext.phraseDetection === void 0) {
      this.privContext.phraseDetection = {
        enrichment: {
          pronunciationAssessment: {}
        }
      };
    }
    this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);
    this.setWordLevelTimings();
    this.privContext.phraseOutput.detailed.options.push("PronunciationAssessment");
    if (this.privContext.phraseOutput.detailed.options.indexOf("SNR") === -1) {
      this.privContext.phraseOutput.detailed.options.push("SNR");
    }
  }
  setWordLevelTimings() {
    if (this.privContext.phraseOutput === void 0) {
      this.privContext.phraseOutput = {
        detailed: {
          options: []
        },
        format: {}
      };
    }
    if (this.privContext.phraseOutput.detailed === void 0) {
      this.privContext.phraseOutput.detailed = {
        options: []
      };
    }
    this.privContext.phraseOutput.format = "Detailed";
    if (this.privContext.phraseOutput.detailed.options.indexOf("WordTimings") === -1) {
      this.privContext.phraseOutput.detailed.options.push("WordTimings");
    }
  }
  toJSON() {
    const dgi = this.privDynamicGrammar.generateGrammarObject();
    this.setSection("dgi", dgi);
    const ret = JSON.stringify(this.privContext);
    return ret;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js
var DynamicGrammarBuilder = class {
  // Adds one more reference phrases to the dynamic grammar to send.
  // All added phrases are generic phrases.
  addPhrase(phrase) {
    if (!this.privPhrases) {
      this.privPhrases = [];
    }
    if (phrase instanceof Array) {
      this.privPhrases = this.privPhrases.concat(phrase);
    } else {
      this.privPhrases.push(phrase);
    }
  }
  // Clears all phrases stored in the current object.
  clearPhrases() {
    this.privPhrases = void 0;
  }
  // Adds one or more reference grammars to the current grammar.
  addReferenceGrammar(grammar) {
    if (!this.privGrammars) {
      this.privGrammars = [];
    }
    if (grammar instanceof Array) {
      this.privGrammars = this.privGrammars.concat(grammar);
    } else {
      this.privGrammars.push(grammar);
    }
  }
  // clears all grammars stored on the recognizer.
  clearGrammars() {
    this.privGrammars = void 0;
  }
  // Generates an object that represents the dynamic grammar used by the Speech Service.
  // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance
  // of a DynamicGrammarBuilder
  generateGrammarObject() {
    if (this.privGrammars === void 0 && this.privPhrases === void 0) {
      return void 0;
    }
    const retObj = {};
    retObj.ReferenceGrammars = this.privGrammars;
    if (void 0 !== this.privPhrases && 0 !== this.privPhrases.length) {
      const retPhrases = [];
      this.privPhrases.forEach((value) => {
        retPhrases.push({
          Text: value
        });
      });
      retObj.Groups = [{ Type: "Generic", Items: retPhrases }];
    }
    return retObj;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js
var ActivityPayloadResponse = class {
  constructor(json) {
    this.privActivityResponse = JSON.parse(json);
  }
  static fromJSON(json) {
    return new ActivityPayloadResponse(json);
  }
  get conversationId() {
    return this.privActivityResponse.conversationId;
  }
  get messageDataStreamType() {
    return this.privActivityResponse.messageDataStreamType;
  }
  get messagePayload() {
    return this.privActivityResponse.messagePayload;
  }
  get version() {
    return this.privActivityResponse.version;
  }
};
var MessageDataStreamType;
(function(MessageDataStreamType2) {
  MessageDataStreamType2[MessageDataStreamType2["None"] = 0] = "None";
  MessageDataStreamType2[MessageDataStreamType2["TextToSpeechAudio"] = 1] = "TextToSpeechAudio";
})(MessageDataStreamType || (MessageDataStreamType = {}));

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js
var DialogServiceTurnState = class {
  constructor(manager, requestId) {
    this.privRequestId = requestId;
    this.privIsCompleted = false;
    this.privAudioStream = null;
    this.privTurnManager = manager;
    this.resetTurnEndTimeout();
  }
  get audioStream() {
    this.resetTurnEndTimeout();
    return this.privAudioStream;
  }
  processActivityPayload(payload, audioFormat) {
    if (payload.messageDataStreamType === MessageDataStreamType.TextToSpeechAudio) {
      this.privAudioStream = AudioOutputStream.createPullStream();
      this.privAudioStream.format = audioFormat !== void 0 ? audioFormat : AudioOutputFormatImpl.getDefaultOutputFormat();
    }
    return this.privAudioStream;
  }
  endAudioStream() {
    if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {
      this.privAudioStream.close();
    }
  }
  complete() {
    if (this.privTimeoutToken !== void 0) {
      clearTimeout(this.privTimeoutToken);
    }
    this.endAudioStream();
  }
  resetTurnEndTimeout() {
    if (this.privTimeoutToken !== void 0) {
      clearTimeout(this.privTimeoutToken);
    }
    this.privTimeoutToken = setTimeout(() => {
      this.privTurnManager.CompleteTurn(this.privRequestId);
      return;
    }, 2e3);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js
var DialogServiceTurnStateManager = class {
  constructor() {
    this.privTurnMap = /* @__PURE__ */ new Map();
    return;
  }
  StartTurn(id) {
    if (this.privTurnMap.has(id)) {
      throw new InvalidOperationError("Service error: There is already a turn with id:" + id);
    }
    const turnState = new DialogServiceTurnState(this, id);
    this.privTurnMap.set(id, turnState);
    return this.privTurnMap.get(id);
  }
  GetTurn(id) {
    return this.privTurnMap.get(id);
  }
  CompleteTurn(id) {
    if (!this.privTurnMap.has(id)) {
      throw new InvalidOperationError("Service error: Received turn end for an unknown turn id:" + id);
    }
    const turnState = this.privTurnMap.get(id);
    turnState.complete();
    this.privTurnMap.delete(id);
    return turnState;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js
var __awaiter24 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var DialogServiceAdapter = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);
    this.privEvents = new EventSource();
    this.privDialogServiceConnector = dialogServiceConnector;
    this.receiveMessageOverride = () => this.receiveDialogMessageOverride();
    this.privTurnStateManager = new DialogServiceTurnStateManager();
    this.recognizeOverride = (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);
    this.postConnectImplOverride = (connection) => this.dialogConnectImpl(connection);
    this.configConnectionOverride = (connection) => this.configConnection(connection);
    this.disconnectOverride = () => this.privDisconnect();
    this.privDialogAudioSource = audioSource;
    this.agentConfigSent = false;
    this.privLastResult = null;
    this.connectionEvents.attach((connectionEvent) => {
      if (connectionEvent.name === "ConnectionClosedEvent") {
        this.terminateMessageLoop = true;
      }
    });
  }
  sendMessage(message) {
    return __awaiter24(this, void 0, void 0, function* () {
      const interactionGuid = createGuid();
      const requestId = createNoDashGuid();
      const agentMessage = {
        context: {
          interactionId: interactionGuid
        },
        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
        messagePayload: JSON.parse(message),
        version: 0.5
      };
      const agentMessageJson = JSON.stringify(agentMessage);
      const connection = yield this.fetchConnection();
      yield connection.send(new SpeechConnectionMessage(MessageType.Text, "agent", requestId, "application/json", agentMessageJson));
    });
  }
  privDisconnect() {
    return __awaiter24(this, void 0, void 0, function* () {
      yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.NoError, "Disconnecting");
      this.terminateMessageLoop = true;
      this.agentConfigSent = false;
      return;
    });
  }
  processTypeSpecificMessages(connectionMessage) {
    const resultProps = new PropertyCollection();
    if (connectionMessage.messageType === MessageType.Text) {
      resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    let result;
    let processed;
    switch (connectionMessage.path.toLowerCase()) {
      case "speech.phrase":
        const speechPhrase = SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);
        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);
        if (speechPhrase.RecognitionStatus !== RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== RecognitionStatus.Error) {
          const args = this.fireEventForResult(speechPhrase, resultProps);
          this.privLastResult = args.result;
          if (!!this.privDialogServiceConnector.recognized) {
            try {
              this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);
            } catch (error) {
            }
          }
        }
        processed = true;
        break;
      case "speech.hypothesis":
        const hypothesis = SpeechHypothesis.fromJSON(connectionMessage.textBody);
        const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;
        result = new SpeechRecognitionResult(this.privRequestSession.requestId, ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, void 0, void 0, connectionMessage.textBody, resultProps);
        this.privRequestSession.onHypothesis(offset);
        const ev = new SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);
        if (!!this.privDialogServiceConnector.recognizing) {
          try {
            this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);
          } catch (error) {
          }
        }
        processed = true;
        break;
      case "speech.keyword":
        const keyword = SpeechKeyword.fromJSON(connectionMessage.textBody);
        result = new SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === "Accepted" ? ResultReason.RecognizedKeyword : ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, void 0, void 0, void 0, void 0, connectionMessage.textBody, resultProps);
        if (keyword.Status !== "Accepted") {
          this.privLastResult = result;
        }
        const event = new SpeechRecognitionEventArgs(result, result.duration, result.resultId);
        if (!!this.privDialogServiceConnector.recognized) {
          try {
            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);
          } catch (error) {
          }
        }
        processed = true;
        break;
      case "audio":
        {
          const audioRequestId = connectionMessage.requestId.toUpperCase();
          const turn = this.privTurnStateManager.GetTurn(audioRequestId);
          try {
            if (!connectionMessage.binaryBody) {
              turn.endAudioStream();
            } else {
              turn.audioStream.write(connectionMessage.binaryBody);
            }
          } catch (error) {
          }
        }
        processed = true;
        break;
      case "response":
        {
          this.handleResponseMessage(connectionMessage);
        }
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    return __awaiter24(this, void 0, void 0, function* () {
      this.terminateMessageLoop = true;
      if (!!this.privRequestSession.isRecognizing) {
        yield this.privRequestSession.onStopRecognizing();
      }
      if (!!this.privDialogServiceConnector.canceled) {
        const properties = new PropertyCollection();
        properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
        const cancelEvent = new SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, void 0, sessionId);
        try {
          this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);
        } catch (_a) {
        }
        if (!!this.privSuccessCallback) {
          const result = new SpeechRecognitionResult(
            void 0,
            // ResultId
            ResultReason.Canceled,
            void 0,
            // Text
            void 0,
            // Duration
            void 0,
            // Offset
            void 0,
            // Language
            void 0,
            // Language Detection Confidence
            void 0,
            // Speaker Id
            error,
            void 0,
            // Json
            properties
          );
          try {
            this.privSuccessCallback(result);
            this.privSuccessCallback = void 0;
          } catch (_b) {
          }
        }
      }
    });
  }
  listenOnce(recoMode, successCallback, errorCallback) {
    return __awaiter24(this, void 0, void 0, function* () {
      this.privRecognizerConfig.recognitionMode = recoMode;
      this.privSuccessCallback = successCallback;
      this.privErrorCallback = errorCallback;
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);
      this.privRecognizerConfig.parameters.setProperty(PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
      const conPromise = this.connectImpl();
      const preAudioPromise = this.sendPreAudioMessages();
      const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);
      const format = yield this.privDialogAudioSource.format;
      const deviceInfo = yield this.privDialogAudioSource.deviceInfo;
      const audioNode = new ReplayableAudioNode(node, format.avgBytesPerSec);
      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
      try {
        yield conPromise;
        yield preAudioPromise;
      } catch (error) {
        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.ConnectionFailure, error);
        return Promise.resolve();
      }
      const sessionStartEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      const audioSendPromise = this.sendAudio(audioNode);
      audioSendPromise.then(() => {
      }, (error) => __awaiter24(this, void 0, void 0, function* () {
        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.RuntimeError, error);
      }));
    });
  }
  // Establishes a websocket connection to the end point.
  dialogConnectImpl(connection) {
    this.privConnectionLoop = this.startMessageLoop();
    return connection;
  }
  receiveDialogMessageOverride() {
    const communicationCustodian = new Deferred();
    const loop = () => __awaiter24(this, void 0, void 0, function* () {
      try {
        const isDisposed = this.isDisposed();
        const terminateMessageLoop = !this.isDisposed() && this.terminateMessageLoop;
        if (isDisposed || terminateMessageLoop) {
          communicationCustodian.resolve(void 0);
          return;
        }
        const connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (!message) {
          return loop();
        }
        const connectionMessage = SpeechConnectionMessage.fromConnectionMessage(message);
        switch (connectionMessage.path.toLowerCase()) {
          case "turn.start":
            {
              const turnRequestId = connectionMessage.requestId.toUpperCase();
              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
              if (turnRequestId !== audioSessionReqId) {
                this.privTurnStateManager.StartTurn(turnRequestId);
              } else {
                this.privRequestSession.onServiceTurnStartResponse();
              }
            }
            break;
          case "speech.startdetected":
            const speechStartDetected = SpeechDetected.fromJSON(connectionMessage.textBody);
            const speechStartEventArgs = new RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);
            if (!!this.privRecognizer.speechStartDetected) {
              this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
            }
            break;
          case "speech.enddetected":
            let json;
            if (connectionMessage.textBody.length > 0) {
              json = connectionMessage.textBody;
            } else {
              json = "{ Offset: 0 }";
            }
            const speechStopDetected = SpeechDetected.fromJSON(json);
            this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);
            const speechStopEventArgs = new RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
            if (!!this.privRecognizer.speechEndDetected) {
              this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
            }
            break;
          case "turn.end":
            {
              const turnEndRequestId = connectionMessage.requestId.toUpperCase();
              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
              if (turnEndRequestId !== audioSessionReqId) {
                this.privTurnStateManager.CompleteTurn(turnEndRequestId);
              } else {
                const sessionStopEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);
                yield this.privRequestSession.onServiceTurnEndResponse(false);
                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                  if (!!this.privRecognizer.sessionStopped) {
                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                  }
                }
                if (!!this.privSuccessCallback && this.privLastResult) {
                  try {
                    this.privSuccessCallback(this.privLastResult);
                    this.privLastResult = null;
                  } catch (e) {
                    if (!!this.privErrorCallback) {
                      this.privErrorCallback(e);
                    }
                  }
                  this.privSuccessCallback = void 0;
                  this.privErrorCallback = void 0;
                }
              }
            }
            break;
          default:
            try {
              const processed = yield this.processTypeSpecificMessages(connectionMessage);
              if (!processed) {
                if (!!this.serviceEvents) {
                  this.serviceEvents.onEvent(new ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                }
              }
            } catch (e) {
            }
        }
        const ret = loop();
        return ret;
      } catch (error) {
        this.terminateMessageLoop = true;
        communicationCustodian.resolve();
      }
    });
    loop().catch((reason) => {
      Events.instance.onEvent(new BackgroundEvent(reason));
    });
    return communicationCustodian.promise;
  }
  startMessageLoop() {
    return __awaiter24(this, void 0, void 0, function* () {
      this.terminateMessageLoop = false;
      try {
        yield this.receiveDialogMessageOverride();
      } catch (error) {
        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.RuntimeError, error);
      }
      return Promise.resolve();
    });
  }
  // Takes an established websocket connection to the endpoint and sends speech configuration information.
  configConnection(connection) {
    return __awaiter24(this, void 0, void 0, function* () {
      if (this.terminateMessageLoop) {
        this.terminateMessageLoop = false;
        return Promise.reject("Connection to service terminated.");
      }
      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
      yield this.sendAgentConfig(connection);
      return connection;
    });
  }
  sendPreAudioMessages() {
    return __awaiter24(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.addKeywordContextData();
      yield this.sendSpeechContext(connection, true);
      yield this.sendAgentContext(connection);
      yield this.sendWaveHeader(connection);
    });
  }
  sendAgentConfig(connection) {
    if (this.agentConfig && !this.agentConfigSent) {
      if (this.privRecognizerConfig.parameters.getProperty(PropertyId.Conversation_DialogType) === DialogServiceConfig.DialogTypes.CustomCommands) {
        const config = this.agentConfig.get();
        config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, "en-us");
        this.agentConfig.set(config);
      }
      this.onEvent(new SendingAgentContextMessageEvent(this.agentConfig));
      const agentConfigJson = this.agentConfig.toJsonString();
      this.agentConfigSent = true;
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "agent.config", this.privRequestSession.requestId, "application/json", agentConfigJson));
    }
    return;
  }
  sendAgentContext(connection) {
    const guid = createGuid();
    const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(PropertyId.Conversation_Speech_Activity_Template);
    const agentContext = {
      channelData: "",
      context: {
        interactionId: guid
      },
      messagePayload: typeof speechActivityTemplate === void 0 ? void 0 : speechActivityTemplate,
      version: 0.5
    };
    const agentContextJson = JSON.stringify(agentContext);
    return connection.send(new SpeechConnectionMessage(MessageType.Text, "speech.agent.context", this.privRequestSession.requestId, "application/json", agentContextJson));
  }
  fireEventForResult(serviceResult, properties) {
    const resultReason = EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);
    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;
    const result = new SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, void 0, void 0, JSON.stringify(serviceResult), properties);
    const ev = new SpeechRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);
    return ev;
  }
  handleResponseMessage(responseMessage) {
    const responsePayload = JSON.parse(responseMessage.textBody);
    switch (responsePayload.messageType.toLowerCase()) {
      case "message":
        const responseRequestId = responseMessage.requestId.toUpperCase();
        const activityPayload = ActivityPayloadResponse.fromJSON(responseMessage.textBody);
        const turn = this.privTurnStateManager.GetTurn(responseRequestId);
        if (activityPayload.conversationId) {
          const updateAgentConfig = this.agentConfig.get();
          updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;
          this.agentConfig.set(updateAgentConfig);
        }
        const pullAudioOutputStream = turn.processActivityPayload(activityPayload, AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, void 0)));
        const activity = new ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);
        if (!!this.privDialogServiceConnector.activityReceived) {
          try {
            this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);
          } catch (error) {
          }
        }
        break;
      case "messagestatus":
        if (!!this.privDialogServiceConnector.turnStatusReceived) {
          try {
            this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new TurnStatusReceivedEventArgs(responseMessage.textBody));
          } catch (error) {
          }
        }
        break;
      default:
        Events.instance.onEvent(new BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));
        break;
    }
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    Events.instance.onEvent(event);
  }
  addKeywordContextData() {
    const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect");
    if (keywordPropertyValue === void 0) {
      return;
    }
    const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect-Offsets");
    const keywordDurationPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect-Durations");
    const keywords = keywordPropertyValue.split(";");
    const keywordOffsets = keywordOffsetPropertyValue === void 0 ? [] : keywordOffsetPropertyValue.split(";");
    const keywordDurations = keywordDurationPropertyValue === void 0 ? [] : keywordDurationPropertyValue.split(";");
    const keywordDefinitionArray = [];
    for (let i = 0; i < keywords.length; i++) {
      const definition = {};
      definition.text = keywords[i];
      if (i < keywordOffsets.length) {
        definition.offset = Number(keywordOffsets[i]);
      }
      if (i < keywordDurations.length) {
        definition.duration = Number(keywordDurations[i]);
      }
      keywordDefinitionArray.push(definition);
    }
    this.speechContext.setSection("invocationSource", "VoiceActivationWithKeyword");
    this.speechContext.setSection("keywordDetection", [{
      clientDetectedKeywords: keywordDefinitionArray,
      onReject: { action: "EndOfTurn" },
      type: "startTrigger"
    }]);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js
var AgentConfig = class {
  toJsonString() {
    return JSON.stringify(this.iPrivConfig);
  }
  get() {
    return this.iPrivConfig;
  }
  /**
   * Setter for the agent.config object.
   * @param value a JSON serializable object.
   */
  set(value) {
    this.iPrivConfig = value;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js
var RestConfigBase = class {
  static get requestOptions() {
    return RestConfigBase.privDefaultRequestOptions;
  }
  static get configParams() {
    return RestConfigBase.privDefaultParams;
  }
  static get restErrors() {
    return RestConfigBase.privRestErrors;
  }
};
RestConfigBase.privDefaultRequestOptions = {
  headers: {
    Accept: "application/json"
  },
  ignoreCache: false,
  timeout: 1e4
};
RestConfigBase.privRestErrors = {
  authInvalidSubscriptionKey: "You must specify either an authentication token to use, or a Cognitive Speech subscription key.",
  authInvalidSubscriptionRegion: "You must specify the Cognitive Speech region to use.",
  invalidArgs: "Required input not found: {arg}.",
  invalidCreateJoinConversationResponse: "Creating/Joining conversation failed with HTTP {status}.",
  invalidParticipantRequest: "The requested participant was not found.",
  permissionDeniedConnect: "Required credentials not found.",
  permissionDeniedConversation: "Invalid operation: only the host can {command} the conversation.",
  permissionDeniedParticipant: "Invalid operation: only the host can {command} a participant.",
  permissionDeniedSend: "Invalid operation: the conversation is not in a connected state.",
  permissionDeniedStart: "Invalid operation: there is already an active conversation."
};
RestConfigBase.privDefaultParams = {
  apiVersion: "api-version",
  authorization: "Authorization",
  clientAppId: "X-ClientAppId",
  contentTypeKey: "Content-Type",
  correlationId: "X-CorrelationId",
  languageCode: "language",
  nickname: "nickname",
  profanity: "profanity",
  requestId: "X-RequestId",
  roomId: "roomid",
  sessionToken: "token",
  subscriptionKey: "Ocp-Apim-Subscription-Key",
  subscriptionRegion: "Ocp-Apim-Subscription-Region",
  token: "X-CapitoToken"
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js
var ConversationConnectionConfig = class extends RestConfigBase {
  static get host() {
    return ConversationConnectionConfig.privHost;
  }
  static get apiVersion() {
    return ConversationConnectionConfig.privApiVersion;
  }
  static get clientAppId() {
    return ConversationConnectionConfig.privClientAppId;
  }
  static get defaultLanguageCode() {
    return ConversationConnectionConfig.privDefaultLanguageCode;
  }
  static get restPath() {
    return ConversationConnectionConfig.privRestPath;
  }
  static get webSocketPath() {
    return ConversationConnectionConfig.privWebSocketPath;
  }
  static get transcriptionEventKeys() {
    return ConversationConnectionConfig.privTranscriptionEventKeys;
  }
};
ConversationConnectionConfig.privHost = "dev.microsofttranslator.com";
ConversationConnectionConfig.privRestPath = "/capito/room";
ConversationConnectionConfig.privApiVersion = "2.0";
ConversationConnectionConfig.privDefaultLanguageCode = "en-US";
ConversationConnectionConfig.privClientAppId = "FC539C22-1767-4F1F-84BC-B4D811114F15";
ConversationConnectionConfig.privWebSocketPath = "/capito/translate";
ConversationConnectionConfig.privTranscriptionEventKeys = ["iCalUid", "callId", "organizer", "FLAC", "MTUri", "DifferentiateGuestSpeakers", "audiorecording", "Threadid", "OrganizerMri", "OrganizerTenantId", "UserToken"];

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js
var ConversationManager = class {
  constructor() {
    this.privRequestParams = ConversationConnectionConfig.configParams;
    this.privErrors = ConversationConnectionConfig.restErrors;
    this.privHost = ConversationConnectionConfig.host;
    this.privApiVersion = ConversationConnectionConfig.apiVersion;
    this.privRestPath = ConversationConnectionConfig.restPath;
    this.privRestAdapter = new RestMessageAdapter({});
  }
  /**
   * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.
   * @param args
   * @param conversationCode
   * @param callback
   * @param errorCallback
   */
  createOrJoin(args, conversationCode, cb, err) {
    try {
      Contracts.throwIfNullOrUndefined(args, "args");
      const languageCode = args.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage, ConversationConnectionConfig.defaultLanguageCode);
      const nickname = args.getProperty(PropertyId.ConversationTranslator_Name, "conversation_host");
      const endpointHost = args.getProperty(PropertyId.ConversationTranslator_Host, this.privHost);
      const correlationId = args.getProperty(PropertyId.ConversationTranslator_CorrelationId);
      const subscriptionKey = args.getProperty(PropertyId.SpeechServiceConnection_Key);
      const subscriptionRegion = args.getProperty(PropertyId.SpeechServiceConnection_Region);
      const authToken = args.getProperty(PropertyId.SpeechServiceAuthorization_Token);
      Contracts.throwIfNullOrWhitespace(languageCode, "languageCode");
      Contracts.throwIfNullOrWhitespace(nickname, "nickname");
      Contracts.throwIfNullOrWhitespace(endpointHost, "endpointHost");
      const queryParams = {};
      queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
      queryParams[this.privRequestParams.languageCode] = languageCode;
      queryParams[this.privRequestParams.nickname] = nickname;
      const headers = {};
      if (correlationId) {
        headers[this.privRequestParams.correlationId] = correlationId;
      }
      headers[this.privRequestParams.clientAppId] = ConversationConnectionConfig.clientAppId;
      if (conversationCode !== void 0) {
        queryParams[this.privRequestParams.roomId] = conversationCode;
      } else {
        Contracts.throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);
        headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;
        if (subscriptionKey) {
          headers[this.privRequestParams.subscriptionKey] = subscriptionKey;
        } else if (authToken) {
          headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;
        } else {
          Contracts.throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);
        }
      }
      const config = {};
      config.headers = headers;
      this.privRestAdapter.options = config;
      const endpoint = `https://${endpointHost}${this.privRestPath}`;
      this.privRestAdapter.request(RestRequestType.Post, endpoint, queryParams, null).then((response) => {
        const requestId = RestMessageAdapter.extractHeaderValue(this.privRequestParams.requestId, response.headers);
        if (!response.ok) {
          if (!!err) {
            let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace("{status}", response.status.toString());
            let errMessageRaw;
            try {
              errMessageRaw = JSON.parse(response.data);
              errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;
            } catch (e) {
              errorMessage += ` [${response.data}]`;
            }
            if (requestId) {
              errorMessage += ` ${requestId}`;
            }
            err(errorMessage);
          }
          return;
        }
        const conversation = JSON.parse(response.data);
        if (conversation) {
          conversation.requestId = requestId;
        }
        if (!!cb) {
          try {
            cb(conversation);
          } catch (e) {
            if (!!err) {
              err(e);
            }
          }
          cb = void 0;
        }
      }).catch(() => {
      });
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
    }
  }
  /**
   * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.
   * @param args
   * @param sessionToken
   * @param callback
   */
  leave(args, sessionToken) {
    return new Promise((resolve, reject) => {
      try {
        Contracts.throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace("{arg}", "config"));
        Contracts.throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace("{arg}", "token"));
        const endpointHost = args.getProperty(PropertyId.ConversationTranslator_Host, this.privHost);
        const correlationId = args.getProperty(PropertyId.ConversationTranslator_CorrelationId);
        const queryParams = {};
        queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
        queryParams[this.privRequestParams.sessionToken] = sessionToken;
        const headers = {};
        if (correlationId) {
          headers[this.privRequestParams.correlationId] = correlationId;
        }
        const config = {};
        config.headers = headers;
        this.privRestAdapter.options = config;
        const endpoint = `https://${endpointHost}${this.privRestPath}`;
        this.privRestAdapter.request(RestRequestType.Delete, endpoint, queryParams, null).then((response) => {
          if (!response.ok) {
          }
          resolve();
        }).catch(() => {
        });
      } catch (error) {
        if (error instanceof Error) {
          const typedError = error;
          reject(typedError.name + ": " + typedError.message);
        } else {
          reject(error);
        }
      }
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js
var ConversationConnectionMessage = class extends ConnectionMessage {
  constructor(messageType, body, headers, id) {
    super(messageType, body, headers, id);
    const json = JSON.parse(this.textBody);
    if (json.type !== void 0) {
      this.privConversationMessageType = json.type;
    }
  }
  get conversationMessageType() {
    return this.privConversationMessageType;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js
var ConversationWebsocketMessageFormatter = class {
  /**
   * Format incoming messages: text (speech partial/final, IM) or binary (tts)
   */
  toConnectionMessage(message) {
    const deferral = new Deferred();
    try {
      if (message.messageType === MessageType.Text) {
        const incomingMessage = new ConversationConnectionMessage(message.messageType, message.textContent, {}, message.id);
        deferral.resolve(incomingMessage);
      } else if (message.messageType === MessageType.Binary) {
        deferral.resolve(new ConversationConnectionMessage(message.messageType, message.binaryContent, void 0, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. Error: ${e}`);
    }
    return deferral.promise;
  }
  /**
   * Format outgoing messages: text (commands or IM)
   */
  fromConnectionMessage(message) {
    const deferral = new Deferred();
    try {
      if (message.messageType === MessageType.Text) {
        const payload = `${message.textBody ? message.textBody : ""}`;
        deferral.resolve(new RawWebsocketMessage(MessageType.Text, payload, message.id));
      }
    } catch (e) {
      deferral.reject(`Error formatting the message. ${e}`);
    }
    return deferral.promise;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js
var ConversationConnectionFactory = class extends ConnectionFactoryBase {
  create(config, authInfo, connectionId) {
    const endpointHost = config.parameters.getProperty(PropertyId.ConversationTranslator_Host, ConversationConnectionConfig.host);
    const correlationId = config.parameters.getProperty(PropertyId.ConversationTranslator_CorrelationId, createGuid());
    const endpoint = `wss://${endpointHost}${ConversationConnectionConfig.webSocketPath}`;
    const token = config.parameters.getProperty(PropertyId.ConversationTranslator_Token, void 0);
    Contracts.throwIfNullOrUndefined(token, "token");
    const queryParams = {};
    queryParams[ConversationConnectionConfig.configParams.apiVersion] = ConversationConnectionConfig.apiVersion;
    queryParams[ConversationConnectionConfig.configParams.token] = token;
    queryParams[ConversationConnectionConfig.configParams.correlationId] = correlationId;
    const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
    return new WebsocketConnection(endpoint, queryParams, {}, new ConversationWebsocketMessageFormatter(), ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js
var __awaiter25 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var ConversationRequestSession = class {
  constructor(sessionId) {
    this.privIsDisposed = false;
    this.privDetachables = new Array();
    this.privSessionId = sessionId;
    this.privRequestId = createNoDashGuid();
    this.privRequestCompletionDeferral = new Deferred();
  }
  get sessionId() {
    return this.privSessionId;
  }
  get requestId() {
    return this.privRequestId;
  }
  get completionPromise() {
    return this.privRequestCompletionDeferral.promise;
  }
  onPreConnectionStart(authFetchEventId, connectionId) {
    this.privSessionId = connectionId;
  }
  onAuthCompleted(isError) {
    if (isError) {
      this.onComplete();
    }
  }
  onConnectionEstablishCompleted(statusCode) {
    if (statusCode === 200) {
      return;
    } else if (statusCode === 403) {
      this.onComplete();
    }
  }
  onServiceTurnEndResponse(continuousRecognition) {
    if (!continuousRecognition) {
      this.onComplete();
    } else {
      this.privRequestId = createNoDashGuid();
    }
  }
  dispose() {
    return __awaiter25(this, void 0, void 0, function* () {
      if (!this.privIsDisposed) {
        this.privIsDisposed = true;
        for (const detachable of this.privDetachables) {
          yield detachable.detach();
        }
      }
    });
  }
  onComplete() {
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js
var MuteAllEventArgs = class extends SessionEventArgs {
  constructor(isMuted, sessionId) {
    super(sessionId);
    this.privIsMuted = isMuted;
  }
  get isMuted() {
    return this.privIsMuted;
  }
};
var LockRoomEventArgs = class extends SessionEventArgs {
  constructor(isLocked, sessionId) {
    super(sessionId);
    this.privIsLocked = isLocked;
  }
  get isMuted() {
    return this.privIsLocked;
  }
};
var ParticipantEventArgs = class extends SessionEventArgs {
  constructor(participant, sessionId) {
    super(sessionId);
    this.privParticipant = participant;
  }
  get participant() {
    return this.privParticipant;
  }
};
var ParticipantAttributeEventArgs = class extends SessionEventArgs {
  constructor(participantId, key, value, sessionId) {
    super(sessionId);
    this.privKey = key;
    this.privValue = value;
    this.privParticipantId = participantId;
  }
  get value() {
    return this.privValue;
  }
  get key() {
    return this.privKey;
  }
  get id() {
    return this.privParticipantId;
  }
};
var ParticipantsListEventArgs = class extends SessionEventArgs {
  constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {
    super(sessionId);
    this.privRoomId = conversationId;
    this.privSessionToken = token;
    this.privTranslateTo = translateTo;
    this.privProfanityFilter = profanityFilter;
    this.privRoomProfanityFilter = roomProfanityFilter;
    this.privIsRoomLocked = isRoomLocked;
    this.privIsRoomLocked = isMuteAll;
    this.privParticipants = participants;
  }
  get sessionToken() {
    return this.privSessionToken;
  }
  get conversationId() {
    return this.privRoomId;
  }
  get translateTo() {
    return this.privTranslateTo;
  }
  get profanityFilter() {
    return this.privProfanityFilter;
  }
  get roomProfanityFilter() {
    return this.privRoomProfanityFilter;
  }
  get isRoomLocked() {
    return this.privIsRoomLocked;
  }
  get isMuteAll() {
    return this.privIsMuteAll;
  }
  get participants() {
    return this.privParticipants;
  }
};
var ConversationReceivedTranslationEventArgs = class {
  constructor(command, payload, sessionId) {
    this.privPayload = payload;
    this.privCommand = command;
    this.privSessionId = sessionId;
  }
  get payload() {
    return this.privPayload;
  }
  get command() {
    return this.privCommand;
  }
  get sessionId() {
    return this.privSessionId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js
var InternalParticipants = class {
  constructor(participants = [], meId) {
    this.participants = participants;
    this.meId = meId;
  }
  /**
   * Add or update a participant
   * @param value
   */
  addOrUpdateParticipant(value) {
    if (value === void 0) {
      return;
    }
    const exists = this.getParticipantIndex(value.id);
    if (exists > -1) {
      this.participants.splice(exists, 1, value);
    } else {
      this.participants.push(value);
    }
    return this.getParticipant(value.id);
  }
  /**
   * Find the participant's position in the participants list.
   * @param id
   */
  getParticipantIndex(id) {
    return this.participants.findIndex((p) => p.id === id);
  }
  /**
   * Find the participant by id.
   * @param id
   */
  getParticipant(id) {
    return this.participants.find((p) => p.id === id);
  }
  /**
   * Remove a participant from the participants list.
   */
  deleteParticipant(id) {
    this.participants = this.participants.filter((p) => p.id !== id);
  }
  /**
   * Helper to return the conversation host.
   */
  get host() {
    return this.participants.find((p) => p.isHost === true);
  }
  /**
   * Helper to return the current user.
   */
  get me() {
    return this.getParticipant(this.meId);
  }
};
var ConversationTranslatorMessageTypes = {
  command: "command",
  final: "final",
  info: "info",
  instantMessage: "instant_message",
  keepAlive: "keep_alive",
  partial: "partial",
  participantCommand: "participant_command",
  translatedMessage: "translated_message"
};
var ConversationTranslatorCommandTypes = {
  changeNickname: "ChangeNickname",
  disconnectSession: "DisconnectSession",
  ejectParticipant: "EjectParticipant",
  instant_message: "instant_message",
  joinSession: "JoinSession",
  leaveSession: "LeaveSession",
  participantList: "ParticipantList",
  roomExpirationWarning: "RoomExpirationWarning",
  setLockState: "SetLockState",
  setMute: "SetMute",
  setMuteAll: "SetMuteAll",
  setProfanityFiltering: "SetProfanityFiltering",
  setTranslateToLanguages: "SetTranslateToLanguages",
  setUseTTS: "SetUseTTS"
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js
var parseCommandResponse = (json) => JSON.parse(json);
var CommandResponsePayload = class {
  constructor(json) {
    this.privCommandResponse = parseCommandResponse(json);
  }
  get type() {
    return this.privCommandResponse.type;
  }
  get command() {
    return this.privCommandResponse.command;
  }
  get id() {
    return this.privCommandResponse.id;
  }
  get nickname() {
    return this.privCommandResponse.nickname;
  }
  get participantId() {
    return this.privCommandResponse.participantId;
  }
  get roomid() {
    return this.privCommandResponse.roomid;
  }
  get value() {
    return this.privCommandResponse.value;
  }
  get token() {
    return this.privCommandResponse.token;
  }
  static fromJSON(json) {
    return new CommandResponsePayload(json);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js
var parseListResponse = (json) => JSON.parse(json);
var parseParticipantResponse = (json) => JSON.parse(json);
var ParticipantsListPayloadResponse = class {
  constructor(json) {
    this.privParticipantsPayloadResponse = parseListResponse(json);
  }
  get roomid() {
    return this.privParticipantsPayloadResponse.roomid;
  }
  get id() {
    return this.privParticipantsPayloadResponse.id;
  }
  get command() {
    return this.privParticipantsPayloadResponse.command;
  }
  get participants() {
    return this.privParticipantsPayloadResponse.participants;
  }
  get token() {
    return this.privParticipantsPayloadResponse.token;
  }
  get translateTo() {
    return this.privParticipantsPayloadResponse.translateTo;
  }
  get profanityFilter() {
    return this.privParticipantsPayloadResponse.profanityFilter;
  }
  get roomProfanityFilter() {
    return this.privParticipantsPayloadResponse.roomProfanityFilter;
  }
  get roomLocked() {
    return this.privParticipantsPayloadResponse.roomLocked;
  }
  get muteAll() {
    return this.privParticipantsPayloadResponse.muteAll;
  }
  get type() {
    return this.privParticipantsPayloadResponse.type;
  }
  static fromJSON(json) {
    return new ParticipantsListPayloadResponse(json);
  }
};
var ParticipantPayloadResponse = class {
  constructor(json) {
    this.privParticipantPayloadResponse = parseParticipantResponse(json);
  }
  get nickname() {
    return this.privParticipantPayloadResponse.nickname;
  }
  get locale() {
    return this.privParticipantPayloadResponse.locale;
  }
  get usetts() {
    return this.privParticipantPayloadResponse.usetts;
  }
  get ismuted() {
    return this.privParticipantPayloadResponse.ismuted;
  }
  get ishost() {
    return this.privParticipantPayloadResponse.ishost;
  }
  get participantId() {
    return this.privParticipantPayloadResponse.participantId;
  }
  get avatar() {
    return this.privParticipantPayloadResponse.avatar;
  }
  static fromJSON(json) {
    return new ParticipantPayloadResponse(json);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js
var parseSpeechResponse = (json) => JSON.parse(json);
var parseTextResponse = (json) => JSON.parse(json);
var SpeechResponsePayload = class {
  constructor(json) {
    this.privSpeechResponse = parseSpeechResponse(json);
  }
  get recognition() {
    return this.privSpeechResponse.recognition;
  }
  get translations() {
    return this.privSpeechResponse.translations;
  }
  get id() {
    return this.privSpeechResponse.id;
  }
  get language() {
    return this.privSpeechResponse.language;
  }
  get nickname() {
    return this.privSpeechResponse.nickname;
  }
  get participantId() {
    return this.privSpeechResponse.participantId;
  }
  get roomid() {
    return this.privSpeechResponse.roomid;
  }
  get timestamp() {
    return this.privSpeechResponse.timestamp;
  }
  get type() {
    return this.privSpeechResponse.type;
  }
  get isFinal() {
    return this.privSpeechResponse.type === "final";
  }
  static fromJSON(json) {
    return new SpeechResponsePayload(json);
  }
};
var TextResponsePayload = class {
  constructor(json) {
    this.privTextResponse = parseTextResponse(json);
  }
  get originalText() {
    return this.privTextResponse.originalText;
  }
  get translations() {
    return this.privTextResponse.translations;
  }
  get id() {
    return this.privTextResponse.id;
  }
  get language() {
    return this.privTextResponse.language;
  }
  get nickname() {
    return this.privTextResponse.nickname;
  }
  get participantId() {
    return this.privTextResponse.participantId;
  }
  get roomid() {
    return this.privTextResponse.roomid;
  }
  get timestamp() {
    return this.privTextResponse.timestamp;
  }
  get type() {
    return this.privTextResponse.type;
  }
  static fromJSON(json) {
    return new TextResponsePayload(json);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js
var __awaiter26 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var ConversationServiceAdapter = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);
    this.privConnectionConfigPromise = void 0;
    this.privLastPartialUtteranceId = "";
    this.privConversationServiceConnector = conversationServiceConnector;
    this.privConversationAuthentication = authentication;
    this.receiveMessageOverride = () => this.receiveConversationMessageOverride();
    this.recognizeOverride = () => this.noOp();
    this.postConnectImplOverride = (connection) => this.conversationConnectImpl(connection);
    this.configConnectionOverride = () => this.configConnection();
    this.disconnectOverride = () => this.privDisconnect();
    this.privConversationRequestSession = new ConversationRequestSession(createNoDashGuid());
    this.privConversationConnectionFactory = connectionFactory;
    this.privConversationIsDisposed = false;
  }
  isDisposed() {
    return super.isDisposed() || this.privConversationIsDisposed;
  }
  dispose(reason) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter26(this, void 0, void 0, function* () {
      this.privConversationIsDisposed = true;
      if (this.privConnectionConfigPromise !== void 0) {
        const connection = yield this.privConnectionConfigPromise;
        yield connection.dispose(reason);
      }
      yield _super.dispose.call(this, reason);
    });
  }
  sendMessage(message) {
    return __awaiter26(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      return connection.send(new ConversationConnectionMessage(MessageType.Text, message));
    });
  }
  sendMessageAsync(message) {
    return __awaiter26(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      yield connection.send(new ConversationConnectionMessage(MessageType.Text, message));
    });
  }
  privDisconnect() {
    if (this.terminateMessageLoop) {
      return;
    }
    this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.NoError, "Disconnecting");
    this.terminateMessageLoop = true;
    return Promise.resolve();
  }
  // eslint-disable-next-line @typescript-eslint/require-await
  processTypeSpecificMessages() {
    return __awaiter26(this, void 0, void 0, function* () {
      return true;
    });
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    this.terminateMessageLoop = true;
    const cancelEvent = new ConversationTranslationCanceledEventArgs(cancellationReason, error, errorCode, void 0, sessionId);
    try {
      if (!!this.privConversationServiceConnector.canceled) {
        this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);
      }
    } catch (_a) {
    }
  }
  /**
   * Establishes a websocket connection to the end point.
   */
  conversationConnectImpl(connection) {
    return __awaiter26(this, void 0, void 0, function* () {
      this.privConnectionLoop = this.startMessageLoop();
      return connection;
    });
  }
  /**
   * Process incoming websocket messages
   */
  receiveConversationMessageOverride() {
    return __awaiter26(this, void 0, void 0, function* () {
      if (this.isDisposed() || this.terminateMessageLoop) {
        return Promise.resolve();
      }
      const communicationCustodian = new Deferred();
      try {
        const connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (this.isDisposed() || this.terminateMessageLoop) {
          communicationCustodian.resolve();
          return Promise.resolve();
        }
        if (!message) {
          return this.receiveConversationMessageOverride();
        }
        const sessionId = this.privConversationRequestSession.sessionId;
        let sendFinal = false;
        try {
          switch (message.conversationMessageType.toLowerCase()) {
            case "info":
            case "participant_command":
            case "command":
              const commandPayload = CommandResponsePayload.fromJSON(message.textBody);
              switch (commandPayload.command.toLowerCase()) {
                case "participantlist":
                  const participantsPayload = ParticipantsListPayloadResponse.fromJSON(message.textBody);
                  const participantsResult = participantsPayload.participants.map((p) => {
                    const participant = {
                      avatar: p.avatar,
                      displayName: p.nickname,
                      id: p.participantId,
                      isHost: p.ishost,
                      isMuted: p.ismuted,
                      isUsingTts: p.usetts,
                      preferredLanguage: p.locale
                    };
                    return participant;
                  });
                  if (!!this.privConversationServiceConnector.participantsListReceived) {
                    this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new ParticipantsListEventArgs(participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));
                  }
                  break;
                case "settranslatetolanguages":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorCommandTypes.setTranslateToLanguages, commandPayload.value, sessionId));
                  }
                  break;
                case "setprofanityfiltering":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorCommandTypes.setProfanityFiltering, commandPayload.value, sessionId));
                  }
                  break;
                case "setmute":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorCommandTypes.setMute, commandPayload.value, sessionId));
                  }
                  break;
                case "setmuteall":
                  if (!!this.privConversationServiceConnector.muteAllCommandReceived) {
                    this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new MuteAllEventArgs(commandPayload.value, sessionId));
                  }
                  break;
                case "roomexpirationwarning":
                  if (!!this.privConversationServiceConnector.conversationExpiration) {
                    this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new ConversationExpirationEventArgs(commandPayload.value, this.privConversationRequestSession.sessionId));
                  }
                  break;
                case "setusetts":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorCommandTypes.setUseTTS, commandPayload.value, sessionId));
                  }
                  break;
                case "setlockstate":
                  if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {
                    this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new LockRoomEventArgs(commandPayload.value, sessionId));
                  }
                  break;
                case "changenickname":
                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorCommandTypes.changeNickname, commandPayload.nickname, sessionId));
                  }
                  break;
                case "joinsession":
                  const joinParticipantPayload = ParticipantPayloadResponse.fromJSON(message.textBody);
                  const joiningParticipant = {
                    avatar: joinParticipantPayload.avatar,
                    displayName: joinParticipantPayload.nickname,
                    id: joinParticipantPayload.participantId,
                    isHost: joinParticipantPayload.ishost,
                    isMuted: joinParticipantPayload.ismuted,
                    isUsingTts: joinParticipantPayload.usetts,
                    preferredLanguage: joinParticipantPayload.locale
                  };
                  if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {
                    this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new ParticipantEventArgs(joiningParticipant, sessionId));
                  }
                  break;
                case "leavesession":
                  const leavingParticipant = {
                    id: commandPayload.participantId
                  };
                  if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {
                    this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new ParticipantEventArgs(leavingParticipant, sessionId));
                  }
                  break;
                case "disconnectsession":
                  const disconnectParticipant = {
                    id: commandPayload.participantId
                  };
                  break;
                case "token":
                  const token = new CognitiveTokenAuthentication(() => {
                    const authorizationToken = commandPayload.token;
                    return Promise.resolve(authorizationToken);
                  }, () => {
                    const authorizationToken = commandPayload.token;
                    return Promise.resolve(authorizationToken);
                  });
                  this.authentication = token;
                  break;
                default:
                  break;
              }
              break;
            case "partial":
            case "final":
              const speechPayload = SpeechResponsePayload.fromJSON(message.textBody);
              const speechResult = new ConversationTranslationResult(speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, void 0, void 0, speechPayload.recognition, void 0, void 0, message.textBody, void 0);
              if (speechPayload.isFinal) {
                if (speechResult.text !== void 0 && speechResult.text.length > 0) {
                  sendFinal = true;
                } else if (speechPayload.id === this.privLastPartialUtteranceId) {
                  sendFinal = true;
                } else {
                }
                if (sendFinal) {
                  if (!!this.privConversationServiceConnector.translationReceived) {
                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationReceivedTranslationEventArgs(ConversationTranslatorMessageTypes.final, speechResult, sessionId));
                  }
                }
              } else if (speechResult.text !== void 0) {
                this.privLastPartialUtteranceId = speechPayload.id;
                if (!!this.privConversationServiceConnector.translationReceived) {
                  this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationReceivedTranslationEventArgs(ConversationTranslatorMessageTypes.partial, speechResult, sessionId));
                }
              }
              break;
            case "translated_message":
              const textPayload = TextResponsePayload.fromJSON(message.textBody);
              const textResult = new ConversationTranslationResult(textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, void 0, void 0, textPayload.originalText, void 0, void 0, void 0, message.textBody, void 0);
              if (!!this.privConversationServiceConnector.translationReceived) {
                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationReceivedTranslationEventArgs(ConversationTranslatorMessageTypes.instantMessage, textResult, sessionId));
              }
              break;
            default:
              break;
          }
        } catch (e) {
        }
        return this.receiveConversationMessageOverride();
      } catch (e) {
        this.terminateMessageLoop = true;
      }
      return communicationCustodian.promise;
    });
  }
  startMessageLoop() {
    return __awaiter26(this, void 0, void 0, function* () {
      if (this.isDisposed()) {
        return Promise.resolve();
      }
      this.terminateMessageLoop = false;
      const messageRetrievalPromise = this.receiveConversationMessageOverride();
      try {
        const r = yield messageRetrievalPromise;
        return r;
      } catch (error) {
        this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : "", this.privRequestSession ? this.privRequestSession.requestId : "", CancellationReason.Error, CancellationErrorCode.RuntimeError, error);
        return null;
      }
    });
  }
  // Takes an established websocket connection to the endpoint
  configConnection() {
    if (this.isDisposed()) {
      return Promise.resolve(void 0);
    }
    if (this.privConnectionConfigPromise !== void 0) {
      return this.privConnectionConfigPromise.then((connection) => {
        if (connection.state() === ConnectionState.Disconnected) {
          this.privConnectionId = null;
          this.privConnectionConfigPromise = void 0;
          return this.configConnection();
        }
        return this.privConnectionConfigPromise;
      }, () => {
        this.privConnectionId = null;
        this.privConnectionConfigPromise = void 0;
        return this.configConnection();
      });
    }
    if (this.terminateMessageLoop) {
      return Promise.resolve(void 0);
    }
    this.privConnectionConfigPromise = this.connectImpl().then((connection) => connection);
    return this.privConnectionConfigPromise;
  }
  getTranslations(serviceResultTranslations) {
    let translations;
    if (void 0 !== serviceResultTranslations) {
      translations = new Translations();
      for (const translation of serviceResultTranslations) {
        translations.set(translation.lang, translation.translation);
      }
    }
    return translations;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js
var __awaiter27 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var ConversationRecognizerFactory = class {
  static fromConfig(conversation, speechConfig, audioConfig) {
    return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);
  }
};
var ConversationTranslatorRecognizer = class extends Recognizer {
  constructor(conversation, speechConfig, audioConfig) {
    const serviceConfigImpl = speechConfig;
    Contracts.throwIfNull(serviceConfigImpl, "speechConfig");
    const conversationImpl = conversation;
    Contracts.throwIfNull(conversationImpl, "conversationImpl");
    super(audioConfig, serviceConfigImpl.properties, new ConversationConnectionFactory());
    this.privConversation = conversationImpl;
    this.privIsDisposed = false;
    this.privProperties = serviceConfigImpl.properties.clone();
    this.privConnection = Connection.fromRecognizer(this);
    this.privSetTimeout = typeof Blob !== "undefined" && typeof Worker !== "undefined" ? Timeout.setTimeout : setTimeout;
    this.privClearTimeout = typeof Blob !== "undefined" && typeof Worker !== "undefined" ? Timeout.clearTimeout : clearTimeout;
  }
  set connected(cb) {
    this.privConnection.connected = cb;
  }
  set disconnected(cb) {
    this.privConnection.disconnected = cb;
  }
  /**
   * Return the speech language used by the recognizer
   */
  get speechRecognitionLanguage() {
    return this.privSpeechRecognitionLanguage;
  }
  /**
   * Return the properties for the recognizer
   */
  get properties() {
    return this.privProperties;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  /**
   * Connect to the recognizer
   * @param token
   */
  connect(token, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      Contracts.throwIfNullOrWhitespace(token, "token");
      this.privReco.conversationTranslatorToken = token;
      this.resetConversationTimeout();
      this.privReco.connectAsync(cb, err);
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
    }
  }
  /**
   * Disconnect from the recognizer
   */
  disconnect(cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      if (this.privTimeoutToken !== void 0) {
        this.privClearTimeout(this.privTimeoutToken);
      }
      this.privReco.disconnect().then(() => {
        if (!!cb) {
          cb();
        }
      }, (error) => {
        if (!!err) {
          err(error);
        }
      });
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
      this.dispose(true).catch((reason) => {
        Events.instance.onEvent(new BackgroundEvent(reason));
      });
    }
  }
  /**
   * Send the mute all participants command to the websocket
   * @param conversationId
   * @param participantId
   * @param isMuted
   */
  sendRequest(command, cb, err) {
    try {
      Contracts.throwIfDisposed(this.privIsDisposed);
      this.sendMessage(command, cb, err);
    } catch (error) {
      if (!!err) {
        if (error instanceof Error) {
          const typedError = error;
          err(typedError.name + ": " + typedError.message);
        } else {
          err(error);
        }
      }
      this.dispose(true).catch((reason) => {
        Events.instance.onEvent(new BackgroundEvent(reason));
      });
    }
  }
  /**
   * Close and dispose the recognizer
   */
  close() {
    return __awaiter27(this, void 0, void 0, function* () {
      if (!this.privIsDisposed) {
        if (!!this.privConnection) {
          this.privConnection.closeConnection();
          this.privConnection.close();
        }
        this.privConnection = void 0;
        yield this.dispose(true);
      }
    });
  }
  /**
   * Dispose the recognizer
   * @param disposing
   */
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter27(this, void 0, void 0, function* () {
      if (this.privIsDisposed) {
        return;
      }
      if (disposing) {
        if (this.privTimeoutToken !== void 0) {
          this.privClearTimeout(this.privTimeoutToken);
        }
        this.privIsDisposed = true;
        if (!!this.privConnection) {
          this.privConnection.closeConnection();
          this.privConnection.close();
          this.privConnection = void 0;
        }
        yield _super.dispose.call(this, disposing);
      }
    });
  }
  /**
   * Create the config for the recognizer
   * @param speechConfig
   */
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.privProperties);
  }
  /**
   * Create the service recognizer.
   * The audio source is redundnant here but is required by the implementation.
   * @param authentication
   * @param connectionFactory
   * @param audioConfig
   * @param recognizerConfig
   */
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const audioSource = audioConfig;
    return new ConversationServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);
  }
  sendMessage(msg, cb, err) {
    const withAsync = this.privReco;
    const PromiseToEmptyCallback = (promise, cb2, err2) => {
      if (promise !== void 0) {
        promise.then(() => {
          try {
            if (!!cb2) {
              cb2();
            }
          } catch (e) {
            if (!!err2) {
              err2(`'Unhandled error on promise callback: ${e}'`);
            }
          }
        }, (reason) => {
          try {
            if (!!err2) {
              err2(reason);
            }
          } catch (error) {
          }
        });
      } else {
        if (!!err2) {
          err2("Null promise");
        }
      }
    };
    PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);
    this.resetConversationTimeout();
  }
  resetConversationTimeout() {
    if (this.privTimeoutToken !== void 0) {
      this.privClearTimeout(this.privTimeoutToken);
    }
    this.privTimeoutToken = this.privSetTimeout(() => {
      this.sendRequest(this.privConversation.getKeepAlive());
    }, 6e4);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js
var __awaiter28 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var TranscriberRecognizer = class extends Recognizer {
  /**
   * TranscriberRecognizer constructor.
   * @constructor
   * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer
   * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer
   */
  constructor(speechTranslationConfig, audioConfig) {
    const speechTranslationConfigImpl = speechTranslationConfig;
    Contracts.throwIfNull(speechTranslationConfigImpl, "speechTranslationConfig");
    const audioConfigImpl = audioConfig;
    Contracts.throwIfNull(audioConfigImpl, "audioConfigImpl");
    Contracts.throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, PropertyId[PropertyId.SpeechServiceConnection_RecoLanguage]);
    super(audioConfig, speechTranslationConfigImpl.properties, new TranscriberConnectionFactory());
    this.privDisposedRecognizer = false;
  }
  get speechRecognitionLanguage() {
    Contracts.throwIfDisposed(this.privDisposedRecognizer);
    return this.properties.getProperty(PropertyId.SpeechServiceConnection_RecoLanguage);
  }
  get properties() {
    return this.privProperties;
  }
  get authorizationToken() {
    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);
  }
  set authorizationToken(token) {
    Contracts.throwIfNullOrWhitespace(token, "token");
    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);
  }
  set conversation(c) {
    Contracts.throwIfNullOrUndefined(c, "Conversation");
    this.privConversation = c;
  }
  getConversationInfo() {
    Contracts.throwIfNullOrUndefined(this.privConversation, "Conversation");
    return this.privConversation.conversationInfo;
  }
  startContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(RecognitionMode.Conversation), cb, err);
  }
  stopContinuousRecognitionAsync(cb, err) {
    marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);
  }
  close() {
    return __awaiter28(this, void 0, void 0, function* () {
      if (!this.privDisposedRecognizer) {
        yield this.dispose(true);
      }
    });
  }
  // Push async join/leave conversation message via serviceRecognizer
  pushConversationEvent(conversationInfo, command) {
    return __awaiter28(this, void 0, void 0, function* () {
      const reco = this.privReco;
      Contracts.throwIfNullOrUndefined(reco, "serviceRecognizer");
      yield reco.sendSpeechEventAsync(conversationInfo, command);
    });
  }
  enforceAudioGating() {
    return __awaiter28(this, void 0, void 0, function* () {
      const audioConfigImpl = this.audioConfig;
      const format = yield audioConfigImpl.format;
      const channels = format.channels;
      if (channels === 1) {
        if (this.properties.getProperty("f0f5debc-f8c9-4892-ac4b-90a7ab359fd2", "false").toLowerCase() !== "true") {
          throw new Error("Single channel audio configuration for ConversationTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details");
        }
      } else if (channels !== 8) {
        throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);
      }
      return;
    });
  }
  connectCallbacks(transcriber) {
    this.canceled = (s, e) => {
      if (!!transcriber.canceled) {
        transcriber.canceled(transcriber, e);
      }
    };
    this.recognizing = (s, e) => {
      if (!!transcriber.transcribing) {
        transcriber.transcribing(transcriber, e);
      }
    };
    this.recognized = (s, e) => {
      if (!!transcriber.transcribed) {
        transcriber.transcribed(transcriber, e);
      }
    };
    this.sessionStarted = (s, e) => {
      if (!!transcriber.sessionStarted) {
        transcriber.sessionStarted(transcriber, e);
      }
    };
    this.sessionStopped = (s, e) => {
      if (!!transcriber.sessionStopped) {
        transcriber.sessionStopped(transcriber, e);
      }
    };
  }
  disconnectCallbacks() {
    this.canceled = void 0;
    this.recognizing = void 0;
    this.recognized = void 0;
    this.sessionStarted = void 0;
    this.sessionStopped = void 0;
  }
  /**
   * Disposes any resources held by the object.
   * @member ConversationTranscriber.prototype.dispose
   * @function
   * @public
   * @param {boolean} disposing - true if disposing the object.
   */
  dispose(disposing) {
    const _super = Object.create(null, {
      dispose: { get: () => super.dispose }
    });
    return __awaiter28(this, void 0, void 0, function* () {
      if (this.privDisposedRecognizer) {
        return;
      }
      if (disposing) {
        this.privDisposedRecognizer = true;
        yield this.implRecognizerStop();
      }
      yield _super.dispose.call(this, disposing);
    });
  }
  createRecognizerConfig(speechConfig) {
    return new RecognizerConfig(speechConfig, this.properties);
  }
  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
    const configImpl = audioConfig;
    return new TranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js
var MetadataType;
(function(MetadataType2) {
  MetadataType2["WordBoundary"] = "WordBoundary";
  MetadataType2["Bookmark"] = "Bookmark";
  MetadataType2["Viseme"] = "Viseme";
  MetadataType2["SentenceBoundary"] = "SentenceBoundary";
  MetadataType2["SessionEnd"] = "SessionEnd";
})(MetadataType || (MetadataType = {}));
var SynthesisAudioMetadata = class {
  constructor(json) {
    this.privSynthesisAudioMetadata = JSON.parse(json);
  }
  static fromJSON(json) {
    return new SynthesisAudioMetadata(json);
  }
  get Metadata() {
    return this.privSynthesisAudioMetadata.Metadata;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js
var __awaiter29 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SynthesisAdapterBase = class {
  constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {
    this.speakOverride = void 0;
    this.receiveMessageOverride = void 0;
    this.connectImplOverride = void 0;
    this.configConnectionOverride = void 0;
    this.privConnectionConfigurationPromise = void 0;
    if (!authentication) {
      throw new ArgumentNullError("authentication");
    }
    if (!connectionFactory) {
      throw new ArgumentNullError("connectionFactory");
    }
    if (!synthesizerConfig) {
      throw new ArgumentNullError("synthesizerConfig");
    }
    this.privAuthentication = authentication;
    this.privConnectionFactory = connectionFactory;
    this.privSynthesizerConfig = synthesizerConfig;
    this.privIsDisposed = false;
    this.privSpeechSynthesizer = speechSynthesizer;
    this.privSessionAudioDestination = audioDestination;
    this.privSynthesisTurn = new SynthesisTurn();
    this.privConnectionEvents = new EventSource();
    this.privServiceEvents = new EventSource();
    this.privSynthesisContext = new SynthesisContext(this.privSpeechSynthesizer);
    this.privAgentConfig = new AgentConfig();
    this.connectionEvents.attach((connectionEvent) => {
      if (connectionEvent.name === "ConnectionClosedEvent") {
        const connectionClosedEvent = connectionEvent;
        if (connectionClosedEvent.statusCode !== 1e3) {
          this.cancelSynthesisLocal(CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? CancellationErrorCode.BadRequestParameters : CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);
        }
      }
    });
  }
  get synthesisContext() {
    return this.privSynthesisContext;
  }
  get agentConfig() {
    return this.privAgentConfig;
  }
  get connectionEvents() {
    return this.privConnectionEvents;
  }
  get serviceEvents() {
    return this.privServiceEvents;
  }
  set activityTemplate(messagePayload) {
    this.privActivityTemplate = messagePayload;
  }
  get activityTemplate() {
    return this.privActivityTemplate;
  }
  set audioOutputFormat(format) {
    this.privAudioOutputFormat = format;
    this.privSynthesisTurn.audioOutputFormat = format;
    if (this.privSessionAudioDestination !== void 0) {
      this.privSessionAudioDestination.format = format;
    }
    if (this.synthesisContext !== void 0) {
      this.synthesisContext.audioOutputFormat = format;
    }
  }
  static addHeader(audio, format) {
    if (!format.hasHeader) {
      return audio;
    }
    format.updateHeader(audio.byteLength);
    const tmp = new Uint8Array(audio.byteLength + format.header.byteLength);
    tmp.set(new Uint8Array(format.header), 0);
    tmp.set(new Uint8Array(audio), format.header.byteLength);
    return tmp.buffer;
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  dispose(reason) {
    return __awaiter29(this, void 0, void 0, function* () {
      this.privIsDisposed = true;
      if (this.privSessionAudioDestination !== void 0) {
        this.privSessionAudioDestination.close();
      }
      if (this.privConnectionConfigurationPromise !== void 0) {
        const connection = yield this.privConnectionConfigurationPromise;
        yield connection.dispose(reason);
      }
    });
  }
  connect() {
    return __awaiter29(this, void 0, void 0, function* () {
      yield this.connectImpl();
    });
  }
  sendNetworkMessage(path, payload) {
    return __awaiter29(this, void 0, void 0, function* () {
      const type2 = typeof payload === "string" ? MessageType.Text : MessageType.Binary;
      const contentType = typeof payload === "string" ? "application/json" : "";
      const connection = yield this.fetchConnection();
      return connection.send(new SpeechConnectionMessage(type2, path, this.privSynthesisTurn.requestId, contentType, payload));
    });
  }
  Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {
    return __awaiter29(this, void 0, void 0, function* () {
      let ssml;
      if (isSSML) {
        ssml = text;
      } else {
        ssml = this.privSpeechSynthesizer.buildSsml(text);
      }
      if (this.speakOverride !== void 0) {
        return this.speakOverride(ssml, requestId, successCallback, errorCallBack);
      }
      this.privSuccessCallback = successCallback;
      this.privErrorCallback = errorCallBack;
      this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);
      try {
        yield this.connectImpl();
        const connection = yield this.fetchConnection();
        yield this.sendSynthesisContext(connection);
        yield this.sendSsmlMessage(connection, ssml, requestId);
        const synthesisStartEventArgs = new SpeechSynthesisEventArgs(new SpeechSynthesisResult(requestId, ResultReason.SynthesizingAudioStarted));
        if (!!this.privSpeechSynthesizer.synthesisStarted) {
          this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);
        }
        void this.receiveMessage();
      } catch (e) {
        this.cancelSynthesisLocal(CancellationReason.Error, CancellationErrorCode.ConnectionFailure, e);
        return Promise.reject(e);
      }
    });
  }
  // Cancels synthesis.
  cancelSynthesis(requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    const result = new SpeechSynthesisResult(requestId, ResultReason.Canceled, void 0, error, properties);
    if (!!this.privSpeechSynthesizer.SynthesisCanceled) {
      const cancelEvent = new SpeechSynthesisEventArgs(result);
      try {
        this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);
      } catch (_a) {
      }
    }
    if (!!this.privSuccessCallback) {
      try {
        this.privSuccessCallback(result);
      } catch (_b) {
      }
    }
  }
  // Cancels synthesis.
  cancelSynthesisLocal(cancellationReason, errorCode, error) {
    if (!!this.privSynthesisTurn.isSynthesizing) {
      this.privSynthesisTurn.onStopSynthesizing();
      this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);
    }
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  processTypeSpecificMessages(connectionMessage) {
    return true;
  }
  receiveMessage() {
    return __awaiter29(this, void 0, void 0, function* () {
      try {
        const connection = yield this.fetchConnection();
        const message = yield connection.read();
        if (this.receiveMessageOverride !== void 0) {
          return this.receiveMessageOverride();
        }
        if (this.privIsDisposed) {
          return;
        }
        if (!message) {
          if (!this.privSynthesisTurn.isSynthesizing) {
            return;
          } else {
            return this.receiveMessage();
          }
        }
        const connectionMessage = SpeechConnectionMessage.fromConnectionMessage(message);
        if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {
          switch (connectionMessage.path.toLowerCase()) {
            case "turn.start":
              this.privSynthesisTurn.onServiceTurnStartResponse();
              break;
            case "response":
              this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);
              break;
            case "audio":
              if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase() && !!connectionMessage.binaryBody) {
                this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);
                if (!!this.privSpeechSynthesizer.synthesizing) {
                  try {
                    const audioWithHeader = SynthesisAdapterBase.addHeader(connectionMessage.binaryBody, this.privSynthesisTurn.audioOutputFormat);
                    const ev = new SpeechSynthesisEventArgs(new SpeechSynthesisResult(this.privSynthesisTurn.requestId, ResultReason.SynthesizingAudio, audioWithHeader));
                    this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);
                  } catch (error) {
                  }
                }
                if (this.privSessionAudioDestination !== void 0) {
                  this.privSessionAudioDestination.write(connectionMessage.binaryBody);
                }
              }
              break;
            case "audio.metadata":
              const metadataList = SynthesisAudioMetadata.fromJSON(connectionMessage.textBody).Metadata;
              for (const metadata of metadataList) {
                switch (metadata.Type) {
                  case MetadataType.WordBoundary:
                  case MetadataType.SentenceBoundary:
                    this.privSynthesisTurn.onTextBoundaryEvent(metadata);
                    const wordBoundaryEventArgs = new SpeechSynthesisWordBoundaryEventArgs(metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === MetadataType.WordBoundary ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);
                    if (!!this.privSpeechSynthesizer.wordBoundary) {
                      try {
                        this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);
                      } catch (error) {
                      }
                    }
                    break;
                  case MetadataType.Bookmark:
                    const bookmarkEventArgs = new SpeechSynthesisBookmarkEventArgs(metadata.Data.Offset, metadata.Data.Bookmark);
                    if (!!this.privSpeechSynthesizer.bookmarkReached) {
                      try {
                        this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);
                      } catch (error) {
                      }
                    }
                    break;
                  case MetadataType.Viseme:
                    this.privSynthesisTurn.onVisemeMetadataReceived(metadata);
                    if (metadata.Data.IsLastAnimation) {
                      const visemeEventArgs = new SpeechSynthesisVisemeEventArgs(metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());
                      if (!!this.privSpeechSynthesizer.visemeReceived) {
                        try {
                          this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);
                        } catch (error) {
                        }
                      }
                    }
                    break;
                  case MetadataType.SessionEnd:
                    this.privSynthesisTurn.onSessionEnd(metadata);
                    break;
                }
              }
              break;
            case "turn.end":
              this.privSynthesisTurn.onServiceTurnEndResponse();
              let result;
              try {
                const audioBuffer = yield this.privSynthesisTurn.getAllReceivedAudioWithHeader();
                result = new SpeechSynthesisResult(this.privSynthesisTurn.requestId, ResultReason.SynthesizingAudioCompleted, audioBuffer, void 0, void 0, this.privSynthesisTurn.audioDuration);
                if (!!this.privSuccessCallback) {
                  this.privSuccessCallback(result);
                }
              } catch (error) {
                if (!!this.privErrorCallback) {
                  this.privErrorCallback(error);
                }
              }
              if (this.privSpeechSynthesizer.synthesisCompleted) {
                try {
                  this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new SpeechSynthesisEventArgs(result));
                } catch (e) {
                }
              }
              break;
            default:
              if (!this.processTypeSpecificMessages(connectionMessage)) {
                if (!!this.privServiceEvents) {
                  this.serviceEvents.onEvent(new ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                }
              }
          }
        }
        return this.receiveMessage();
      } catch (e) {
      }
    });
  }
  sendSynthesisContext(connection) {
    const synthesisContextJson = this.synthesisContext.toJSON();
    if (synthesisContextJson) {
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "synthesis.context", this.privSynthesisTurn.requestId, "application/json", synthesisContextJson));
    }
    return;
  }
  connectImpl(isUnAuthorized = false) {
    if (this.privConnectionPromise != null) {
      return this.privConnectionPromise.then((connection) => {
        if (connection.state() === ConnectionState.Disconnected) {
          this.privConnectionId = null;
          this.privConnectionPromise = null;
          return this.connectImpl();
        }
        return this.privConnectionPromise;
      }, () => {
        this.privConnectionId = null;
        this.privConnectionPromise = null;
        return this.connectImpl();
      });
    }
    this.privAuthFetchEventId = createNoDashGuid();
    this.privConnectionId = createNoDashGuid();
    this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);
    const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
    this.privConnectionPromise = authPromise.then((result) => __awaiter29(this, void 0, void 0, function* () {
      this.privSynthesisTurn.onAuthCompleted(false);
      const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);
      connection.events.attach((event) => {
        this.connectionEvents.onEvent(event);
      });
      const response = yield connection.open();
      if (response.statusCode === 200) {
        this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
        return Promise.resolve(connection);
      } else if (response.statusCode === 403 && !isUnAuthorized) {
        return this.connectImpl(true);
      } else {
        this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
        return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode}, ${this.privSynthesizerConfig.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${response.reason}`);
      }
    }), (error) => {
      this.privSynthesisTurn.onAuthCompleted(true);
      throw new Error(error);
    });
    this.privConnectionPromise.catch(() => {
    });
    return this.privConnectionPromise;
  }
  sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {
    if (SpeechServiceConfigJson) {
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speech.config", this.privSynthesisTurn.requestId, "application/json", SpeechServiceConfigJson));
    }
  }
  sendSsmlMessage(connection, ssml, requestId) {
    return connection.send(new SpeechConnectionMessage(MessageType.Text, "ssml", requestId, "application/ssml+xml", ssml));
  }
  fetchConnection() {
    return __awaiter29(this, void 0, void 0, function* () {
      if (this.privConnectionConfigurationPromise !== void 0) {
        return this.privConnectionConfigurationPromise.then((connection) => {
          if (connection.state() === ConnectionState.Disconnected) {
            this.privConnectionId = null;
            this.privConnectionConfigurationPromise = void 0;
            return this.fetchConnection();
          }
          return this.privConnectionConfigurationPromise;
        }, () => {
          this.privConnectionId = null;
          this.privConnectionConfigurationPromise = void 0;
          return this.fetchConnection();
        });
      }
      this.privConnectionConfigurationPromise = this.configureConnection();
      return yield this.privConnectionConfigurationPromise;
    });
  }
  // Takes an established websocket connection to the endpoint and sends speech configuration information.
  configureConnection() {
    return __awaiter29(this, void 0, void 0, function* () {
      const connection = yield this.connectImpl();
      if (this.configConnectionOverride !== void 0) {
        return this.configConnectionOverride(connection);
      }
      yield this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());
      return connection;
    });
  }
};
SynthesisAdapterBase.telemetryDataEnabled = true;

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js
var SpeechSynthesisEvent = class extends PlatformEvent {
  constructor(eventName, requestId, eventType = EventType.Info) {
    super(eventName, eventType);
    this.privRequestId = requestId;
  }
  get requestId() {
    return this.privRequestId;
  }
};
var SynthesisTriggeredEvent = class extends SpeechSynthesisEvent {
  constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {
    super("SynthesisTriggeredEvent", requestId);
    this.privSessionAudioDestinationId = sessionAudioDestinationId;
    this.privTurnAudioDestinationId = turnAudioDestinationId;
  }
  get audioSessionDestinationId() {
    return this.privSessionAudioDestinationId;
  }
  get audioTurnDestinationId() {
    return this.privTurnAudioDestinationId;
  }
};
var ConnectingToSynthesisServiceEvent = class extends SpeechSynthesisEvent {
  constructor(requestId, authFetchEventId) {
    super("ConnectingToSynthesisServiceEvent", requestId);
    this.privAuthFetchEventId = authFetchEventId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
};
var SynthesisStartedEvent = class extends SpeechSynthesisEvent {
  constructor(requestId, authFetchEventId) {
    super("SynthesisStartedEvent", requestId);
    this.privAuthFetchEventId = authFetchEventId;
  }
  get authFetchEventId() {
    return this.privAuthFetchEventId;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js
var __awaiter30 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SynthesisTurn = class {
  constructor() {
    this.privIsDisposed = false;
    this.privIsSynthesizing = false;
    this.privIsSynthesisEnded = false;
    this.privBytesReceived = 0;
    this.privInTurn = false;
    this.privTextOffset = 0;
    this.privNextSearchTextIndex = 0;
    this.privSentenceOffset = 0;
    this.privNextSearchSentenceIndex = 0;
    this.privRequestId = createNoDashGuid();
    this.privTurnDeferral = new Deferred();
    this.privTurnDeferral.resolve();
  }
  get requestId() {
    return this.privRequestId;
  }
  get streamId() {
    return this.privStreamId;
  }
  set streamId(value) {
    this.privStreamId = value;
  }
  get audioOutputFormat() {
    return this.privAudioOutputFormat;
  }
  set audioOutputFormat(format) {
    this.privAudioOutputFormat = format;
  }
  get turnCompletionPromise() {
    return this.privTurnDeferral.promise;
  }
  get isSynthesisEnded() {
    return this.privIsSynthesisEnded;
  }
  get isSynthesizing() {
    return this.privIsSynthesizing;
  }
  get currentTextOffset() {
    return this.privTextOffset;
  }
  get currentSentenceOffset() {
    return this.privSentenceOffset;
  }
  // The number of bytes received for current turn
  get bytesReceived() {
    return this.privBytesReceived;
  }
  get audioDuration() {
    return this.privAudioDuration;
  }
  getAllReceivedAudio() {
    return __awaiter30(this, void 0, void 0, function* () {
      if (!!this.privReceivedAudio) {
        return Promise.resolve(this.privReceivedAudio);
      }
      if (!this.privIsSynthesisEnded) {
        return null;
      }
      yield this.readAllAudioFromStream();
      return Promise.resolve(this.privReceivedAudio);
    });
  }
  getAllReceivedAudioWithHeader() {
    return __awaiter30(this, void 0, void 0, function* () {
      if (!!this.privReceivedAudioWithHeader) {
        return this.privReceivedAudioWithHeader;
      }
      if (!this.privIsSynthesisEnded) {
        return null;
      }
      if (this.audioOutputFormat.hasHeader) {
        const audio = yield this.getAllReceivedAudio();
        this.privReceivedAudioWithHeader = SynthesisAdapterBase.addHeader(audio, this.audioOutputFormat);
        return this.privReceivedAudioWithHeader;
      } else {
        return this.getAllReceivedAudio();
      }
    });
  }
  startNewSynthesis(requestId, rawText, isSSML, audioDestination) {
    this.privIsSynthesisEnded = false;
    this.privIsSynthesizing = true;
    this.privRequestId = requestId;
    this.privRawText = rawText;
    this.privIsSSML = isSSML;
    this.privAudioOutputStream = new PullAudioOutputStreamImpl();
    this.privAudioOutputStream.format = this.privAudioOutputFormat;
    this.privReceivedAudio = null;
    this.privReceivedAudioWithHeader = null;
    this.privBytesReceived = 0;
    this.privTextOffset = 0;
    this.privNextSearchTextIndex = 0;
    this.privSentenceOffset = 0;
    this.privNextSearchSentenceIndex = 0;
    this.privPartialVisemeAnimation = "";
    if (audioDestination !== void 0) {
      this.privTurnAudioDestination = audioDestination;
      this.privTurnAudioDestination.format = this.privAudioOutputFormat;
    }
    this.onEvent(new SynthesisTriggeredEvent(this.requestId, void 0, audioDestination === void 0 ? void 0 : audioDestination.id()));
  }
  onPreConnectionStart(authFetchEventId) {
    this.privAuthFetchEventId = authFetchEventId;
    this.onEvent(new ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));
  }
  onAuthCompleted(isError) {
    if (isError) {
      this.onComplete();
    }
  }
  onConnectionEstablishCompleted(statusCode) {
    if (statusCode === 200) {
      this.onEvent(new SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));
      this.privBytesReceived = 0;
      return;
    } else if (statusCode === 403) {
      this.onComplete();
    }
  }
  onServiceResponseMessage(responseJson) {
    const response = JSON.parse(responseJson);
    this.streamId = response.audio.streamId;
  }
  onServiceTurnEndResponse() {
    this.privInTurn = false;
    this.privTurnDeferral.resolve();
    this.onComplete();
  }
  onServiceTurnStartResponse() {
    if (!!this.privTurnDeferral && !!this.privInTurn) {
      this.privTurnDeferral.reject("Another turn started before current completed.");
      this.privTurnDeferral.promise.then().catch(() => {
      });
    }
    this.privInTurn = true;
    this.privTurnDeferral = new Deferred();
  }
  onAudioChunkReceived(data) {
    if (this.isSynthesizing) {
      this.privAudioOutputStream.write(data);
      this.privBytesReceived += data.byteLength;
      if (this.privTurnAudioDestination !== void 0) {
        this.privTurnAudioDestination.write(data);
      }
    }
  }
  onTextBoundaryEvent(metadata) {
    this.updateTextOffset(metadata.Data.text.Text, metadata.Type);
  }
  onVisemeMetadataReceived(metadata) {
    if (metadata.Data.AnimationChunk !== void 0) {
      this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;
    }
  }
  onSessionEnd(metadata) {
    this.privAudioDuration = metadata.Data.Offset;
  }
  dispose() {
    if (!this.privIsDisposed) {
      this.privIsDisposed = true;
    }
  }
  onStopSynthesizing() {
    this.onComplete();
  }
  /**
   * Gets the viseme animation string (merged from animation chunk), and clears the internal
   * partial animation.
   */
  getAndClearVisemeAnimation() {
    const animation = this.privPartialVisemeAnimation;
    this.privPartialVisemeAnimation = "";
    return animation;
  }
  onEvent(event) {
    Events.instance.onEvent(event);
  }
  /**
   * Check if the text is an XML(SSML) tag
   * @param text
   * @private
   */
  static isXmlTag(text) {
    return text.length >= 2 && text[0] === "<" && text[text.length - 1] === ">";
  }
  updateTextOffset(text, type2) {
    if (type2 === MetadataType.WordBoundary) {
      this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);
      if (this.privTextOffset >= 0) {
        this.privNextSearchTextIndex = this.privTextOffset + text.length;
        if (this.privIsSSML) {
          if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {
            this.updateTextOffset(text, type2);
          }
        }
      }
    } else {
      this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);
      if (this.privSentenceOffset >= 0) {
        this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;
        if (this.privIsSSML) {
          if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {
            this.updateTextOffset(text, type2);
          }
        }
      }
    }
  }
  onComplete() {
    if (this.privIsSynthesizing) {
      this.privIsSynthesizing = false;
      this.privIsSynthesisEnded = true;
      this.privAudioOutputStream.close();
      this.privInTurn = false;
      if (this.privTurnAudioDestination !== void 0) {
        this.privTurnAudioDestination.close();
        this.privTurnAudioDestination = void 0;
      }
    }
  }
  readAllAudioFromStream() {
    return __awaiter30(this, void 0, void 0, function* () {
      if (this.privIsSynthesisEnded) {
        this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);
        try {
          yield this.privAudioOutputStream.read(this.privReceivedAudio);
        } catch (e) {
          this.privReceivedAudio = new ArrayBuffer(0);
        }
      }
    });
  }
  /**
   * Check if current idx is in XML(SSML) tag
   * @param idx
   * @private
   */
  withinXmlTag(idx) {
    return this.privRawText.indexOf("<", idx + 1) > this.privRawText.indexOf(">", idx + 1);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js
var SynthesisRestAdapter = class {
  constructor(config, authentication) {
    let endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Endpoint, void 0);
    if (!endpoint) {
      const region = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Region, "westus");
      const hostSuffix = ConnectionFactoryBase.getHostSuffix(region);
      endpoint = config.parameters.getProperty(PropertyId.SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);
    }
    this.privUri = `${endpoint}/cognitiveservices/voices/list`;
    const options = RestConfigBase.requestOptions;
    this.privRestAdapter = new RestMessageAdapter(options);
    this.privAuthentication = authentication;
  }
  /**
   * Sends list voices request to endpoint.
   * @function
   * @public
   * @param connectionId - guid for connectionId
   * @returns {Promise<IRestResponse>} rest response to status request
   */
  getVoicesList(connectionId) {
    this.privRestAdapter.setHeaders(HeaderNames.ConnectionId, connectionId);
    return this.privAuthentication.fetch(connectionId).then((authInfo) => {
      this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);
      return this.privRestAdapter.request(RestRequestType.Get, this.privUri);
    });
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js
var SynthesisServiceType;
(function(SynthesisServiceType2) {
  SynthesisServiceType2[SynthesisServiceType2["Standard"] = 0] = "Standard";
  SynthesisServiceType2[SynthesisServiceType2["Custom"] = 1] = "Custom";
})(SynthesisServiceType || (SynthesisServiceType = {}));
var SynthesizerConfig = class {
  constructor(speechServiceConfig, parameters) {
    this.privSynthesisServiceType = SynthesisServiceType.Standard;
    this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));
    this.privParameters = parameters;
  }
  get parameters() {
    return this.privParameters;
  }
  get synthesisServiceType() {
    return this.privSynthesisServiceType;
  }
  set synthesisServiceType(value) {
    this.privSynthesisServiceType = value;
  }
  get SpeechServiceConfig() {
    return this.privSpeechServiceConfig;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js
var SynthesisContext = class {
  constructor(speechSynthesizer) {
    this.privContext = {};
    this.privSpeechSynthesizer = speechSynthesizer;
  }
  /**
   * Adds a section to the synthesis.context object.
   * @param sectionName Name of the section to add.
   * @param value JSON serializable object that represents the value.
   */
  setSection(sectionName, value) {
    this.privContext[sectionName] = value;
  }
  /**
   * Sets the audio output format for synthesis context generation.
   * @param format {AudioOutputFormatImpl} the output format
   */
  set audioOutputFormat(format) {
    this.privAudioOutputFormat = format;
  }
  toJSON() {
    const synthesisSection = this.buildSynthesisContext();
    this.setSection("synthesis", synthesisSection);
    return JSON.stringify(this.privContext);
  }
  buildSynthesisContext() {
    return {
      audio: {
        metadataOptions: {
          bookmarkEnabled: !!this.privSpeechSynthesizer.bookmarkReached,
          punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, !!this.privSpeechSynthesizer.wordBoundary),
          sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),
          sessionEndEnabled: true,
          visemeEnabled: !!this.privSpeechSynthesizer.visemeReceived,
          wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(PropertyId.SpeechServiceResponse_RequestWordBoundary, !!this.privSpeechSynthesizer.wordBoundary)
        },
        outputFormat: this.privAudioOutputFormat.requestAudioFormatString
      },
      language: {
        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage
      }
    };
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerServiceRecognizer.js
var __awaiter31 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var SpeakerServiceRecognizer = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.privSpeakerRecognizer = recognizer;
    this.privSpeakerAudioSource = audioSource;
    this.recognizeSpeaker = (model) => this.recognizeSpeakerOnce(model);
    this.sendPrePayloadJSONOverride = () => this.noOp();
  }
  processTypeSpecificMessages(connectionMessage) {
    let processed = false;
    const resultProps = new PropertyCollection();
    if (connectionMessage.messageType === MessageType.Text) {
      resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    switch (connectionMessage.path.toLowerCase()) {
      case "speaker.response":
        const response = JSON.parse(connectionMessage.textBody);
        let result;
        if (response.status.statusCode.toLowerCase() !== "success") {
          result = new SpeakerRecognitionResult(response, ResultReason.Canceled, CancellationErrorCode.ServiceError, response.status.reason);
        } else {
          result = new SpeakerRecognitionResult(response, ResultReason.RecognizedSpeaker);
        }
        if (!!this.privResultDeferral) {
          this.privResultDeferral.resolve(result);
        }
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    if (!!this.privResultDeferral) {
      const result = new SpeakerRecognitionResult({
        scenario: this.privSpeakerModel.scenario,
        status: { statusCode: error, reason: error }
      }, ResultReason.Canceled, errorCode, error);
      try {
        this.privResultDeferral.resolve(result);
      } catch (error2) {
        this.privResultDeferral.reject(error2);
      }
    }
  }
  recognizeSpeakerOnce(model) {
    return __awaiter31(this, void 0, void 0, function* () {
      this.privSpeakerModel = model;
      this.voiceProfileType = model.scenario;
      if (!this.privResultDeferral) {
        this.privResultDeferral = new Deferred();
      }
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);
      this.privRecognizerConfig.parameters.setProperty(PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
      const conPromise = this.connectImpl();
      const preAudioPromise = this.sendPreAudioMessages(this.extractSpeakerContext(model));
      const node = yield this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);
      const format = yield this.privSpeakerAudioSource.format;
      const deviceInfo = yield this.privSpeakerAudioSource.deviceInfo;
      const audioNode = new ReplayableAudioNode(node, format.avgBytesPerSec);
      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
      try {
        yield conPromise;
        yield preAudioPromise;
      } catch (err) {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.ConnectionFailure, err);
      }
      const sessionStartEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      void this.receiveMessage();
      const audioSendPromise = this.sendAudio(audioNode);
      audioSendPromise.then(() => {
      }, (error) => {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.RuntimeError, error);
      });
      return this.privResultDeferral.promise;
    });
  }
  sendPreAudioMessages(context) {
    return __awaiter31(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      yield this.sendSpeakerRecognition(connection, context);
    });
  }
  sendSpeakerRecognition(connection, context) {
    return __awaiter31(this, void 0, void 0, function* () {
      const speakerContextJson = JSON.stringify(context);
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speaker.context", this.privRequestSession.requestId, "application/json; charset=utf-8", speakerContextJson));
    });
  }
  extractSpeakerContext(model) {
    return {
      features: {
        interimResult: "enabled",
        progressiveDetection: "disabled"
      },
      profileIds: model.profileIds,
      scenario: model.scenario
    };
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/VoiceServiceRecognizer.js
var __awaiter32 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var VoiceServiceRecognizer = class extends ServiceRecognizerBase {
  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
    this.privDeferralMap = new DeferralMap();
    this.privSpeakerAudioSource = audioSource;
    this.sendPrePayloadJSONOverride = () => this.noOp();
  }
  set SpeakerAudioSource(audioSource) {
    this.privSpeakerAudioSource = audioSource;
  }
  processTypeSpecificMessages(connectionMessage) {
    let processed = false;
    const resultProps = new PropertyCollection();
    if (connectionMessage.messageType === MessageType.Text) {
      resultProps.setProperty(PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
    }
    switch (connectionMessage.path.toLowerCase()) {
      case "speaker.profiles":
        const response = JSON.parse(connectionMessage.textBody);
        switch (response.operation.toLowerCase()) {
          case "create":
            this.handleCreateResponse(response, connectionMessage.requestId);
            break;
          case "delete":
          case "reset":
            this.handleResultResponse(response, connectionMessage.requestId);
            break;
          case "fetch":
            const enrollmentResponse2 = JSON.parse(connectionMessage.textBody);
            this.handleFetchResponse(enrollmentResponse2, connectionMessage.requestId);
            break;
          default:
            break;
        }
        processed = true;
        break;
      case "speaker.phrases":
        const phraseResponse = JSON.parse(connectionMessage.textBody);
        this.handlePhrasesResponse(phraseResponse, connectionMessage.requestId);
        processed = true;
        break;
      case "speaker.profile.enrollment":
        const enrollmentResponse = JSON.parse(connectionMessage.textBody);
        const result = new VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(!!enrollmentResponse.enrollment ? enrollmentResponse.enrollment.enrollmentStatus : enrollmentResponse.status.statusCode), !!enrollmentResponse.enrollment ? JSON.stringify(enrollmentResponse.enrollment) : void 0, enrollmentResponse.status.reason);
        if (!!this.privDeferralMap.getId(connectionMessage.requestId)) {
          this.privDeferralMap.complete(connectionMessage.requestId, result);
        }
        this.privRequestSession.onSpeechEnded();
        processed = true;
        break;
      default:
        break;
    }
    const defferal = new Deferred();
    defferal.resolve(processed);
    return defferal.promise;
  }
  // Cancels recognition.
  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
    const properties = new PropertyCollection();
    properties.setProperty(CancellationErrorCodePropertyName, CancellationErrorCode[errorCode]);
    const result = new VoiceProfileEnrollmentResult(ResultReason.Canceled, error, error);
    if (!!this.privDeferralMap.getId(requestId)) {
      this.privDeferralMap.complete(requestId, result);
    }
  }
  createProfile(profileType, locale) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profileType.toString();
      const conPromise = this.connectImpl();
      try {
        const createProfileDeferral = new Deferred();
        yield conPromise;
        yield this.sendCreateProfile(createProfileDeferral, profileType, locale);
        void this.receiveMessage();
        return createProfileDeferral.promise;
      } catch (err) {
        throw err;
      }
    });
  }
  resetProfile(profile) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      return this.sendCommonRequest("reset", profile.profileType, profile);
    });
  }
  deleteProfile(profile) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      return this.sendCommonRequest("delete", profile.profileType, profile);
    });
  }
  retrieveEnrollmentResult(profile) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      this.privExpectedProfileId = profile.profileId;
      return this.sendCommonRequest("fetch", profile.profileType, profile);
    });
  }
  getAllProfiles(profileType) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profileType.toString();
      return this.sendCommonRequest("fetch", profileType);
    });
  }
  getActivationPhrases(profileType, lang) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profileType.toString();
      const conPromise = this.connectImpl();
      try {
        const getPhrasesDeferral = new Deferred();
        yield conPromise;
        yield this.sendPhrasesRequest(getPhrasesDeferral, profileType, lang);
        void this.receiveMessage();
        return getPhrasesDeferral.promise;
      } catch (err) {
        throw err;
      }
    });
  }
  enrollProfile(profile) {
    return __awaiter32(this, void 0, void 0, function* () {
      this.voiceProfileType = profile.profileType.toString();
      const enrollmentDeferral = new Deferred();
      this.privRequestSession.startNewRecognition();
      this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);
      this.privRecognizerConfig.parameters.setProperty(PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
      const conPromise = this.connectImpl();
      const preAudioPromise = this.sendPreAudioMessages(profile, enrollmentDeferral);
      const node = yield this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);
      const format = yield this.privSpeakerAudioSource.format;
      const deviceInfo = yield this.privSpeakerAudioSource.deviceInfo;
      const audioNode = new ReplayableAudioNode(node, format.avgBytesPerSec);
      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
      try {
        yield conPromise;
        yield preAudioPromise;
      } catch (err) {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.ConnectionFailure, err);
      }
      const sessionStartEventArgs = new SessionEventArgs(this.privRequestSession.sessionId);
      if (!!this.privRecognizer.sessionStarted) {
        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
      }
      void this.receiveMessage();
      const audioSendPromise = this.sendAudio(audioNode);
      audioSendPromise.then(() => {
      }, (error) => {
        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, CancellationReason.Error, CancellationErrorCode.RuntimeError, error);
      });
      return enrollmentDeferral.promise;
    });
  }
  sendPreAudioMessages(profile, enrollmentDeferral) {
    return __awaiter32(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.privRequestSession.onSpeechContext();
      this.privDeferralMap.add(this.privRequestSession.requestId, enrollmentDeferral);
      yield this.sendBaseRequest(connection, "enroll", this.scenarioFrom(profile.profileType), profile);
    });
  }
  sendPhrasesRequest(getPhrasesDeferral, profileType, locale) {
    return __awaiter32(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.privRequestSession.onSpeechContext();
      this.privDeferralMap.add(this.privRequestSession.requestId, getPhrasesDeferral);
      const scenario = this.scenarioFrom(profileType);
      const profileCreateRequest = {
        locale,
        scenario
      };
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speaker.profile.phrases", this.privRequestSession.requestId, "application/json; charset=utf-8", JSON.stringify(profileCreateRequest)));
    });
  }
  sendCreateProfile(createProfileDeferral, profileType, locale) {
    return __awaiter32(this, void 0, void 0, function* () {
      const connection = yield this.fetchConnection();
      this.privRequestSession.onSpeechContext();
      this.privDeferralMap.add(this.privRequestSession.requestId, createProfileDeferral);
      const scenario = profileType === VoiceProfileType.TextIndependentIdentification ? "TextIndependentIdentification" : profileType === VoiceProfileType.TextIndependentVerification ? "TextIndependentVerification" : "TextDependentVerification";
      const profileCreateRequest = {
        locale,
        number: "1",
        scenario
      };
      return connection.send(new SpeechConnectionMessage(MessageType.Text, "speaker.profile.create", this.privRequestSession.requestId, "application/json; charset=utf-8", JSON.stringify(profileCreateRequest)));
    });
  }
  sendCommonRequest(operation, profileType, profile = void 0) {
    return __awaiter32(this, void 0, void 0, function* () {
      const conPromise = this.connectImpl();
      try {
        const deferral = new Deferred();
        this.privRequestSession.onSpeechContext();
        yield conPromise;
        const connection = yield this.fetchConnection();
        this.privDeferralMap.add(this.privRequestSession.requestId, deferral);
        yield this.sendBaseRequest(connection, operation, this.scenarioFrom(profileType), profile);
        void this.receiveMessage();
        return deferral.promise;
      } catch (err) {
        throw err;
      }
    });
  }
  sendBaseRequest(connection, operation, scenario, profile) {
    return __awaiter32(this, void 0, void 0, function* () {
      const profileRequest = {
        scenario
      };
      if (!!profile) {
        profileRequest.profileIds = [profile.profileId];
      } else {
        profileRequest.maxPageSize = -1;
      }
      return connection.send(new SpeechConnectionMessage(MessageType.Text, `speaker.profile.${operation}`, this.privRequestSession.requestId, "application/json; charset=utf-8", JSON.stringify(profileRequest)));
    });
  }
  extractSpeakerContext(model) {
    return {
      features: {
        interimResult: "enabled",
        progressiveDetection: "disabled"
      },
      profileIds: model.profileIds,
      scenario: model.scenario
    };
  }
  handlePhrasesResponse(response, requestId) {
    if (!!this.privDeferralMap.getId(requestId)) {
      if (response.status.statusCode.toLowerCase() !== "success") {
        const reason = ResultReason.Canceled;
        const result = new VoiceProfilePhraseResult(reason, response.status.statusCode, response.passPhraseType, []);
        this.privDeferralMap.complete(requestId, result);
      } else if (!!response.phrases && response.phrases.length > 0) {
        const reason = ResultReason.EnrollingVoiceProfile;
        const result = new VoiceProfilePhraseResult(reason, response.status.statusCode, response.passPhraseType, response.phrases);
        this.privDeferralMap.complete(requestId, result);
      } else {
        throw new Error("Voice Profile get activation phrases failed, no phrases received");
      }
    } else {
      throw new Error(`Voice Profile get activation phrases request for requestID ${requestId} not found`);
    }
  }
  handleCreateResponse(response, requestId) {
    if (!!response.profiles && response.profiles.length > 0) {
      if (!!this.privDeferralMap.getId(requestId)) {
        const profileIds = response.profiles.map((profile) => profile.profileId);
        this.privDeferralMap.complete(requestId, profileIds);
      } else {
        throw new Error(`Voice Profile create request for requestID ${requestId} not found`);
      }
    } else {
      throw new Error("Voice Profile create failed, no profile id received");
    }
  }
  handleResultResponse(response, requestId) {
    if (!!this.privDeferralMap.getId(requestId)) {
      const successReason = response.operation.toLowerCase() === "delete" ? ResultReason.DeletedVoiceProfile : ResultReason.ResetVoiceProfile;
      const reason = response.status.statusCode.toLowerCase() === "success" ? successReason : ResultReason.Canceled;
      const result = new VoiceProfileResult(reason, `statusCode: ${response.status.statusCode}, errorDetails: ${response.status.reason}`);
      this.privDeferralMap.complete(requestId, result);
    } else {
      throw new Error(`Voice Profile create request for requestID ${requestId} not found`);
    }
  }
  handleFetchResponse(enrollmentResponse, requestId) {
    if (!!this.privDeferralMap.getId(requestId) && !!enrollmentResponse.profiles[0]) {
      if (!!this.privExpectedProfileId && enrollmentResponse.profiles.length === 1 && enrollmentResponse.profiles[0].profileId === this.privExpectedProfileId) {
        this.privExpectedProfileId = void 0;
        const profileInfo = enrollmentResponse.profiles[0];
        const result = new VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(profileInfo.enrollmentStatus), JSON.stringify(profileInfo), enrollmentResponse.status.reason);
        this.privDeferralMap.complete(requestId, result);
      } else if (enrollmentResponse.profiles.length > 0) {
        const iProfiles = enrollmentResponse.profiles;
        const profileResults = [];
        for (const profile of iProfiles) {
          profileResults.push(new VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(profile.enrollmentStatus), JSON.stringify(profile), enrollmentResponse.status.reason));
        }
        this.privDeferralMap.complete(requestId, profileResults);
      }
    } else {
      throw new Error(`Voice Profile fetch request for requestID ${requestId} not found`);
    }
  }
  enrollmentReasonFrom(statusCode) {
    switch (statusCode.toLowerCase()) {
      case "enrolled":
        return ResultReason.EnrolledVoiceProfile;
      case "invalidlocale":
      case "invalidphrase":
      case "invalidaudioformat":
      case "invalidscenario":
      case "invalidprofilecount":
      case "invalidoperation":
      case "audiotooshort":
      case "audiotoolong":
      case "toomanyenrollments":
      case "storageconflict":
      case "profilenotfound":
      case "incompatibleprofiles":
      case "incompleteenrollment":
        return ResultReason.Canceled;
      default:
        return ResultReason.EnrollingVoiceProfile;
    }
  }
  scenarioFrom(profileType) {
    return profileType === VoiceProfileType.TextIndependentIdentification ? "TextIndependentIdentification" : profileType === VoiceProfileType.TextIndependentVerification ? "TextIndependentVerification" : "TextDependentVerification";
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js
var OutputFormatPropertyName = "OutputFormat";
var CancellationErrorCodePropertyName = "CancellationErrorCode";
var ServicePropertiesPropertyName = "ServiceProperties";
var ForceDictationPropertyName = "ForceDictation";
var AutoDetectSourceLanguagesOpenRangeOptionName = "OpenRange";

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js
var __awaiter33 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var AudioWorkletSourceURLPropertyName = "MICROPHONE-WorkletSourceUrl";
var MicAudioSource = class {
  constructor(privRecorder, deviceId, audioSourceId, mediaStream) {
    this.privRecorder = privRecorder;
    this.deviceId = deviceId;
    this.privStreams = {};
    this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;
    this.privId = audioSourceId ? audioSourceId : createNoDashGuid();
    this.privEvents = new EventSource();
    this.privMediaStream = mediaStream || null;
    this.privIsClosing = false;
  }
  get format() {
    return Promise.resolve(MicAudioSource.AUDIOFORMAT);
  }
  turnOn() {
    if (this.privInitializeDeferral) {
      return this.privInitializeDeferral.promise;
    }
    this.privInitializeDeferral = new Deferred();
    try {
      this.createAudioContext();
    } catch (error) {
      if (error instanceof Error) {
        const typedError = error;
        this.privInitializeDeferral.reject(typedError.name + ": " + typedError.message);
      } else {
        this.privInitializeDeferral.reject(error);
      }
      return this.privInitializeDeferral.promise;
    }
    const nav = window.navigator;
    let getUserMedia = (
      // eslint-disable-next-line
      nav.getUserMedia || nav.webkitGetUserMedia || nav.mozGetUserMedia || nav.msGetUserMedia
    );
    if (!!nav.mediaDevices) {
      getUserMedia = (constraints, successCallback, errorCallback) => {
        nav.mediaDevices.getUserMedia(constraints).then(successCallback).catch(errorCallback);
      };
    }
    if (!getUserMedia) {
      const errorMsg = "Browser does not support getUserMedia.";
      this.privInitializeDeferral.reject(errorMsg);
      this.onEvent(new AudioSourceErrorEvent(errorMsg, ""));
    } else {
      const next = () => {
        this.onEvent(new AudioSourceInitializingEvent(this.privId));
        if (this.privMediaStream && this.privMediaStream.active) {
          this.onEvent(new AudioSourceReadyEvent(this.privId));
          this.privInitializeDeferral.resolve();
        } else {
          getUserMedia({ audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false }, (mediaStream) => {
            this.privMediaStream = mediaStream;
            this.onEvent(new AudioSourceReadyEvent(this.privId));
            this.privInitializeDeferral.resolve();
          }, (error) => {
            const errorMsg = `Error occurred during microphone initialization: ${error}`;
            this.privInitializeDeferral.reject(errorMsg);
            this.onEvent(new AudioSourceErrorEvent(this.privId, errorMsg));
          });
        }
      };
      if (this.privContext.state === "suspended") {
        this.privContext.resume().then(next).catch((reason) => {
          this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);
        });
      } else {
        next();
      }
    }
    return this.privInitializeDeferral.promise;
  }
  id() {
    return this.privId;
  }
  attach(audioNodeId) {
    this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
    return this.listen(audioNodeId).then((stream) => {
      this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return {
        detach: () => __awaiter33(this, void 0, void 0, function* () {
          stream.readEnded();
          delete this.privStreams[audioNodeId];
          this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          return this.turnOff();
        }),
        id: () => audioNodeId,
        read: () => stream.read()
      };
    });
  }
  detach(audioNodeId) {
    if (audioNodeId && this.privStreams[audioNodeId]) {
      this.privStreams[audioNodeId].close();
      delete this.privStreams[audioNodeId];
      this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
    }
  }
  turnOff() {
    return __awaiter33(this, void 0, void 0, function* () {
      for (const streamId in this.privStreams) {
        if (streamId) {
          const stream = this.privStreams[streamId];
          if (stream) {
            stream.close();
          }
        }
      }
      this.onEvent(new AudioSourceOffEvent(this.privId));
      if (this.privInitializeDeferral) {
        yield this.privInitializeDeferral;
        this.privInitializeDeferral = null;
      }
      yield this.destroyAudioContext();
      return;
    });
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return this.getMicrophoneLabel().then((label) => ({
      bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,
      channelcount: MicAudioSource.AUDIOFORMAT.channels,
      connectivity: connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: label,
      samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,
      type: type.Microphones
    }));
  }
  setProperty(name, value) {
    if (name === AudioWorkletSourceURLPropertyName) {
      this.privRecorder.setWorkletUrl(value);
    } else {
      throw new Error("Property '" + name + "' is not supported on Microphone.");
    }
  }
  getMicrophoneLabel() {
    const defaultMicrophoneName = "microphone";
    if (this.privMicrophoneLabel !== void 0) {
      return Promise.resolve(this.privMicrophoneLabel);
    }
    if (this.privMediaStream === void 0 || !this.privMediaStream.active) {
      return Promise.resolve(defaultMicrophoneName);
    }
    this.privMicrophoneLabel = defaultMicrophoneName;
    const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;
    if (void 0 === microphoneDeviceId) {
      return Promise.resolve(this.privMicrophoneLabel);
    }
    const deferred = new Deferred();
    navigator.mediaDevices.enumerateDevices().then((devices) => {
      for (const device of devices) {
        if (device.deviceId === microphoneDeviceId) {
          this.privMicrophoneLabel = device.label;
          break;
        }
      }
      deferred.resolve(this.privMicrophoneLabel);
    }, () => deferred.resolve(this.privMicrophoneLabel));
    return deferred.promise;
  }
  listen(audioNodeId) {
    return __awaiter33(this, void 0, void 0, function* () {
      yield this.turnOn();
      const stream = new ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);
      this.privStreams[audioNodeId] = stream;
      try {
        this.privRecorder.record(this.privContext, this.privMediaStream, stream);
      } catch (error) {
        this.onEvent(new AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));
        throw error;
      }
      const result = stream;
      return result;
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    Events.instance.onEvent(event);
  }
  createAudioContext() {
    if (!!this.privContext) {
      return;
    }
    this.privContext = AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);
  }
  destroyAudioContext() {
    return __awaiter33(this, void 0, void 0, function* () {
      if (!this.privContext) {
        return;
      }
      this.privRecorder.releaseMediaResources(this.privContext);
      let hasClose = false;
      if ("close" in this.privContext) {
        hasClose = true;
      }
      if (hasClose) {
        if (!this.privIsClosing) {
          this.privIsClosing = true;
          yield this.privContext.close();
          this.privContext = null;
          this.privIsClosing = false;
        }
      } else if (null !== this.privContext && this.privContext.state === "running") {
        yield this.privContext.suspend();
      }
    });
  }
};
MicAudioSource.AUDIOFORMAT = AudioStreamFormat.getDefaultInputFormat();

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js
var __awaiter34 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var FileAudioSource = class {
  constructor(file, filename, audioSourceId) {
    this.privStreams = {};
    this.privHeaderEnd = 44;
    this.privId = audioSourceId ? audioSourceId : createNoDashGuid();
    this.privEvents = new EventSource();
    this.privSource = file;
    if (typeof window !== "undefined" && typeof Blob !== "undefined" && this.privSource instanceof Blob) {
      this.privFilename = file.name;
    } else {
      this.privFilename = filename || "unknown.wav";
    }
    this.privAudioFormatPromise = this.readHeader();
  }
  get format() {
    return this.privAudioFormatPromise;
  }
  turnOn() {
    if (this.privFilename.lastIndexOf(".wav") !== this.privFilename.length - 4) {
      const errorMsg = this.privFilename + " is not supported. Only WAVE files are allowed at the moment.";
      this.onEvent(new AudioSourceErrorEvent(errorMsg, ""));
      return Promise.reject(errorMsg);
    }
    this.onEvent(new AudioSourceInitializingEvent(this.privId));
    this.onEvent(new AudioSourceReadyEvent(this.privId));
    return;
  }
  id() {
    return this.privId;
  }
  attach(audioNodeId) {
    return __awaiter34(this, void 0, void 0, function* () {
      this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
      const stream = yield this.upload(audioNodeId);
      this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
      return Promise.resolve({
        detach: () => __awaiter34(this, void 0, void 0, function* () {
          stream.readEnded();
          delete this.privStreams[audioNodeId];
          this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
          yield this.turnOff();
        }),
        id: () => audioNodeId,
        read: () => stream.read()
      });
    });
  }
  detach(audioNodeId) {
    if (audioNodeId && this.privStreams[audioNodeId]) {
      this.privStreams[audioNodeId].close();
      delete this.privStreams[audioNodeId];
      this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
    }
  }
  turnOff() {
    for (const streamId in this.privStreams) {
      if (streamId) {
        const stream = this.privStreams[streamId];
        if (stream && !stream.isClosed) {
          stream.close();
        }
      }
    }
    this.onEvent(new AudioSourceOffEvent(this.privId));
    return Promise.resolve();
  }
  get events() {
    return this.privEvents;
  }
  get deviceInfo() {
    return this.privAudioFormatPromise.then((result) => Promise.resolve({
      bitspersample: result.bitsPerSample,
      channelcount: result.channels,
      connectivity: connectivity.Unknown,
      manufacturer: "Speech SDK",
      model: "File",
      samplerate: result.samplesPerSec,
      type: type.File
    }));
  }
  readHeader() {
    const maxHeaderSize = 4296;
    const header = this.privSource.slice(0, maxHeaderSize);
    const headerResult = new Deferred();
    const processHeader = (header2) => {
      const view = new DataView(header2);
      const getWord = (index) => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));
      if ("RIFF" !== getWord(0)) {
        headerResult.reject("Invalid WAV header in file, RIFF was not found");
        return;
      }
      if ("WAVE" !== getWord(8) || "fmt " !== getWord(12)) {
        headerResult.reject("Invalid WAV header in file, WAVEfmt was not found");
        return;
      }
      const formatSize = view.getInt32(16, true);
      const channelCount = view.getUint16(22, true);
      const sampleRate = view.getUint32(24, true);
      const bitsPerSample = view.getUint16(34, true);
      let pos = 36 + Math.max(formatSize - 16, 0);
      for (; getWord(pos) !== "data"; pos += 2) {
        if (pos > maxHeaderSize - 8) {
          headerResult.reject("Invalid WAV header in file, data block was not found");
          return;
        }
      }
      this.privHeaderEnd = pos + 8;
      headerResult.resolve(AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));
    };
    if (typeof window !== "undefined" && typeof Blob !== "undefined" && header instanceof Blob) {
      const reader = new FileReader();
      reader.onload = (event) => {
        const header2 = event.target.result;
        processHeader(header2);
      };
      reader.readAsArrayBuffer(header);
    } else {
      const h = header;
      processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));
    }
    return headerResult.promise;
  }
  upload(audioNodeId) {
    return __awaiter34(this, void 0, void 0, function* () {
      const onerror = (error) => {
        const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;
        this.onEvent(new AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));
        throw new Error(errorMsg);
      };
      try {
        yield this.turnOn();
        const format = yield this.privAudioFormatPromise;
        const stream = new ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);
        this.privStreams[audioNodeId] = stream;
        const chunk = this.privSource.slice(this.privHeaderEnd);
        const processFile = (buff) => {
          if (stream.isClosed) {
            return;
          }
          stream.writeStreamChunk({
            buffer: buff,
            isEnd: false,
            timeReceived: Date.now()
          });
          stream.close();
        };
        if (typeof window !== "undefined" && typeof Blob !== "undefined" && chunk instanceof Blob) {
          const reader = new FileReader();
          reader.onerror = (ev) => onerror(ev.toString());
          reader.onload = (event) => {
            const fileBuffer = event.target.result;
            processFile(fileBuffer);
          };
          reader.readAsArrayBuffer(chunk);
        } else {
          const c = chunk;
          processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));
        }
        return stream;
      } catch (e) {
        onerror(e);
      }
    });
  }
  onEvent(event) {
    this.privEvents.onEvent(event);
    Events.instance.onEvent(event);
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js
var PcmRecorder = class {
  constructor(stopInputOnRelease) {
    this.privStopInputOnRelease = stopInputOnRelease;
  }
  record(context, mediaStream, outputStream) {
    const desiredSampleRate = 16e3;
    const waveStreamEncoder = new RiffPcmEncoder(context.sampleRate, desiredSampleRate);
    const micInput = context.createMediaStreamSource(mediaStream);
    const attachScriptProcessor = () => {
      const scriptNode = (() => {
        let bufferSize = 0;
        try {
          return context.createScriptProcessor(bufferSize, 1, 1);
        } catch (error) {
          bufferSize = 2048;
          let audioSampleRate = context.sampleRate;
          while (bufferSize < 16384 && audioSampleRate >= 2 * desiredSampleRate) {
            bufferSize <<= 1;
            audioSampleRate >>= 1;
          }
          return context.createScriptProcessor(bufferSize, 1, 1);
        }
      })();
      scriptNode.onaudioprocess = (event) => {
        const inputFrame = event.inputBuffer.getChannelData(0);
        if (outputStream && !outputStream.isClosed) {
          const waveFrame = waveStreamEncoder.encode(inputFrame);
          if (!!waveFrame) {
            outputStream.writeStreamChunk({
              buffer: waveFrame,
              isEnd: false,
              timeReceived: Date.now()
            });
          }
        }
      };
      micInput.connect(scriptNode);
      scriptNode.connect(context.destination);
      this.privMediaResources = {
        scriptProcessorNode: scriptNode,
        source: micInput,
        stream: mediaStream
      };
    };
    if (!!context.audioWorklet) {
      if (!this.privSpeechProcessorScript) {
        const workletScript = `class SP extends AudioWorkletProcessor {
                    constructor(options) {
                      super(options);
                    }
                    process(inputs, outputs) {
                      const input = inputs[0];
                      const output = [];
                      for (let channel = 0; channel < input.length; channel += 1) {
                        output[channel] = input[channel];
                      }
                      this.port.postMessage(output[0]);
                      return true;
                    }
                  }
                  registerProcessor('speech-processor', SP);`;
        const blob = new Blob([workletScript], { type: "application/javascript; charset=utf-8" });
        this.privSpeechProcessorScript = URL.createObjectURL(blob);
      }
      context.audioWorklet.addModule(this.privSpeechProcessorScript).then(() => {
        const workletNode = new AudioWorkletNode(context, "speech-processor");
        workletNode.port.onmessage = (ev) => {
          const inputFrame = ev.data;
          if (outputStream && !outputStream.isClosed) {
            const waveFrame = waveStreamEncoder.encode(inputFrame);
            if (!!waveFrame) {
              outputStream.writeStreamChunk({
                buffer: waveFrame,
                isEnd: false,
                timeReceived: Date.now()
              });
            }
          }
        };
        micInput.connect(workletNode);
        workletNode.connect(context.destination);
        this.privMediaResources = {
          scriptProcessorNode: workletNode,
          source: micInput,
          stream: mediaStream
        };
      }).catch(() => {
        attachScriptProcessor();
      });
    } else {
      try {
        attachScriptProcessor();
      } catch (err) {
        throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);
      }
    }
  }
  releaseMediaResources(context) {
    if (this.privMediaResources) {
      if (this.privMediaResources.scriptProcessorNode) {
        this.privMediaResources.scriptProcessorNode.disconnect(context.destination);
        this.privMediaResources.scriptProcessorNode = null;
      }
      if (this.privMediaResources.source) {
        this.privMediaResources.source.disconnect();
        if (this.privStopInputOnRelease) {
          this.privMediaResources.stream.getTracks().forEach((track) => track.stop());
        }
        this.privMediaResources.source = null;
      }
    }
  }
  setWorkletUrl(url) {
    this.privSpeechProcessorScript = url;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js
var net = __toESM(require_net());
var tls = __toESM(require_tls());
var import_agent_base = __toESM(require_agent_base());
var import_https_proxy_agent = __toESM(require_https_proxy_agent());
var import_ws = __toESM(require_ws());
var __awaiter35 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var WebsocketMessageAdapter = class {
  constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {
    if (!uri) {
      throw new ArgumentNullError("uri");
    }
    if (!messageFormatter) {
      throw new ArgumentNullError("messageFormatter");
    }
    this.proxyInfo = proxyInfo;
    this.privConnectionEvents = new EventSource();
    this.privConnectionId = connectionId;
    this.privMessageFormatter = messageFormatter;
    this.privConnectionState = ConnectionState.None;
    this.privUri = uri;
    this.privHeaders = headers;
    this.privEnableCompression = enableCompression;
    this.privHeaders[HeaderNames.ConnectionId] = this.privConnectionId;
    this.privLastErrorReceived = "";
  }
  get state() {
    return this.privConnectionState;
  }
  open() {
    if (this.privConnectionState === ConnectionState.Disconnected) {
      return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);
    }
    if (this.privConnectionEstablishDeferral) {
      return this.privConnectionEstablishDeferral.promise;
    }
    this.privConnectionEstablishDeferral = new Deferred();
    this.privCertificateValidatedDeferral = new Deferred();
    this.privConnectionState = ConnectionState.Connecting;
    try {
      if (typeof WebSocket !== "undefined" && !WebsocketMessageAdapter.forceNpmWebSocket) {
        this.privCertificateValidatedDeferral.resolve();
        this.privWebsocketClient = new WebSocket(this.privUri);
      } else {
        const options = { headers: this.privHeaders, perMessageDeflate: this.privEnableCompression };
        this.privCertificateValidatedDeferral.resolve();
        options.agent = this.getAgent();
        const uri = new URL(this.privUri);
        let protocol = uri.protocol;
        if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === "wss:") {
          protocol = "https:";
        } else if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === "ws:") {
          protocol = "http:";
        }
        options.agent.protocol = protocol;
        this.privWebsocketClient = new import_ws.default(this.privUri, options);
      }
      this.privWebsocketClient.binaryType = "arraybuffer";
      this.privReceivingMessageQueue = new Queue();
      this.privDisconnectDeferral = new Deferred();
      this.privSendMessageQueue = new Queue();
      this.processSendQueue().catch((reason) => {
        Events.instance.onEvent(new BackgroundEvent(reason));
      });
    } catch (error) {
      this.privConnectionEstablishDeferral.resolve(new ConnectionOpenResponse(500, error));
      return this.privConnectionEstablishDeferral.promise;
    }
    this.onEvent(new ConnectionStartEvent(this.privConnectionId, this.privUri));
    this.privWebsocketClient.onopen = () => {
      this.privCertificateValidatedDeferral.promise.then(() => {
        this.privConnectionState = ConnectionState.Connected;
        this.onEvent(new ConnectionEstablishedEvent(this.privConnectionId));
        this.privConnectionEstablishDeferral.resolve(new ConnectionOpenResponse(200, ""));
      }, (error) => {
        this.privConnectionEstablishDeferral.reject(error);
      });
    };
    this.privWebsocketClient.onerror = (e) => {
      this.onEvent(new ConnectionErrorEvent(this.privConnectionId, e.message, e.type));
      this.privLastErrorReceived = e.message;
    };
    this.privWebsocketClient.onclose = (e) => {
      if (this.privConnectionState === ConnectionState.Connecting) {
        this.privConnectionState = ConnectionState.Disconnected;
        this.privConnectionEstablishDeferral.resolve(new ConnectionOpenResponse(e.code, e.reason + " " + this.privLastErrorReceived));
      } else {
        this.privConnectionState = ConnectionState.Disconnected;
        this.privWebsocketClient = null;
        this.onEvent(new ConnectionClosedEvent(this.privConnectionId, e.code, e.reason));
      }
      this.onClose(e.code, e.reason).catch((reason) => {
        Events.instance.onEvent(new BackgroundEvent(reason));
      });
    };
    this.privWebsocketClient.onmessage = (e) => {
      const networkReceivedTime = (/* @__PURE__ */ new Date()).toISOString();
      if (this.privConnectionState === ConnectionState.Connected) {
        const deferred = new Deferred();
        this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);
        if (e.data instanceof ArrayBuffer) {
          const rawMessage = new RawWebsocketMessage(MessageType.Binary, e.data);
          this.privMessageFormatter.toConnectionMessage(rawMessage).then((connectionMessage) => {
            this.onEvent(new ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));
            deferred.resolve(connectionMessage);
          }, (error) => {
            deferred.reject(`Invalid binary message format. Error: ${error}`);
          });
        } else {
          const rawMessage = new RawWebsocketMessage(MessageType.Text, e.data);
          this.privMessageFormatter.toConnectionMessage(rawMessage).then((connectionMessage) => {
            this.onEvent(new ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));
            deferred.resolve(connectionMessage);
          }, (error) => {
            deferred.reject(`Invalid text message format. Error: ${error}`);
          });
        }
      }
    };
    return this.privConnectionEstablishDeferral.promise;
  }
  send(message) {
    if (this.privConnectionState !== ConnectionState.Connected) {
      return Promise.reject(`Cannot send on connection that is in ${ConnectionState[this.privConnectionState]} state`);
    }
    const messageSendStatusDeferral = new Deferred();
    const messageSendDeferral = new Deferred();
    this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);
    this.privMessageFormatter.fromConnectionMessage(message).then((rawMessage) => {
      messageSendDeferral.resolve({
        Message: message,
        RawWebsocketMessage: rawMessage,
        sendStatusDeferral: messageSendStatusDeferral
      });
    }, (error) => {
      messageSendDeferral.reject(`Error formatting the message. ${error}`);
    });
    return messageSendStatusDeferral.promise;
  }
  read() {
    if (this.privConnectionState !== ConnectionState.Connected) {
      return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);
    }
    return this.privReceivingMessageQueue.dequeue();
  }
  close(reason) {
    if (this.privWebsocketClient) {
      if (this.privConnectionState !== ConnectionState.Disconnected) {
        this.privWebsocketClient.close(1e3, reason ? reason : "Normal closure by client");
      }
    } else {
      return Promise.resolve();
    }
    return this.privDisconnectDeferral.promise;
  }
  get events() {
    return this.privConnectionEvents;
  }
  sendRawMessage(sendItem) {
    try {
      if (!sendItem) {
        return Promise.resolve();
      }
      this.onEvent(new ConnectionMessageSentEvent(this.privConnectionId, (/* @__PURE__ */ new Date()).toISOString(), sendItem.Message));
      if (this.isWebsocketOpen) {
        this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);
      } else {
        return Promise.reject("websocket send error: Websocket not ready " + this.privConnectionId + " " + sendItem.Message.id + " " + new Error().stack);
      }
      return Promise.resolve();
    } catch (e) {
      return Promise.reject(`websocket send error: ${e}`);
    }
  }
  onClose(code, reason) {
    return __awaiter35(this, void 0, void 0, function* () {
      const closeReason = `Connection closed. ${code}: ${reason}`;
      this.privConnectionState = ConnectionState.Disconnected;
      this.privDisconnectDeferral.resolve();
      yield this.privReceivingMessageQueue.drainAndDispose(() => {
      }, closeReason);
      yield this.privSendMessageQueue.drainAndDispose((pendingSendItem) => {
        pendingSendItem.sendStatusDeferral.reject(closeReason);
      }, closeReason);
    });
  }
  processSendQueue() {
    return __awaiter35(this, void 0, void 0, function* () {
      while (true) {
        const itemToSend = this.privSendMessageQueue.dequeue();
        const sendItem = yield itemToSend;
        if (!sendItem) {
          return;
        }
        try {
          yield this.sendRawMessage(sendItem);
          sendItem.sendStatusDeferral.resolve();
        } catch (sendError) {
          sendItem.sendStatusDeferral.reject(sendError);
        }
      }
    });
  }
  onEvent(event) {
    this.privConnectionEvents.onEvent(event);
    Events.instance.onEvent(event);
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  getAgent() {
    const agent = new import_agent_base.default.Agent(this.createConnection);
    if (this.proxyInfo !== void 0 && this.proxyInfo.HostName !== void 0 && this.proxyInfo.Port > 0) {
      agent.proxyInfo = this.proxyInfo;
    }
    return agent;
  }
  static GetProxyAgent(proxyInfo) {
    const httpProxyOptions = {
      host: proxyInfo.HostName,
      port: proxyInfo.Port
    };
    if (!!proxyInfo.UserName) {
      httpProxyOptions.headers = {
        "Proxy-Authentication": "Basic " + new Buffer(`${proxyInfo.UserName}:${proxyInfo.Password === void 0 ? "" : proxyInfo.Password}`).toString("base64")
      };
    } else {
      httpProxyOptions.headers = {};
    }
    httpProxyOptions.headers.requestOCSP = "true";
    const httpProxyAgent = new import_https_proxy_agent.default(httpProxyOptions);
    return httpProxyAgent;
  }
  createConnection(request, options) {
    let socketPromise;
    options = Object.assign(Object.assign({}, options), {
      requestOCSP: true,
      servername: options.host
    });
    if (!!this.proxyInfo) {
      const httpProxyAgent = WebsocketMessageAdapter.GetProxyAgent(this.proxyInfo);
      const baseAgent = httpProxyAgent;
      socketPromise = new Promise((resolve, reject) => {
        baseAgent.callback(request, options, (error, socket) => {
          if (!!error) {
            reject(error);
          } else {
            resolve(socket);
          }
        });
      });
    } else {
      if (!!options.secureEndpoint) {
        socketPromise = Promise.resolve(tls.connect(options));
      } else {
        socketPromise = Promise.resolve(net.connect(options));
      }
    }
    return socketPromise;
  }
  get isWebsocketOpen() {
    return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;
  }
};
WebsocketMessageAdapter.forceNpmWebSocket = false;

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js
var __awaiter36 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var WebsocketConnection = class {
  constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {
    this.privIsDisposed = false;
    if (!uri) {
      throw new ArgumentNullError("uri");
    }
    if (!messageFormatter) {
      throw new ArgumentNullError("messageFormatter");
    }
    this.privMessageFormatter = messageFormatter;
    let queryParams = "";
    let i = 0;
    if (queryParameters) {
      for (const paramName in queryParameters) {
        if (paramName) {
          queryParams += i === 0 && uri.indexOf("?") === -1 ? "?" : "&";
          const key = encodeURIComponent(paramName);
          queryParams += key;
          let val = queryParameters[paramName];
          if (val) {
            val = encodeURIComponent(val);
            queryParams += `=${val}`;
          }
          i++;
        }
      }
    }
    if (headers) {
      for (const headerName in headers) {
        if (headerName) {
          queryParams += i === 0 && uri.indexOf("?") === -1 ? "?" : "&";
          const val = encodeURIComponent(headers[headerName]);
          queryParams += `${headerName}=${val}`;
          i++;
        }
      }
    }
    this.privUri = uri + queryParams;
    this.privId = connectionId ? connectionId : createNoDashGuid();
    this.privConnectionMessageAdapter = new WebsocketMessageAdapter(this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);
  }
  dispose() {
    return __awaiter36(this, void 0, void 0, function* () {
      this.privIsDisposed = true;
      if (this.privConnectionMessageAdapter) {
        yield this.privConnectionMessageAdapter.close();
      }
    });
  }
  isDisposed() {
    return this.privIsDisposed;
  }
  get id() {
    return this.privId;
  }
  get uri() {
    return this.privUri;
  }
  state() {
    return this.privConnectionMessageAdapter.state;
  }
  open() {
    return this.privConnectionMessageAdapter.open();
  }
  send(message) {
    return this.privConnectionMessageAdapter.send(message);
  }
  read() {
    return this.privConnectionMessageAdapter.read();
  }
  get events() {
    return this.privConnectionMessageAdapter.events;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js
var ReplayableAudioNode = class {
  constructor(audioSource, bytesPerSecond) {
    this.privBuffers = [];
    this.privReplayOffset = 0;
    this.privLastShrinkOffset = 0;
    this.privBufferStartOffset = 0;
    this.privBufferSerial = 0;
    this.privBufferedBytes = 0;
    this.privReplay = false;
    this.privLastChunkAcquiredTime = 0;
    this.privAudioNode = audioSource;
    this.privBytesPerSecond = bytesPerSecond;
  }
  id() {
    return this.privAudioNode.id();
  }
  // Reads and returns the next chunk of audio buffer.
  // If replay of existing buffers are needed, read() will first seek and replay
  // existing content, and upoin completion it will read new content from the underlying
  // audio node, saving that content into the replayable buffers.
  read() {
    if (!!this.privReplay && this.privBuffers.length !== 0) {
      const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;
      let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
      if (0 !== bytesToSeek % 2) {
        bytesToSeek++;
      }
      let i = 0;
      while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
        bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
      }
      if (i < this.privBuffers.length) {
        const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);
        this.privReplayOffset += retVal.byteLength / this.privBytesPerSecond * 1e7;
        if (i === this.privBuffers.length - 1) {
          this.privReplay = false;
        }
        return Promise.resolve({
          buffer: retVal,
          isEnd: false,
          timeReceived: this.privBuffers[i].chunk.timeReceived
        });
      }
    }
    return this.privAudioNode.read().then((result) => {
      if (result && result.buffer) {
        this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));
        this.privBufferedBytes += result.buffer.byteLength;
      }
      return result;
    });
  }
  detach() {
    this.privBuffers = void 0;
    return this.privAudioNode.detach();
  }
  replay() {
    if (this.privBuffers && 0 !== this.privBuffers.length) {
      this.privReplay = true;
      this.privReplayOffset = this.privLastShrinkOffset;
    }
  }
  // Shrinks the existing audio buffers to start at the new offset, or at the
  // beginning of the buffer closest to the requested offset.
  // A replay request will start from the last shrink point.
  shrinkBuffers(offset) {
    if (this.privBuffers === void 0 || this.privBuffers.length === 0) {
      return;
    }
    this.privLastShrinkOffset = offset;
    const offsetToSeek = offset - this.privBufferStartOffset;
    let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
    let i = 0;
    while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
      bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
    }
    this.privBufferStartOffset = Math.round(offset - bytesToSeek / this.privBytesPerSecond * 1e7);
    this.privBuffers = this.privBuffers.slice(i);
  }
  // Finds the time a buffer of audio was first seen by offset.
  findTimeAtOffset(offset) {
    if (offset < this.privBufferStartOffset || this.privBuffers === void 0) {
      return 0;
    }
    for (const value of this.privBuffers) {
      const startOffset = value.byteOffset / this.privBytesPerSecond * 1e7;
      const endOffset = startOffset + value.chunk.buffer.byteLength / this.privBytesPerSecond * 1e7;
      if (offset >= startOffset && offset <= endOffset) {
        return value.chunk.timeReceived;
      }
    }
    return 0;
  }
};
var BufferEntry = class {
  constructor(chunk, serial, byteOffset) {
    this.chunk = chunk;
    this.serial = serial;
    this.byteOffset = byteOffset;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js
var ProxyInfo = class {
  constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
    this.privProxyHostName = proxyHostName;
    this.privProxyPort = proxyPort;
    this.privProxyUserName = proxyUserName;
    this.privProxyPassword = proxyPassword;
  }
  static fromParameters(parameters) {
    return new ProxyInfo(parameters.getProperty(PropertyId.SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(PropertyId.SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(PropertyId.SpeechServiceConnection_ProxyUserName), parameters.getProperty(PropertyId.SpeechServiceConnection_ProxyPassword));
  }
  static fromRecognizerConfig(config) {
    return this.fromParameters(config.parameters);
  }
  get HostName() {
    return this.privProxyHostName;
  }
  get Port() {
    return this.privProxyPort;
  }
  get UserName() {
    return this.privProxyUserName;
  }
  get Password() {
    return this.privProxyPassword;
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js
var import_bent = __toESM(require_browser());
var __awaiter37 = function(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, _arguments || [])).next());
  });
};
var RestRequestType;
(function(RestRequestType2) {
  RestRequestType2["Get"] = "GET";
  RestRequestType2["Post"] = "POST";
  RestRequestType2["Delete"] = "DELETE";
  RestRequestType2["File"] = "file";
})(RestRequestType || (RestRequestType = {}));
var RestMessageAdapter = class {
  constructor(configParams) {
    if (!configParams) {
      throw new ArgumentNullError("configParams");
    }
    this.privHeaders = configParams.headers;
    this.privIgnoreCache = configParams.ignoreCache;
  }
  static extractHeaderValue(headerKey, headers) {
    let headerValue = "";
    try {
      const arr = headers.trim().split(/[\r\n]+/);
      const headerMap = {};
      arr.forEach((line) => {
        const parts = line.split(": ");
        const header = parts.shift().toLowerCase();
        const value = parts.join(": ");
        headerMap[header] = value;
      });
      headerValue = headerMap[headerKey.toLowerCase()];
    } catch (e) {
    }
    return headerValue;
  }
  set options(configParams) {
    this.privHeaders = configParams.headers;
    this.privIgnoreCache = configParams.ignoreCache;
  }
  setHeaders(key, value) {
    this.privHeaders[key] = value;
  }
  request(method, uri, queryParams = {}, body = null) {
    const responseReceivedDeferral = new Deferred();
    const requestCommand = method === RestRequestType.File ? "POST" : method;
    const handleRestResponse = (data, j = {}) => {
      const d = data;
      return {
        data: JSON.stringify(j),
        headers: JSON.stringify(data.headers),
        json: j,
        ok: data.statusCode >= 200 && data.statusCode < 300,
        status: data.statusCode,
        statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage
      };
    };
    const send = (postData) => {
      const sendRequest = (0, import_bent.default)(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);
      const params = this.queryParams(queryParams) === "" ? "" : `?${this.queryParams(queryParams)}`;
      sendRequest(params, postData).then((data) => __awaiter37(this, void 0, void 0, function* () {
        if (method === RestRequestType.Delete || data.statusCode === 204) {
          responseReceivedDeferral.resolve(handleRestResponse(data));
        } else {
          try {
            const j = yield data.json();
            responseReceivedDeferral.resolve(handleRestResponse(data, j));
          } catch (_a) {
            responseReceivedDeferral.resolve(handleRestResponse(data));
          }
        }
      })).catch((error) => {
        responseReceivedDeferral.reject(error);
      });
    };
    if (this.privIgnoreCache) {
      this.privHeaders["Cache-Control"] = "no-cache";
    }
    if (method === RestRequestType.Post && body) {
      this.privHeaders["content-type"] = "application/json";
      this.privHeaders["Content-Type"] = "application/json";
    }
    send(body);
    return responseReceivedDeferral.promise;
  }
  queryParams(params = {}) {
    return Object.keys(params).map((k) => encodeURIComponent(k) + "=" + encodeURIComponent(params[k])).join("&");
  }
};

// node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js
Events.instance.attachConsoleListener(new ConsoleLoggingListener());
export {
  ActivityReceivedEventArgs,
  AudioConfig,
  AudioFormatTag,
  AudioInputStream,
  AudioOutputStream,
  AudioStreamFormat,
  AutoDetectSourceLanguageConfig,
  AutoDetectSourceLanguageResult,
  BaseAudioPlayer,
  BotFrameworkConfig,
  CancellationDetails,
  CancellationDetailsBase,
  CancellationErrorCode,
  CancellationReason,
  Connection,
  ConnectionEventArgs,
  ConnectionMessage2 as ConnectionMessage,
  ConnectionMessageEventArgs,
  Conversation,
  ConversationExpirationEventArgs,
  ConversationParticipantsChangedEventArgs,
  ConversationTranscriber,
  ConversationTranscriptionCanceledEventArgs,
  ConversationTranscriptionEventArgs,
  ConversationTranslationCanceledEventArgs,
  ConversationTranslationEventArgs,
  ConversationTranslationResult,
  ConversationTranslator,
  CustomCommandsConfig,
  Diagnostics,
  DialogServiceConfig,
  DialogServiceConnector,
  IntentRecognitionCanceledEventArgs,
  IntentRecognitionEventArgs,
  IntentRecognitionResult,
  IntentRecognizer,
  KeywordRecognitionModel,
  LanguageIdMode,
  LanguageUnderstandingModel,
  EventType as LogLevel,
  NoMatchDetails,
  NoMatchReason,
  OutputFormat,
  Participant,
  ParticipantChangedReason,
  PhraseListGrammar,
  ProfanityOption,
  PronunciationAssessmentConfig,
  PronunciationAssessmentGradingSystem,
  PronunciationAssessmentGranularity,
  PronunciationAssessmentResult,
  PropertyCollection,
  PropertyId,
  PullAudioInputStream,
  PullAudioInputStreamCallback,
  PullAudioOutputStream,
  PushAudioInputStream,
  PushAudioOutputStream,
  PushAudioOutputStreamCallback,
  RecognitionEventArgs,
  RecognitionResult,
  Recognizer,
  ResultReason,
  ServiceEventArgs,
  ServicePropertyChannel,
  SessionEventArgs,
  SourceLanguageConfig,
  SpeakerAudioDestination,
  SpeakerIdentificationModel,
  SpeakerRecognitionCancellationDetails,
  SpeakerRecognitionResult,
  SpeakerRecognitionResultType,
  SpeakerRecognizer,
  SpeakerVerificationModel,
  SpeechConfig,
  SpeechConfigImpl,
  SpeechRecognitionCanceledEventArgs,
  SpeechRecognitionEventArgs,
  SpeechRecognitionResult,
  SpeechRecognizer,
  SpeechSynthesisBookmarkEventArgs,
  SpeechSynthesisBoundaryType,
  SpeechSynthesisEventArgs,
  SpeechSynthesisOutputFormat,
  SpeechSynthesisResult,
  SpeechSynthesisVisemeEventArgs,
  SpeechSynthesisWordBoundaryEventArgs,
  SpeechSynthesizer,
  SpeechTranslationConfig,
  SpeechTranslationConfigImpl,
  SynthesisResult,
  SynthesisVoicesResult,
  TranslationRecognitionCanceledEventArgs,
  TranslationRecognitionEventArgs,
  TranslationRecognitionResult,
  TranslationRecognizer,
  TranslationSynthesisEventArgs,
  TranslationSynthesisResult,
  Translations,
  TurnStatusReceivedEventArgs,
  User,
  VoiceInfo,
  VoiceProfile,
  VoiceProfileCancellationDetails,
  VoiceProfileClient,
  VoiceProfileEnrollmentCancellationDetails,
  VoiceProfileEnrollmentResult,
  VoiceProfilePhraseResult,
  VoiceProfileResult,
  VoiceProfileType
};
//# sourceMappingURL=microsoft-cognitiveservices-speech-sdk.js.map
